{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "659 project",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqyQij_2YY9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmebF6Xo1aAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Pathloss(dis_array):\n",
        "  d=dis_array\n",
        "  result=32.4+20*np.log10(2400)+np.log10(d)*20\n",
        "  return result"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD5WQRJXX3u8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def creat_label(ball):\n",
        "  target=[]\n",
        "  for i in range(len(ball)):\n",
        "    if(2<=ball[i][0]<=12.97 and 2<=ball[i][1]<=13.89):\n",
        "      target.append(1)\n",
        "    else:\n",
        "      target.append(0)\n",
        "  return np.array(target)  "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgXIj1JNX8W6",
        "colab_type": "text"
      },
      "source": [
        "# LSTM to predict the location of dropoint of tennis ball"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyOWrfO8dncl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=500\n",
        "x_boundary=12.97\n",
        "y_boundary=13.89\n",
        "s_cor=np.array([[0,0],[14.97,0],[0,15.89],[14.97,15.89]])\n",
        "np.random.seed(5)\n",
        "x=np.random.uniform(low=0,high=14.97,size=N)\n",
        "y=np.random.uniform(low=0,high=15.89,size=N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McTZLkr8fGYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_cor=[]\n",
        "temp=[]\n",
        "for i in range(N):\n",
        "  temp.append(x[i])\n",
        "  temp.append(y[i])\n",
        "  t_cor.append(temp)\n",
        "  temp=[]\n",
        "dis=[]\n",
        "#compute the distance\n",
        "for i in range(N):\n",
        "  dis.append(list(np.linalg.norm((t_cor[i]-s_cor),axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hokKo3eMi079",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis_array=np.array(dis)\n",
        "fsl=Pathloss(dis_array)\n",
        "RSS=10+24-fsl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdVgmf9WyqUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=RSS\n",
        "label=np.array(t_cor)\n",
        "x_train,x_test,y_train,y_test=train_test_split(data,label,random_state=42,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQCMApLr3vJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale=StandardScaler()\n",
        "scale.fit(x_train)\n",
        "x_train_s=scale.transform(x_train).astype('float64')\n",
        "x_test_s=scale.transform(x_test)\n",
        "x_train_rnn=x_train_s.reshape(-1,1,4)\n",
        "x_test_rnn=x_test_s.reshape(-1,1,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_QuGerA3wG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(16,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(8,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(4,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(2))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGCVq9JlRXfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RNN():\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.LSTM(24,input_shape=(1,4),return_sequences=True))\n",
        "  # model.add(layers.LSTM(24,return_sequences=True))\n",
        "  model.add(layers.LSTM(24))\n",
        "  model.add(layers.Dense(2))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNREBHnES4Zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1225ff3a-9897-4153-8ec9-0ad69f312cee"
      },
      "source": [
        "mlp=RNN()\n",
        "mlp.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 24)             2784      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 24)                4704      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 50        \n",
            "=================================================================\n",
            "Total params: 7,538\n",
            "Trainable params: 7,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdNjY9b7bZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e609f2e3-175b-4e37-f850-038a96c4dbc9"
      },
      "source": [
        "mlp=RNN()\n",
        "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau('loss',patience=3,factor=0.3,min_lr=0.00001)\n",
        "mlp.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, ),\n",
        "      loss='mse',\n",
        "      metrics=['mae'])\n",
        "history_mlp=mlp.fit(\n",
        "    x_train_rnn,y_train,\n",
        "    epochs=2000,\n",
        "    batch_size=10,\n",
        "    validation_split=0.2,\n",
        "    validation_freq=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 77.0781 - mae: 7.5761 - val_loss: 80.2615 - val_mae: 7.8237\n",
            "Epoch 2/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 75.2982 - mae: 7.4856 - val_loss: 77.8114 - val_mae: 7.7032\n",
            "Epoch 3/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 71.9321 - mae: 7.3170 - val_loss: 72.4360 - val_mae: 7.4405\n",
            "Epoch 4/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 64.6347 - mae: 6.9444 - val_loss: 60.9242 - val_mae: 6.8420\n",
            "Epoch 5/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 51.7514 - mae: 6.2260 - val_loss: 44.4865 - val_mae: 5.8658\n",
            "Epoch 6/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 36.6750 - mae: 5.2580 - val_loss: 29.6361 - val_mae: 4.8378\n",
            "Epoch 7/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 24.3919 - mae: 4.3189 - val_loss: 19.7009 - val_mae: 4.0024\n",
            "Epoch 8/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 16.5628 - mae: 3.5902 - val_loss: 13.4613 - val_mae: 3.3204\n",
            "Epoch 9/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 11.7905 - mae: 3.0347 - val_loss: 9.7895 - val_mae: 2.7965\n",
            "Epoch 10/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9309 - mae: 2.6058 - val_loss: 7.5958 - val_mae: 2.3968\n",
            "Epoch 11/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 7.2054 - mae: 2.2823 - val_loss: 6.1904 - val_mae: 2.0888\n",
            "Epoch 12/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0611 - mae: 2.0409 - val_loss: 5.2619 - val_mae: 1.8578\n",
            "Epoch 13/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2467 - mae: 1.8433 - val_loss: 4.5692 - val_mae: 1.6780\n",
            "Epoch 14/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5882 - mae: 1.6748 - val_loss: 3.9775 - val_mae: 1.5194\n",
            "Epoch 15/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0104 - mae: 1.5294 - val_loss: 3.5020 - val_mae: 1.3962\n",
            "Epoch 16/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5270 - mae: 1.4104 - val_loss: 3.0844 - val_mae: 1.2985\n",
            "Epoch 17/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.1286 - mae: 1.3122 - val_loss: 2.7374 - val_mae: 1.2184\n",
            "Epoch 18/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7972 - mae: 1.2367 - val_loss: 2.4533 - val_mae: 1.1522\n",
            "Epoch 19/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5146 - mae: 1.1614 - val_loss: 2.2264 - val_mae: 1.0966\n",
            "Epoch 20/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2864 - mae: 1.1050 - val_loss: 2.0257 - val_mae: 1.0617\n",
            "Epoch 21/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0861 - mae: 1.0589 - val_loss: 1.8593 - val_mae: 1.0277\n",
            "Epoch 22/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9140 - mae: 1.0140 - val_loss: 1.7176 - val_mae: 0.9970\n",
            "Epoch 23/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7668 - mae: 0.9857 - val_loss: 1.5938 - val_mae: 0.9731\n",
            "Epoch 24/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6420 - mae: 0.9561 - val_loss: 1.4966 - val_mae: 0.9501\n",
            "Epoch 25/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5357 - mae: 0.9337 - val_loss: 1.4093 - val_mae: 0.9306\n",
            "Epoch 26/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4445 - mae: 0.9118 - val_loss: 1.3367 - val_mae: 0.9140\n",
            "Epoch 27/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3615 - mae: 0.8873 - val_loss: 1.2748 - val_mae: 0.8969\n",
            "Epoch 28/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2928 - mae: 0.8703 - val_loss: 1.2174 - val_mae: 0.8820\n",
            "Epoch 29/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2313 - mae: 0.8496 - val_loss: 1.1696 - val_mae: 0.8680\n",
            "Epoch 30/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1768 - mae: 0.8357 - val_loss: 1.1249 - val_mae: 0.8546\n",
            "Epoch 31/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1229 - mae: 0.8169 - val_loss: 1.0843 - val_mae: 0.8406\n",
            "Epoch 32/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0777 - mae: 0.8008 - val_loss: 1.0437 - val_mae: 0.8279\n",
            "Epoch 33/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0313 - mae: 0.7857 - val_loss: 1.0111 - val_mae: 0.8143\n",
            "Epoch 34/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9907 - mae: 0.7687 - val_loss: 0.9760 - val_mae: 0.7988\n",
            "Epoch 35/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9547 - mae: 0.7538 - val_loss: 0.9427 - val_mae: 0.7848\n",
            "Epoch 36/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9187 - mae: 0.7391 - val_loss: 0.9107 - val_mae: 0.7719\n",
            "Epoch 37/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8875 - mae: 0.7277 - val_loss: 0.8809 - val_mae: 0.7582\n",
            "Epoch 38/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.8515 - mae: 0.7104 - val_loss: 0.8479 - val_mae: 0.7421\n",
            "Epoch 39/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.8244 - mae: 0.6993 - val_loss: 0.8249 - val_mae: 0.7327\n",
            "Epoch 40/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7940 - mae: 0.6862 - val_loss: 0.7928 - val_mae: 0.7172\n",
            "Epoch 41/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7673 - mae: 0.6717 - val_loss: 0.7717 - val_mae: 0.7064\n",
            "Epoch 42/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7418 - mae: 0.6631 - val_loss: 0.7426 - val_mae: 0.6951\n",
            "Epoch 43/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7162 - mae: 0.6508 - val_loss: 0.7147 - val_mae: 0.6801\n",
            "Epoch 44/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6902 - mae: 0.6384 - val_loss: 0.6973 - val_mae: 0.6705\n",
            "Epoch 45/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6695 - mae: 0.6289 - val_loss: 0.6679 - val_mae: 0.6575\n",
            "Epoch 46/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6450 - mae: 0.6153 - val_loss: 0.6500 - val_mae: 0.6470\n",
            "Epoch 47/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6260 - mae: 0.6075 - val_loss: 0.6291 - val_mae: 0.6360\n",
            "Epoch 48/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6051 - mae: 0.5977 - val_loss: 0.6095 - val_mae: 0.6257\n",
            "Epoch 49/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5848 - mae: 0.5859 - val_loss: 0.5856 - val_mae: 0.6142\n",
            "Epoch 50/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5651 - mae: 0.5773 - val_loss: 0.5663 - val_mae: 0.6053\n",
            "Epoch 51/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5470 - mae: 0.5683 - val_loss: 0.5469 - val_mae: 0.5945\n",
            "Epoch 52/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5297 - mae: 0.5598 - val_loss: 0.5295 - val_mae: 0.5849\n",
            "Epoch 53/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5123 - mae: 0.5496 - val_loss: 0.5116 - val_mae: 0.5745\n",
            "Epoch 54/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4951 - mae: 0.5422 - val_loss: 0.4950 - val_mae: 0.5689\n",
            "Epoch 55/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4805 - mae: 0.5375 - val_loss: 0.4767 - val_mae: 0.5567\n",
            "Epoch 56/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4655 - mae: 0.5259 - val_loss: 0.4633 - val_mae: 0.5462\n",
            "Epoch 57/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4504 - mae: 0.5187 - val_loss: 0.4456 - val_mae: 0.5379\n",
            "Epoch 58/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4350 - mae: 0.5064 - val_loss: 0.4296 - val_mae: 0.5292\n",
            "Epoch 59/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4211 - mae: 0.4999 - val_loss: 0.4188 - val_mae: 0.5229\n",
            "Epoch 60/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4108 - mae: 0.4939 - val_loss: 0.4004 - val_mae: 0.5110\n",
            "Epoch 61/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3941 - mae: 0.4855 - val_loss: 0.3948 - val_mae: 0.5074\n",
            "Epoch 62/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3849 - mae: 0.4806 - val_loss: 0.3782 - val_mae: 0.4947\n",
            "Epoch 63/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3697 - mae: 0.4706 - val_loss: 0.3652 - val_mae: 0.4871\n",
            "Epoch 64/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3599 - mae: 0.4611 - val_loss: 0.3527 - val_mae: 0.4770\n",
            "Epoch 65/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3477 - mae: 0.4575 - val_loss: 0.3425 - val_mae: 0.4761\n",
            "Epoch 66/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3363 - mae: 0.4491 - val_loss: 0.3327 - val_mae: 0.4622\n",
            "Epoch 67/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3261 - mae: 0.4380 - val_loss: 0.3193 - val_mae: 0.4521\n",
            "Epoch 68/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3157 - mae: 0.4349 - val_loss: 0.3100 - val_mae: 0.4464\n",
            "Epoch 69/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3057 - mae: 0.4275 - val_loss: 0.2935 - val_mae: 0.4342\n",
            "Epoch 70/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2957 - mae: 0.4214 - val_loss: 0.2895 - val_mae: 0.4320\n",
            "Epoch 71/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2852 - mae: 0.4121 - val_loss: 0.2754 - val_mae: 0.4197\n",
            "Epoch 72/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2769 - mae: 0.4079 - val_loss: 0.2714 - val_mae: 0.4173\n",
            "Epoch 73/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2676 - mae: 0.4005 - val_loss: 0.2566 - val_mae: 0.4019\n",
            "Epoch 74/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2579 - mae: 0.3923 - val_loss: 0.2493 - val_mae: 0.4003\n",
            "Epoch 75/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2504 - mae: 0.3883 - val_loss: 0.2425 - val_mae: 0.3910\n",
            "Epoch 76/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2434 - mae: 0.3820 - val_loss: 0.2327 - val_mae: 0.3833\n",
            "Epoch 77/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2351 - mae: 0.3713 - val_loss: 0.2266 - val_mae: 0.3777\n",
            "Epoch 78/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2265 - mae: 0.3680 - val_loss: 0.2176 - val_mae: 0.3705\n",
            "Epoch 79/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2181 - mae: 0.3602 - val_loss: 0.2095 - val_mae: 0.3607\n",
            "Epoch 80/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2115 - mae: 0.3555 - val_loss: 0.2007 - val_mae: 0.3523\n",
            "Epoch 81/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2049 - mae: 0.3488 - val_loss: 0.1935 - val_mae: 0.3456\n",
            "Epoch 82/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1994 - mae: 0.3409 - val_loss: 0.1898 - val_mae: 0.3432\n",
            "Epoch 83/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1913 - mae: 0.3345 - val_loss: 0.1806 - val_mae: 0.3278\n",
            "Epoch 84/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1855 - mae: 0.3317 - val_loss: 0.1729 - val_mae: 0.3267\n",
            "Epoch 85/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1769 - mae: 0.3217 - val_loss: 0.1677 - val_mae: 0.3168\n",
            "Epoch 86/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1722 - mae: 0.3184 - val_loss: 0.1663 - val_mae: 0.3174\n",
            "Epoch 87/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1661 - mae: 0.3127 - val_loss: 0.1555 - val_mae: 0.3069\n",
            "Epoch 88/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1599 - mae: 0.3068 - val_loss: 0.1457 - val_mae: 0.2955\n",
            "Epoch 89/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1538 - mae: 0.2984 - val_loss: 0.1420 - val_mae: 0.2899\n",
            "Epoch 90/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1494 - mae: 0.2938 - val_loss: 0.1379 - val_mae: 0.2877\n",
            "Epoch 91/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1433 - mae: 0.2866 - val_loss: 0.1328 - val_mae: 0.2826\n",
            "Epoch 92/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1372 - mae: 0.2823 - val_loss: 0.1269 - val_mae: 0.2746\n",
            "Epoch 93/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1339 - mae: 0.2767 - val_loss: 0.1242 - val_mae: 0.2668\n",
            "Epoch 94/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1286 - mae: 0.2722 - val_loss: 0.1160 - val_mae: 0.2602\n",
            "Epoch 95/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1242 - mae: 0.2667 - val_loss: 0.1118 - val_mae: 0.2541\n",
            "Epoch 96/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1196 - mae: 0.2598 - val_loss: 0.1096 - val_mae: 0.2511\n",
            "Epoch 97/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1153 - mae: 0.2580 - val_loss: 0.1040 - val_mae: 0.2470\n",
            "Epoch 98/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1126 - mae: 0.2501 - val_loss: 0.1006 - val_mae: 0.2418\n",
            "Epoch 99/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1073 - mae: 0.2504 - val_loss: 0.0982 - val_mae: 0.2336\n",
            "Epoch 100/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1047 - mae: 0.2401 - val_loss: 0.0977 - val_mae: 0.2350\n",
            "Epoch 101/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1014 - mae: 0.2387 - val_loss: 0.0898 - val_mae: 0.2217\n",
            "Epoch 102/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0967 - mae: 0.2318 - val_loss: 0.0858 - val_mae: 0.2191\n",
            "Epoch 103/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0938 - mae: 0.2281 - val_loss: 0.0837 - val_mae: 0.2167\n",
            "Epoch 104/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0905 - mae: 0.2253 - val_loss: 0.0803 - val_mae: 0.2089\n",
            "Epoch 105/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0892 - mae: 0.2224 - val_loss: 0.0784 - val_mae: 0.2054\n",
            "Epoch 106/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0860 - mae: 0.2135 - val_loss: 0.0771 - val_mae: 0.2089\n",
            "Epoch 107/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0820 - mae: 0.2147 - val_loss: 0.0735 - val_mae: 0.1995\n",
            "Epoch 108/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0791 - mae: 0.2044 - val_loss: 0.0693 - val_mae: 0.1962\n",
            "Epoch 109/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0770 - mae: 0.2069 - val_loss: 0.0687 - val_mae: 0.1900\n",
            "Epoch 110/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0745 - mae: 0.1987 - val_loss: 0.0664 - val_mae: 0.1906\n",
            "Epoch 111/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0719 - mae: 0.1989 - val_loss: 0.0634 - val_mae: 0.1860\n",
            "Epoch 112/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0703 - mae: 0.1957 - val_loss: 0.0631 - val_mae: 0.1878\n",
            "Epoch 113/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0683 - mae: 0.1918 - val_loss: 0.0611 - val_mae: 0.1818\n",
            "Epoch 114/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0671 - mae: 0.1913 - val_loss: 0.0602 - val_mae: 0.1771\n",
            "Epoch 115/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0650 - mae: 0.1855 - val_loss: 0.0586 - val_mae: 0.1780\n",
            "Epoch 116/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0628 - mae: 0.1832 - val_loss: 0.0568 - val_mae: 0.1734\n",
            "Epoch 117/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0614 - mae: 0.1834 - val_loss: 0.0547 - val_mae: 0.1723\n",
            "Epoch 118/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0594 - mae: 0.1803 - val_loss: 0.0523 - val_mae: 0.1653\n",
            "Epoch 119/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0592 - mae: 0.1781 - val_loss: 0.0529 - val_mae: 0.1639\n",
            "Epoch 120/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0563 - mae: 0.1720 - val_loss: 0.0499 - val_mae: 0.1621\n",
            "Epoch 121/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0548 - mae: 0.1700 - val_loss: 0.0483 - val_mae: 0.1565\n",
            "Epoch 122/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0538 - mae: 0.1696 - val_loss: 0.0480 - val_mae: 0.1603\n",
            "Epoch 123/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0524 - mae: 0.1670 - val_loss: 0.0474 - val_mae: 0.1512\n",
            "Epoch 124/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0532 - mae: 0.1661 - val_loss: 0.0476 - val_mae: 0.1590\n",
            "Epoch 125/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0504 - mae: 0.1620 - val_loss: 0.0458 - val_mae: 0.1537\n",
            "Epoch 126/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.1654 - val_loss: 0.0430 - val_mae: 0.1493\n",
            "Epoch 127/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.1605 - val_loss: 0.0445 - val_mae: 0.1536\n",
            "Epoch 128/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.1580 - val_loss: 0.0424 - val_mae: 0.1480\n",
            "Epoch 129/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.1576 - val_loss: 0.0411 - val_mae: 0.1441\n",
            "Epoch 130/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0462 - mae: 0.1554 - val_loss: 0.0419 - val_mae: 0.1430\n",
            "Epoch 131/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0452 - mae: 0.1533 - val_loss: 0.0411 - val_mae: 0.1433\n",
            "Epoch 132/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1529 - val_loss: 0.0401 - val_mae: 0.1435\n",
            "Epoch 133/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1516 - val_loss: 0.0392 - val_mae: 0.1393\n",
            "Epoch 134/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1496 - val_loss: 0.0397 - val_mae: 0.1416\n",
            "Epoch 135/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1500 - val_loss: 0.0418 - val_mae: 0.1467\n",
            "Epoch 136/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1503 - val_loss: 0.0379 - val_mae: 0.1345\n",
            "Epoch 137/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1449 - val_loss: 0.0405 - val_mae: 0.1413\n",
            "Epoch 138/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1483 - val_loss: 0.0360 - val_mae: 0.1311\n",
            "Epoch 139/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1453 - val_loss: 0.0361 - val_mae: 0.1326\n",
            "Epoch 140/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1417 - val_loss: 0.0369 - val_mae: 0.1374\n",
            "Epoch 141/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1428 - val_loss: 0.0360 - val_mae: 0.1289\n",
            "Epoch 142/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1397 - val_loss: 0.0342 - val_mae: 0.1292\n",
            "Epoch 143/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1400 - val_loss: 0.0358 - val_mae: 0.1294\n",
            "Epoch 144/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1400 - val_loss: 0.0342 - val_mae: 0.1303\n",
            "Epoch 145/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1359 - val_loss: 0.0338 - val_mae: 0.1324\n",
            "Epoch 146/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1347 - val_loss: 0.0318 - val_mae: 0.1259\n",
            "Epoch 147/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1375 - val_loss: 0.0355 - val_mae: 0.1280\n",
            "Epoch 148/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1384 - val_loss: 0.0320 - val_mae: 0.1254\n",
            "Epoch 149/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0339 - mae: 0.1344 - val_loss: 0.0308 - val_mae: 0.1211\n",
            "Epoch 150/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0335 - mae: 0.1323 - val_loss: 0.0336 - val_mae: 0.1269\n",
            "Epoch 151/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1328 - val_loss: 0.0306 - val_mae: 0.1216\n",
            "Epoch 152/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1299 - val_loss: 0.0307 - val_mae: 0.1212\n",
            "Epoch 153/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.1301 - val_loss: 0.0298 - val_mae: 0.1182\n",
            "Epoch 154/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1283 - val_loss: 0.0300 - val_mae: 0.1189\n",
            "Epoch 155/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0305 - mae: 0.1275 - val_loss: 0.0300 - val_mae: 0.1206\n",
            "Epoch 156/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1301 - val_loss: 0.0312 - val_mae: 0.1190\n",
            "Epoch 157/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0309 - mae: 0.1277 - val_loss: 0.0279 - val_mae: 0.1180\n",
            "Epoch 158/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1290 - val_loss: 0.0298 - val_mae: 0.1246\n",
            "Epoch 159/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1261 - val_loss: 0.0283 - val_mae: 0.1173\n",
            "Epoch 160/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0295 - mae: 0.1255 - val_loss: 0.0285 - val_mae: 0.1186\n",
            "Epoch 161/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1255 - val_loss: 0.0272 - val_mae: 0.1156\n",
            "Epoch 162/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1237 - val_loss: 0.0263 - val_mae: 0.1135\n",
            "Epoch 163/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1257 - val_loss: 0.0297 - val_mae: 0.1222\n",
            "Epoch 164/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1229 - val_loss: 0.0273 - val_mae: 0.1183\n",
            "Epoch 165/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0269 - mae: 0.1206 - val_loss: 0.0263 - val_mae: 0.1113\n",
            "Epoch 166/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1242 - val_loss: 0.0273 - val_mae: 0.1146\n",
            "Epoch 167/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0271 - mae: 0.1223 - val_loss: 0.0258 - val_mae: 0.1145\n",
            "Epoch 168/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1197 - val_loss: 0.0251 - val_mae: 0.1121\n",
            "Epoch 169/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0258 - mae: 0.1199 - val_loss: 0.0251 - val_mae: 0.1149\n",
            "Epoch 170/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.1203 - val_loss: 0.0249 - val_mae: 0.1133\n",
            "Epoch 171/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0245 - mae: 0.1161 - val_loss: 0.0252 - val_mae: 0.1139\n",
            "Epoch 172/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1188 - val_loss: 0.0255 - val_mae: 0.1147\n",
            "Epoch 173/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.1179 - val_loss: 0.0244 - val_mae: 0.1129\n",
            "Epoch 174/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.1175 - val_loss: 0.0231 - val_mae: 0.1086\n",
            "Epoch 175/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.1168 - val_loss: 0.0234 - val_mae: 0.1099\n",
            "Epoch 176/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0237 - mae: 0.1148 - val_loss: 0.0224 - val_mae: 0.1083\n",
            "Epoch 177/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.1186 - val_loss: 0.0234 - val_mae: 0.1123\n",
            "Epoch 178/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.1166 - val_loss: 0.0235 - val_mae: 0.1125\n",
            "Epoch 179/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.1137 - val_loss: 0.0220 - val_mae: 0.1102\n",
            "Epoch 180/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0241 - mae: 0.1175 - val_loss: 0.0241 - val_mae: 0.1108\n",
            "Epoch 181/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0229 - mae: 0.1152 - val_loss: 0.0246 - val_mae: 0.1129\n",
            "Epoch 182/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0228 - mae: 0.1138 - val_loss: 0.0217 - val_mae: 0.1067\n",
            "Epoch 183/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0220 - mae: 0.1103 - val_loss: 0.0230 - val_mae: 0.1103\n",
            "Epoch 184/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.1086 - val_loss: 0.0226 - val_mae: 0.1135\n",
            "Epoch 185/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0212 - mae: 0.1089 - val_loss: 0.0204 - val_mae: 0.1064\n",
            "Epoch 186/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.1116 - val_loss: 0.0226 - val_mae: 0.1081\n",
            "Epoch 187/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.1124 - val_loss: 0.0204 - val_mae: 0.1087\n",
            "Epoch 188/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0209 - mae: 0.1080 - val_loss: 0.0196 - val_mae: 0.1033\n",
            "Epoch 189/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0200 - mae: 0.1077 - val_loss: 0.0190 - val_mae: 0.1021\n",
            "Epoch 190/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.1079 - val_loss: 0.0206 - val_mae: 0.1047\n",
            "Epoch 191/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.1077 - val_loss: 0.0220 - val_mae: 0.1081\n",
            "Epoch 192/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.1095 - val_loss: 0.0201 - val_mae: 0.1035\n",
            "Epoch 193/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.1067 - val_loss: 0.0184 - val_mae: 0.1033\n",
            "Epoch 194/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.1044 - val_loss: 0.0196 - val_mae: 0.1038\n",
            "Epoch 195/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1058 - val_loss: 0.0179 - val_mae: 0.1030\n",
            "Epoch 196/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.1056 - val_loss: 0.0179 - val_mae: 0.1020\n",
            "Epoch 197/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.1023 - val_loss: 0.0181 - val_mae: 0.1023\n",
            "Epoch 198/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.1047 - val_loss: 0.0181 - val_mae: 0.1027\n",
            "Epoch 199/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.1032 - val_loss: 0.0174 - val_mae: 0.0978\n",
            "Epoch 200/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.1037 - val_loss: 0.0167 - val_mae: 0.0975\n",
            "Epoch 201/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.1022 - val_loss: 0.0176 - val_mae: 0.1001\n",
            "Epoch 202/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.1023 - val_loss: 0.0180 - val_mae: 0.1019\n",
            "Epoch 203/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.1033 - val_loss: 0.0187 - val_mae: 0.1012\n",
            "Epoch 204/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0999 - val_loss: 0.0185 - val_mae: 0.1048\n",
            "Epoch 205/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.1006 - val_loss: 0.0183 - val_mae: 0.1008\n",
            "Epoch 206/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0991 - val_loss: 0.0159 - val_mae: 0.0946\n",
            "Epoch 207/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.1007 - val_loss: 0.0155 - val_mae: 0.0962\n",
            "Epoch 208/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0994 - val_loss: 0.0166 - val_mae: 0.0967\n",
            "Epoch 209/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0979 - val_loss: 0.0172 - val_mae: 0.0982\n",
            "Epoch 210/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0960 - val_loss: 0.0151 - val_mae: 0.0940\n",
            "Epoch 211/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0942 - val_loss: 0.0152 - val_mae: 0.0934\n",
            "Epoch 212/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0934 - val_loss: 0.0157 - val_mae: 0.0972\n",
            "Epoch 213/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0946 - val_loss: 0.0152 - val_mae: 0.0926\n",
            "Epoch 214/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0952 - val_loss: 0.0161 - val_mae: 0.0960\n",
            "Epoch 215/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0941 - val_loss: 0.0149 - val_mae: 0.0928\n",
            "Epoch 216/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0952 - val_loss: 0.0155 - val_mae: 0.0945\n",
            "Epoch 217/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0945 - val_loss: 0.0147 - val_mae: 0.0911\n",
            "Epoch 218/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0942 - val_loss: 0.0141 - val_mae: 0.0909\n",
            "Epoch 219/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0952 - val_loss: 0.0149 - val_mae: 0.0959\n",
            "Epoch 220/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0929 - val_loss: 0.0156 - val_mae: 0.0953\n",
            "Epoch 221/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0912 - val_loss: 0.0133 - val_mae: 0.0893\n",
            "Epoch 222/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0901 - val_loss: 0.0132 - val_mae: 0.0890\n",
            "Epoch 223/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0891 - val_loss: 0.0131 - val_mae: 0.0869\n",
            "Epoch 224/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0891 - val_loss: 0.0135 - val_mae: 0.0901\n",
            "Epoch 225/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0886 - val_loss: 0.0125 - val_mae: 0.0871\n",
            "Epoch 226/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0121 - val_mae: 0.0842\n",
            "Epoch 227/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0891 - val_loss: 0.0127 - val_mae: 0.0867\n",
            "Epoch 228/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0890 - val_loss: 0.0122 - val_mae: 0.0863\n",
            "Epoch 229/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0862 - val_loss: 0.0124 - val_mae: 0.0868\n",
            "Epoch 230/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0885 - val_loss: 0.0142 - val_mae: 0.0919\n",
            "Epoch 231/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0119 - val_mae: 0.0846\n",
            "Epoch 232/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0848 - val_loss: 0.0124 - val_mae: 0.0869\n",
            "Epoch 233/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0844 - val_loss: 0.0112 - val_mae: 0.0818\n",
            "Epoch 234/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0849 - val_loss: 0.0124 - val_mae: 0.0860\n",
            "Epoch 235/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0852 - val_loss: 0.0118 - val_mae: 0.0833\n",
            "Epoch 236/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0832 - val_loss: 0.0145 - val_mae: 0.0946\n",
            "Epoch 237/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0867 - val_loss: 0.0110 - val_mae: 0.0818\n",
            "Epoch 238/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0855 - val_loss: 0.0111 - val_mae: 0.0810\n",
            "Epoch 239/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0832 - val_loss: 0.0106 - val_mae: 0.0805\n",
            "Epoch 240/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0838 - val_loss: 0.0112 - val_mae: 0.0824\n",
            "Epoch 241/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0800 - val_loss: 0.0125 - val_mae: 0.0857\n",
            "Epoch 242/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0822 - val_loss: 0.0118 - val_mae: 0.0830\n",
            "Epoch 243/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0821 - val_loss: 0.0112 - val_mae: 0.0834\n",
            "Epoch 244/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0829 - val_loss: 0.0102 - val_mae: 0.0791\n",
            "Epoch 245/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0786 - val_loss: 0.0105 - val_mae: 0.0793\n",
            "Epoch 246/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0812 - val_loss: 0.0105 - val_mae: 0.0789\n",
            "Epoch 247/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0805 - val_loss: 0.0114 - val_mae: 0.0844\n",
            "Epoch 248/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0819 - val_loss: 0.0091 - val_mae: 0.0746\n",
            "Epoch 249/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0809 - val_loss: 0.0098 - val_mae: 0.0766\n",
            "Epoch 250/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0773 - val_loss: 0.0093 - val_mae: 0.0750\n",
            "Epoch 251/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0747 - val_loss: 0.0105 - val_mae: 0.0793\n",
            "Epoch 252/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0770 - val_loss: 0.0093 - val_mae: 0.0746\n",
            "Epoch 253/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0771 - val_loss: 0.0106 - val_mae: 0.0803\n",
            "Epoch 254/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0768 - val_loss: 0.0098 - val_mae: 0.0775\n",
            "Epoch 255/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0756 - val_loss: 0.0110 - val_mae: 0.0815\n",
            "Epoch 256/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0759 - val_loss: 0.0090 - val_mae: 0.0736\n",
            "Epoch 257/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0742 - val_loss: 0.0090 - val_mae: 0.0737\n",
            "Epoch 258/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0736 - val_loss: 0.0120 - val_mae: 0.0842\n",
            "Epoch 259/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0102 - val_mae: 0.0772\n",
            "Epoch 260/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0763 - val_loss: 0.0094 - val_mae: 0.0747\n",
            "Epoch 261/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0722 - val_loss: 0.0089 - val_mae: 0.0732\n",
            "Epoch 262/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0728 - val_loss: 0.0085 - val_mae: 0.0729\n",
            "Epoch 263/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0708 - val_loss: 0.0088 - val_mae: 0.0729\n",
            "Epoch 264/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0734 - val_loss: 0.0086 - val_mae: 0.0748\n",
            "Epoch 265/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0729 - val_loss: 0.0079 - val_mae: 0.0694\n",
            "Epoch 266/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0739 - val_loss: 0.0078 - val_mae: 0.0689\n",
            "Epoch 267/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0702 - val_loss: 0.0084 - val_mae: 0.0714\n",
            "Epoch 268/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0699 - val_loss: 0.0077 - val_mae: 0.0690\n",
            "Epoch 269/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0692 - val_loss: 0.0082 - val_mae: 0.0705\n",
            "Epoch 270/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0695 - val_loss: 0.0099 - val_mae: 0.0763\n",
            "Epoch 271/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0713 - val_loss: 0.0098 - val_mae: 0.0755\n",
            "Epoch 272/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0692 - val_loss: 0.0075 - val_mae: 0.0681\n",
            "Epoch 273/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0707 - val_loss: 0.0073 - val_mae: 0.0673\n",
            "Epoch 274/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0685 - val_loss: 0.0069 - val_mae: 0.0657\n",
            "Epoch 275/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0685 - val_loss: 0.0093 - val_mae: 0.0744\n",
            "Epoch 276/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0685 - val_loss: 0.0070 - val_mae: 0.0656\n",
            "Epoch 277/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0685 - val_loss: 0.0079 - val_mae: 0.0701\n",
            "Epoch 278/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0685 - val_loss: 0.0083 - val_mae: 0.0704\n",
            "Epoch 279/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0669 - val_loss: 0.0067 - val_mae: 0.0644\n",
            "Epoch 280/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0066 - mae: 0.0643 - val_loss: 0.0067 - val_mae: 0.0647\n",
            "Epoch 281/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0655 - val_loss: 0.0068 - val_mae: 0.0651\n",
            "Epoch 282/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0648 - val_loss: 0.0063 - val_mae: 0.0617\n",
            "Epoch 283/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0640 - val_loss: 0.0065 - val_mae: 0.0633\n",
            "Epoch 284/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0653 - val_loss: 0.0065 - val_mae: 0.0644\n",
            "Epoch 285/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0632 - val_loss: 0.0078 - val_mae: 0.0696\n",
            "Epoch 286/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0745 - val_loss: 0.0073 - val_mae: 0.0677\n",
            "Epoch 287/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0070 - mae: 0.0657 - val_loss: 0.0081 - val_mae: 0.0712\n",
            "Epoch 288/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0653 - val_loss: 0.0064 - val_mae: 0.0628\n",
            "Epoch 289/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0635 - val_loss: 0.0079 - val_mae: 0.0700\n",
            "Epoch 290/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0674 - val_loss: 0.0059 - val_mae: 0.0603\n",
            "Epoch 291/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0611 - val_loss: 0.0060 - val_mae: 0.0618\n",
            "Epoch 292/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0636 - val_loss: 0.0061 - val_mae: 0.0623\n",
            "Epoch 293/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0603 - val_loss: 0.0068 - val_mae: 0.0651\n",
            "Epoch 294/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0604 - val_loss: 0.0068 - val_mae: 0.0628\n",
            "Epoch 295/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0616 - val_loss: 0.0062 - val_mae: 0.0617\n",
            "Epoch 296/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0587 - val_loss: 0.0063 - val_mae: 0.0628\n",
            "Epoch 297/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0640 - val_loss: 0.0066 - val_mae: 0.0642\n",
            "Epoch 298/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0620 - val_loss: 0.0079 - val_mae: 0.0700\n",
            "Epoch 299/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0645 - val_loss: 0.0067 - val_mae: 0.0653\n",
            "Epoch 300/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0594 - val_loss: 0.0072 - val_mae: 0.0666\n",
            "Epoch 301/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0620 - val_loss: 0.0059 - val_mae: 0.0617\n",
            "Epoch 302/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0582 - val_loss: 0.0061 - val_mae: 0.0607\n",
            "Epoch 303/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0589 - val_loss: 0.0052 - val_mae: 0.0586\n",
            "Epoch 304/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0580 - val_loss: 0.0066 - val_mae: 0.0638\n",
            "Epoch 305/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0598 - val_loss: 0.0055 - val_mae: 0.0601\n",
            "Epoch 306/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0613 - val_loss: 0.0058 - val_mae: 0.0593\n",
            "Epoch 307/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0578 - val_loss: 0.0060 - val_mae: 0.0610\n",
            "Epoch 308/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0606 - val_loss: 0.0050 - val_mae: 0.0572\n",
            "Epoch 309/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0598 - val_loss: 0.0054 - val_mae: 0.0581\n",
            "Epoch 310/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0576 - val_loss: 0.0051 - val_mae: 0.0583\n",
            "Epoch 311/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0544 - val_loss: 0.0050 - val_mae: 0.0565\n",
            "Epoch 312/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0572 - val_loss: 0.0045 - val_mae: 0.0549\n",
            "Epoch 313/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0538 - val_loss: 0.0050 - val_mae: 0.0553\n",
            "Epoch 314/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0566 - val_loss: 0.0052 - val_mae: 0.0576\n",
            "Epoch 315/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0563 - val_loss: 0.0045 - val_mae: 0.0547\n",
            "Epoch 316/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0549 - val_loss: 0.0055 - val_mae: 0.0576\n",
            "Epoch 317/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0586 - val_loss: 0.0053 - val_mae: 0.0581\n",
            "Epoch 318/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0548\n",
            "Epoch 319/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0551 - val_loss: 0.0043 - val_mae: 0.0520\n",
            "Epoch 320/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0546 - val_loss: 0.0051 - val_mae: 0.0554\n",
            "Epoch 321/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0549 - val_loss: 0.0058 - val_mae: 0.0597\n",
            "Epoch 322/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0558 - val_loss: 0.0043 - val_mae: 0.0518\n",
            "Epoch 323/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0049 - mae: 0.0547 - val_loss: 0.0040 - val_mae: 0.0517\n",
            "Epoch 324/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0535 - val_loss: 0.0046 - val_mae: 0.0546\n",
            "Epoch 325/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0530 - val_loss: 0.0042 - val_mae: 0.0522\n",
            "Epoch 326/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0513 - val_loss: 0.0058 - val_mae: 0.0600\n",
            "Epoch 327/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0521 - val_loss: 0.0071 - val_mae: 0.0627\n",
            "Epoch 328/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0532 - val_loss: 0.0042 - val_mae: 0.0515\n",
            "Epoch 329/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0516 - val_loss: 0.0045 - val_mae: 0.0517\n",
            "Epoch 330/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0046 - mae: 0.0524 - val_loss: 0.0062 - val_mae: 0.0636\n",
            "Epoch 331/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0547 - val_loss: 0.0039 - val_mae: 0.0493\n",
            "Epoch 332/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0053 - val_mae: 0.0582\n",
            "Epoch 333/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0044 - val_mae: 0.0536\n",
            "Epoch 334/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0500 - val_loss: 0.0046 - val_mae: 0.0525\n",
            "Epoch 335/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0507 - val_loss: 0.0054 - val_mae: 0.0577\n",
            "Epoch 336/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0508\n",
            "Epoch 337/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0034 - val_mae: 0.0485\n",
            "Epoch 338/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0045 - val_mae: 0.0527\n",
            "Epoch 339/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0524\n",
            "Epoch 340/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0476 - val_loss: 0.0035 - val_mae: 0.0490\n",
            "Epoch 341/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0048 - val_mae: 0.0553\n",
            "Epoch 342/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0044 - val_mae: 0.0535\n",
            "Epoch 343/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0507 - val_loss: 0.0035 - val_mae: 0.0483\n",
            "Epoch 344/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0049 - val_mae: 0.0562\n",
            "Epoch 345/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0560 - val_loss: 0.0049 - val_mae: 0.0565\n",
            "Epoch 346/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0509\n",
            "Epoch 347/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0534 - val_loss: 0.0046 - val_mae: 0.0531\n",
            "Epoch 348/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0486\n",
            "Epoch 349/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0049 - val_mae: 0.0524\n",
            "Epoch 350/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0524 - val_loss: 0.0042 - val_mae: 0.0509\n",
            "Epoch 351/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0032 - val_mae: 0.0441\n",
            "Epoch 352/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0031 - val_mae: 0.0447\n",
            "Epoch 353/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0503\n",
            "Epoch 354/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0549 - val_loss: 0.0066 - val_mae: 0.0642\n",
            "Epoch 355/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0030 - val_mae: 0.0459\n",
            "Epoch 356/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0492\n",
            "Epoch 357/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0452 - val_loss: 0.0037 - val_mae: 0.0478\n",
            "Epoch 358/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0038 - val_mae: 0.0489\n",
            "Epoch 359/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0035 - val_mae: 0.0467\n",
            "Epoch 360/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0464 - val_loss: 0.0037 - val_mae: 0.0492\n",
            "Epoch 361/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 0.0032 - val_mae: 0.0452\n",
            "Epoch 362/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0426 - val_loss: 0.0036 - val_mae: 0.0484\n",
            "Epoch 363/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0050 - val_mae: 0.0555\n",
            "Epoch 364/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0044 - val_mae: 0.0525\n",
            "Epoch 365/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0465 - val_loss: 0.0033 - val_mae: 0.0456\n",
            "Epoch 366/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0461 - val_loss: 0.0040 - val_mae: 0.0493\n",
            "Epoch 367/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0470 - val_loss: 0.0031 - val_mae: 0.0435\n",
            "Epoch 368/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0033 - val_mae: 0.0458\n",
            "Epoch 369/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0031 - val_mae: 0.0442\n",
            "Epoch 370/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0032 - val_mae: 0.0460\n",
            "Epoch 371/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0031 - val_mae: 0.0443\n",
            "Epoch 372/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0033 - val_mae: 0.0454\n",
            "Epoch 373/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0029 - val_mae: 0.0428\n",
            "Epoch 374/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.0034 - val_mae: 0.0462\n",
            "Epoch 375/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0031 - val_mae: 0.0440\n",
            "Epoch 376/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0033 - val_mae: 0.0454\n",
            "Epoch 377/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0037 - val_mae: 0.0473\n",
            "Epoch 378/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0502\n",
            "Epoch 379/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0460 - val_loss: 0.0049 - val_mae: 0.0555\n",
            "Epoch 380/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0026 - val_mae: 0.0424\n",
            "Epoch 381/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0035 - val_mae: 0.0465\n",
            "Epoch 382/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0460 - val_loss: 0.0034 - val_mae: 0.0447\n",
            "Epoch 383/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0443 - val_loss: 0.0034 - val_mae: 0.0470\n",
            "Epoch 384/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0034 - val_mae: 0.0461\n",
            "Epoch 385/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0029 - val_mae: 0.0436\n",
            "Epoch 386/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0036 - val_mae: 0.0461\n",
            "Epoch 387/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0025 - val_mae: 0.0398\n",
            "Epoch 388/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0030 - val_mae: 0.0433\n",
            "Epoch 389/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0427 - val_loss: 0.0031 - val_mae: 0.0427\n",
            "Epoch 390/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0026 - val_mae: 0.0422\n",
            "Epoch 391/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0035 - val_mae: 0.0459\n",
            "Epoch 392/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0040 - val_mae: 0.0502\n",
            "Epoch 393/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0026 - val_mae: 0.0403\n",
            "Epoch 394/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0024 - val_mae: 0.0389\n",
            "Epoch 395/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0415 - val_loss: 0.0025 - val_mae: 0.0400\n",
            "Epoch 396/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0030 - val_mae: 0.0437\n",
            "Epoch 397/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0024 - val_mae: 0.0397\n",
            "Epoch 398/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0032 - val_mae: 0.0453\n",
            "Epoch 399/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0028 - val_mae: 0.0429\n",
            "Epoch 400/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0456 - val_loss: 0.0032 - val_mae: 0.0447\n",
            "Epoch 401/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0028 - val_mae: 0.0409\n",
            "Epoch 402/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0455\n",
            "Epoch 403/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0443 - val_loss: 0.0023 - val_mae: 0.0379\n",
            "Epoch 404/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0024 - val_mae: 0.0373\n",
            "Epoch 405/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0029 - val_mae: 0.0425\n",
            "Epoch 406/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0379\n",
            "Epoch 407/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0024 - val_mae: 0.0386\n",
            "Epoch 408/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0385 - val_loss: 0.0024 - val_mae: 0.0396\n",
            "Epoch 409/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0024 - val_mae: 0.0398\n",
            "Epoch 410/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0019 - val_mae: 0.0348\n",
            "Epoch 411/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0365 - val_loss: 0.0023 - val_mae: 0.0391\n",
            "Epoch 412/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0031 - val_mae: 0.0416\n",
            "Epoch 413/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0026 - val_mae: 0.0402\n",
            "Epoch 414/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0416 - val_loss: 0.0022 - val_mae: 0.0380\n",
            "Epoch 415/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0431 - val_loss: 0.0034 - val_mae: 0.0442\n",
            "Epoch 416/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0018 - val_mae: 0.0346\n",
            "Epoch 417/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0350 - val_loss: 0.0029 - val_mae: 0.0407\n",
            "Epoch 418/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0018 - val_mae: 0.0344\n",
            "Epoch 419/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0048 - val_mae: 0.0545\n",
            "Epoch 420/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0017 - val_mae: 0.0335\n",
            "Epoch 421/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0362 - val_loss: 0.0016 - val_mae: 0.0325\n",
            "Epoch 422/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0020 - val_mae: 0.0354\n",
            "Epoch 423/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0353 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 424/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0354 - val_loss: 0.0022 - val_mae: 0.0368\n",
            "Epoch 425/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0022 - val_mae: 0.0383\n",
            "Epoch 426/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0020 - val_mae: 0.0355\n",
            "Epoch 427/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0372 - val_loss: 0.0030 - val_mae: 0.0401\n",
            "Epoch 428/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0027 - val_mae: 0.0398\n",
            "Epoch 429/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0018 - val_mae: 0.0340\n",
            "Epoch 430/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0020 - val_mae: 0.0357\n",
            "Epoch 431/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0021 - val_mae: 0.0366\n",
            "Epoch 432/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0377 - val_loss: 0.0023 - val_mae: 0.0372\n",
            "Epoch 433/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0057 - val_mae: 0.0583\n",
            "Epoch 434/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0028 - val_mae: 0.0417\n",
            "Epoch 435/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0358\n",
            "Epoch 436/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0020 - val_mae: 0.0353\n",
            "Epoch 437/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0017 - val_mae: 0.0335\n",
            "Epoch 438/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0341 - val_loss: 0.0035 - val_mae: 0.0435\n",
            "Epoch 439/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0027 - val_mae: 0.0406\n",
            "Epoch 440/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0028 - val_mae: 0.0405\n",
            "Epoch 441/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0018 - val_mae: 0.0340\n",
            "Epoch 442/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0348 - val_loss: 0.0015 - val_mae: 0.0309\n",
            "Epoch 443/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0313 - val_loss: 0.0021 - val_mae: 0.0375\n",
            "Epoch 444/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0017 - val_mae: 0.0318\n",
            "Epoch 445/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0028 - val_mae: 0.0422\n",
            "Epoch 446/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0020 - val_mae: 0.0365\n",
            "Epoch 447/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0314 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 448/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0034 - val_mae: 0.0447\n",
            "Epoch 449/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 450/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0319 - val_loss: 0.0017 - val_mae: 0.0318\n",
            "Epoch 451/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0306 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 452/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0018 - val_mae: 0.0330\n",
            "Epoch 453/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0021 - val_mae: 0.0360\n",
            "Epoch 454/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0336 - val_loss: 0.0022 - val_mae: 0.0364\n",
            "Epoch 455/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0324 - val_loss: 0.0017 - val_mae: 0.0331\n",
            "Epoch 456/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0021 - val_mae: 0.0347\n",
            "Epoch 457/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0025 - val_mae: 0.0382\n",
            "Epoch 458/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 459/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 0.0020 - val_mae: 0.0356\n",
            "Epoch 460/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0327 - val_loss: 0.0012 - val_mae: 0.0287\n",
            "Epoch 461/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0018 - val_mae: 0.0329\n",
            "Epoch 462/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0022 - val_mae: 0.0374\n",
            "Epoch 463/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0022 - val_mae: 0.0371\n",
            "Epoch 464/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0016 - val_mae: 0.0322\n",
            "Epoch 465/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0020 - val_mae: 0.0357\n",
            "Epoch 466/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0016 - val_mae: 0.0320\n",
            "Epoch 467/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0341 - val_loss: 0.0014 - val_mae: 0.0299\n",
            "Epoch 468/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0314 - val_loss: 0.0019 - val_mae: 0.0345\n",
            "Epoch 469/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0020 - val_mae: 0.0336\n",
            "Epoch 470/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0034 - val_mae: 0.0447\n",
            "Epoch 471/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0024 - val_mae: 0.0382\n",
            "Epoch 472/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0024 - val_mae: 0.0392\n",
            "Epoch 473/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0319 - val_loss: 0.0018 - val_mae: 0.0337\n",
            "Epoch 474/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 475/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0019 - val_mae: 0.0350\n",
            "Epoch 476/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0021 - val_mae: 0.0364\n",
            "Epoch 477/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 0.0017 - val_mae: 0.0317\n",
            "Epoch 478/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0343 - val_loss: 0.0016 - val_mae: 0.0311\n",
            "Epoch 479/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 480/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0309 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 481/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 482/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0015 - val_mae: 0.0307\n",
            "Epoch 483/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 484/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0308 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 485/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0277\n",
            "Epoch 486/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0016 - val_mae: 0.0314\n",
            "Epoch 487/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0014 - val_mae: 0.0293\n",
            "Epoch 488/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0017 - val_mae: 0.0322\n",
            "Epoch 489/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0020 - val_mae: 0.0343\n",
            "Epoch 490/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0015 - val_mae: 0.0303\n",
            "Epoch 491/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 492/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 493/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 494/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0308 - val_loss: 0.0018 - val_mae: 0.0335\n",
            "Epoch 495/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 496/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0019 - val_mae: 0.0318\n",
            "Epoch 497/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 498/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 0.0017 - val_mae: 0.0321\n",
            "Epoch 499/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 500/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0028 - val_mae: 0.0391\n",
            "Epoch 501/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 502/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0285\n",
            "Epoch 503/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0270 - val_loss: 0.0015 - val_mae: 0.0307\n",
            "Epoch 504/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 505/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 506/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0015 - val_mae: 0.0298\n",
            "Epoch 507/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0311 - val_loss: 0.0018 - val_mae: 0.0317\n",
            "Epoch 508/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 509/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0344 - val_loss: 0.0048 - val_mae: 0.0503\n",
            "Epoch 510/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 511/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 512/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0029 - val_mae: 0.0431\n",
            "Epoch 513/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0363 - val_loss: 0.0018 - val_mae: 0.0338\n",
            "Epoch 514/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0016 - val_mae: 0.0311\n",
            "Epoch 515/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 9.3746e-04 - val_mae: 0.0239\n",
            "Epoch 516/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.8452e-04 - mae: 0.0243 - val_loss: 0.0013 - val_mae: 0.0303\n",
            "Epoch 517/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0020 - val_mae: 0.0332\n",
            "Epoch 518/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 519/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0019 - val_mae: 0.0342\n",
            "Epoch 520/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0016 - val_mae: 0.0319\n",
            "Epoch 521/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0016 - val_mae: 0.0313\n",
            "Epoch 522/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.8727e-04 - mae: 0.0248 - val_loss: 0.0015 - val_mae: 0.0308\n",
            "Epoch 523/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 524/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 525/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0345 - val_loss: 0.0025 - val_mae: 0.0360\n",
            "Epoch 526/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0421 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 527/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 528/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 529/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0252\n",
            "Epoch 530/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0021 - val_mae: 0.0366\n",
            "Epoch 531/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0253\n",
            "Epoch 532/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0957e-04 - mae: 0.0232 - val_loss: 8.3946e-04 - val_mae: 0.0240\n",
            "Epoch 533/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.7938e-04 - mae: 0.0241 - val_loss: 0.0014 - val_mae: 0.0294\n",
            "Epoch 534/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 535/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 536/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 537/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 9.5127e-04 - val_mae: 0.0244\n",
            "Epoch 538/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0270 - val_loss: 7.3320e-04 - val_mae: 0.0210\n",
            "Epoch 539/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 8.7089e-04 - val_mae: 0.0229\n",
            "Epoch 540/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.4431e-04 - mae: 0.0236 - val_loss: 7.8554e-04 - val_mae: 0.0227\n",
            "Epoch 541/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 9.1548e-04 - val_mae: 0.0241\n",
            "Epoch 542/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 7.9047e-04 - val_mae: 0.0221\n",
            "Epoch 543/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 544/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0012 - val_mae: 0.0264\n",
            "Epoch 545/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 7.7882e-04 - val_mae: 0.0221\n",
            "Epoch 546/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 9.7566e-04 - val_mae: 0.0245\n",
            "Epoch 547/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9818e-04 - mae: 0.0233 - val_loss: 9.0984e-04 - val_mae: 0.0236\n",
            "Epoch 548/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0016 - val_mae: 0.0322\n",
            "Epoch 549/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 550/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0047 - val_mae: 0.0510\n",
            "Epoch 551/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 8.5930e-04 - val_mae: 0.0231\n",
            "Epoch 552/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0249 - val_loss: 0.0018 - val_mae: 0.0327\n",
            "Epoch 553/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0246 - val_loss: 8.8005e-04 - val_mae: 0.0228\n",
            "Epoch 554/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 555/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0016 - val_mae: 0.0317\n",
            "Epoch 556/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 9.9323e-04 - val_mae: 0.0243\n",
            "Epoch 557/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.6347e-04 - mae: 0.0229 - val_loss: 8.2353e-04 - val_mae: 0.0222\n",
            "Epoch 558/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0243 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 559/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 560/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 561/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0018 - val_mae: 0.0335\n",
            "Epoch 562/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 8.2985e-04 - val_mae: 0.0218\n",
            "Epoch 563/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.7051e-04 - mae: 0.0233 - val_loss: 8.6472e-04 - val_mae: 0.0220\n",
            "Epoch 564/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 7.6923e-04 - val_mae: 0.0219\n",
            "Epoch 565/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 7.9352e-04 - val_mae: 0.0223\n",
            "Epoch 566/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1184e-04 - mae: 0.0234 - val_loss: 8.7354e-04 - val_mae: 0.0230\n",
            "Epoch 567/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5634e-04 - mae: 0.0241 - val_loss: 9.6806e-04 - val_mae: 0.0229\n",
            "Epoch 568/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0246\n",
            "Epoch 569/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 6.7768e-04 - val_mae: 0.0201\n",
            "Epoch 570/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0019 - val_mae: 0.0342\n",
            "Epoch 571/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0024 - val_mae: 0.0364\n",
            "Epoch 572/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0273\n",
            "Epoch 573/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.7414e-04 - mae: 0.0236 - val_loss: 8.4728e-04 - val_mae: 0.0230\n",
            "Epoch 574/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0907e-04 - mae: 0.0229 - val_loss: 6.1373e-04 - val_mae: 0.0191\n",
            "Epoch 575/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1205e-04 - mae: 0.0204 - val_loss: 7.7844e-04 - val_mae: 0.0216\n",
            "Epoch 576/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1165e-04 - mae: 0.0232 - val_loss: 8.7398e-04 - val_mae: 0.0242\n",
            "Epoch 577/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.2616e-04 - mae: 0.0224 - val_loss: 8.3497e-04 - val_mae: 0.0228\n",
            "Epoch 578/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0374e-04 - mae: 0.0205 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 579/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8286e-04 - mae: 0.0227 - val_loss: 7.7741e-04 - val_mae: 0.0214\n",
            "Epoch 580/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5636e-04 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 581/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2607e-04 - mae: 0.0231 - val_loss: 8.4427e-04 - val_mae: 0.0225\n",
            "Epoch 582/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0017 - val_mae: 0.0327\n",
            "Epoch 583/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 584/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0289 - val_loss: 0.0021 - val_mae: 0.0336\n",
            "Epoch 585/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0012 - val_mae: 0.0268\n",
            "Epoch 586/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9505e-04 - mae: 0.0224 - val_loss: 0.0010 - val_mae: 0.0230\n",
            "Epoch 587/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.7421e-04 - val_mae: 0.0239\n",
            "Epoch 588/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 6.8187e-04 - val_mae: 0.0203\n",
            "Epoch 589/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0243 - val_loss: 0.0020 - val_mae: 0.0303\n",
            "Epoch 590/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0246\n",
            "Epoch 591/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0012 - val_mae: 0.0287\n",
            "Epoch 592/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9690e-04 - mae: 0.0240 - val_loss: 9.5886e-04 - val_mae: 0.0238\n",
            "Epoch 593/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1174e-04 - mae: 0.0236 - val_loss: 7.3110e-04 - val_mae: 0.0212\n",
            "Epoch 594/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.5878e-04 - mae: 0.0201 - val_loss: 6.1438e-04 - val_mae: 0.0182\n",
            "Epoch 595/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.2977e-04 - mae: 0.0213 - val_loss: 5.5685e-04 - val_mae: 0.0185\n",
            "Epoch 596/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5250e-04 - mae: 0.0223 - val_loss: 7.7162e-04 - val_mae: 0.0222\n",
            "Epoch 597/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1050e-04 - mae: 0.0206 - val_loss: 6.5691e-04 - val_mae: 0.0194\n",
            "Epoch 598/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5375e-04 - mae: 0.0227 - val_loss: 0.0013 - val_mae: 0.0305\n",
            "Epoch 599/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0546e-04 - mae: 0.0227 - val_loss: 5.9212e-04 - val_mae: 0.0184\n",
            "Epoch 600/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6010e-04 - mae: 0.0196 - val_loss: 6.1982e-04 - val_mae: 0.0185\n",
            "Epoch 601/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5464e-04 - mae: 0.0204 - val_loss: 7.2033e-04 - val_mae: 0.0205\n",
            "Epoch 602/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7807e-04 - mae: 0.0202 - val_loss: 5.8295e-04 - val_mae: 0.0190\n",
            "Epoch 603/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6659e-04 - mae: 0.0194 - val_loss: 7.5734e-04 - val_mae: 0.0216\n",
            "Epoch 604/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 7.7646e-04 - val_mae: 0.0213\n",
            "Epoch 605/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8648e-04 - mae: 0.0204 - val_loss: 7.7606e-04 - val_mae: 0.0214\n",
            "Epoch 606/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4562e-04 - mae: 0.0198 - val_loss: 7.0228e-04 - val_mae: 0.0210\n",
            "Epoch 607/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3517e-04 - mae: 0.0219 - val_loss: 0.0022 - val_mae: 0.0346\n",
            "Epoch 608/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0019 - val_mae: 0.0337\n",
            "Epoch 609/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0015 - val_mae: 0.0305\n",
            "Epoch 610/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 611/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6702e-04 - mae: 0.0209 - val_loss: 0.0010 - val_mae: 0.0236\n",
            "Epoch 612/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3165e-04 - mae: 0.0227 - val_loss: 5.6195e-04 - val_mae: 0.0181\n",
            "Epoch 613/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6315e-04 - mae: 0.0211 - val_loss: 5.9062e-04 - val_mae: 0.0187\n",
            "Epoch 614/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1403e-04 - mae: 0.0219 - val_loss: 0.0014 - val_mae: 0.0279\n",
            "Epoch 615/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.6141e-04 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 616/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 617/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 8.8295e-04 - val_mae: 0.0236\n",
            "Epoch 618/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9519e-04 - mae: 0.0200 - val_loss: 5.5851e-04 - val_mae: 0.0175\n",
            "Epoch 619/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8952e-04 - mae: 0.0184 - val_loss: 7.3943e-04 - val_mae: 0.0201\n",
            "Epoch 620/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0111e-04 - mae: 0.0186 - val_loss: 7.0938e-04 - val_mae: 0.0201\n",
            "Epoch 621/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.3412e-04 - mae: 0.0236 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 622/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9988e-04 - mae: 0.0204 - val_loss: 6.2466e-04 - val_mae: 0.0195\n",
            "Epoch 623/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2860e-04 - mae: 0.0194 - val_loss: 6.9057e-04 - val_mae: 0.0201\n",
            "Epoch 624/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1452e-04 - mae: 0.0224 - val_loss: 7.5358e-04 - val_mae: 0.0200\n",
            "Epoch 625/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1174e-04 - mae: 0.0223 - val_loss: 7.8435e-04 - val_mae: 0.0212\n",
            "Epoch 626/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1349e-04 - mae: 0.0217 - val_loss: 7.9633e-04 - val_mae: 0.0212\n",
            "Epoch 627/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3074e-04 - mae: 0.0198 - val_loss: 4.8370e-04 - val_mae: 0.0165\n",
            "Epoch 628/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8695e-04 - mae: 0.0200 - val_loss: 0.0013 - val_mae: 0.0276\n",
            "Epoch 629/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 630/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5546e-04 - mae: 0.0202 - val_loss: 8.6749e-04 - val_mae: 0.0204\n",
            "Epoch 631/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0821e-04 - mae: 0.0226 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 632/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9043e-04 - mae: 0.0244 - val_loss: 7.1980e-04 - val_mae: 0.0206\n",
            "Epoch 633/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.4639e-04 - mae: 0.0219 - val_loss: 0.0020 - val_mae: 0.0335\n",
            "Epoch 634/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 635/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0345 - val_loss: 0.0020 - val_mae: 0.0345\n",
            "Epoch 636/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0352 - val_loss: 0.0019 - val_mae: 0.0361\n",
            "Epoch 637/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0248 - val_loss: 5.5515e-04 - val_mae: 0.0170\n",
            "Epoch 638/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0250 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 639/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.8173e-04 - mae: 0.0214 - val_loss: 9.2790e-04 - val_mae: 0.0242\n",
            "Epoch 640/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0993e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mae: 0.0264\n",
            "Epoch 641/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0246 - val_loss: 9.8516e-04 - val_mae: 0.0234\n",
            "Epoch 642/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 7.3533e-04 - val_mae: 0.0212\n",
            "Epoch 643/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0144e-04 - mae: 0.0229 - val_loss: 5.7876e-04 - val_mae: 0.0191\n",
            "Epoch 644/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6307e-04 - mae: 0.0196 - val_loss: 6.4315e-04 - val_mae: 0.0195\n",
            "Epoch 645/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.8312e-04 - mae: 0.0240 - val_loss: 5.8813e-04 - val_mae: 0.0195\n",
            "Epoch 646/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4601e-04 - mae: 0.0198 - val_loss: 6.4852e-04 - val_mae: 0.0207\n",
            "Epoch 647/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.5983e-04 - mae: 0.0189 - val_loss: 9.4581e-04 - val_mae: 0.0229\n",
            "Epoch 648/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.8936e-04 - mae: 0.0208 - val_loss: 7.1916e-04 - val_mae: 0.0202\n",
            "Epoch 649/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.5553e-04 - mae: 0.0197 - val_loss: 5.7040e-04 - val_mae: 0.0175\n",
            "Epoch 650/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8603e-04 - mae: 0.0183 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 651/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7153e-04 - mae: 0.0201 - val_loss: 6.7170e-04 - val_mae: 0.0195\n",
            "Epoch 652/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3551e-04 - mae: 0.0221 - val_loss: 6.9667e-04 - val_mae: 0.0196\n",
            "Epoch 653/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8550e-04 - mae: 0.0227 - val_loss: 4.6873e-04 - val_mae: 0.0164\n",
            "Epoch 654/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2943e-04 - mae: 0.0189 - val_loss: 9.0992e-04 - val_mae: 0.0232\n",
            "Epoch 655/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3535e-04 - mae: 0.0206 - val_loss: 0.0010 - val_mae: 0.0234\n",
            "Epoch 656/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 657/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9234e-04 - mae: 0.0240 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 658/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 5.1806e-04 - val_mae: 0.0170\n",
            "Epoch 659/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4406e-04 - mae: 0.0204 - val_loss: 6.2414e-04 - val_mae: 0.0185\n",
            "Epoch 660/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1765e-04 - mae: 0.0173 - val_loss: 5.0487e-04 - val_mae: 0.0169\n",
            "Epoch 661/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3787e-04 - mae: 0.0202 - val_loss: 7.0683e-04 - val_mae: 0.0202\n",
            "Epoch 662/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2760e-04 - mae: 0.0194 - val_loss: 7.0462e-04 - val_mae: 0.0200\n",
            "Epoch 663/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7719e-04 - mae: 0.0199 - val_loss: 6.0491e-04 - val_mae: 0.0171\n",
            "Epoch 664/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7677e-04 - mae: 0.0183 - val_loss: 9.5662e-04 - val_mae: 0.0229\n",
            "Epoch 665/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.5940e-04 - mae: 0.0197 - val_loss: 0.0010 - val_mae: 0.0233\n",
            "Epoch 666/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 667/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6860e-04 - mae: 0.0208 - val_loss: 7.2523e-04 - val_mae: 0.0210\n",
            "Epoch 668/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9967e-04 - mae: 0.0207 - val_loss: 5.6577e-04 - val_mae: 0.0180\n",
            "Epoch 669/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6716e-04 - mae: 0.0216 - val_loss: 4.8373e-04 - val_mae: 0.0165\n",
            "Epoch 670/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1987e-04 - mae: 0.0194 - val_loss: 6.8337e-04 - val_mae: 0.0205\n",
            "Epoch 671/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2759e-04 - mae: 0.0195 - val_loss: 6.3434e-04 - val_mae: 0.0183\n",
            "Epoch 672/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6822e-04 - mae: 0.0197 - val_loss: 4.9501e-04 - val_mae: 0.0179\n",
            "Epoch 673/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9919e-04 - mae: 0.0184 - val_loss: 9.8807e-04 - val_mae: 0.0244\n",
            "Epoch 674/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2697e-04 - mae: 0.0193 - val_loss: 6.5521e-04 - val_mae: 0.0197\n",
            "Epoch 675/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.7374e-04 - mae: 0.0223 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 676/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4654e-04 - mae: 0.0207 - val_loss: 7.4682e-04 - val_mae: 0.0212\n",
            "Epoch 677/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7662e-04 - mae: 0.0184 - val_loss: 4.9396e-04 - val_mae: 0.0178\n",
            "Epoch 678/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0199e-04 - mae: 0.0172 - val_loss: 5.6416e-04 - val_mae: 0.0186\n",
            "Epoch 679/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3480e-04 - mae: 0.0180 - val_loss: 5.9325e-04 - val_mae: 0.0194\n",
            "Epoch 680/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0259\n",
            "Epoch 681/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.8587e-04 - mae: 0.0234 - val_loss: 6.5923e-04 - val_mae: 0.0180\n",
            "Epoch 682/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4337e-04 - mae: 0.0177 - val_loss: 3.5298e-04 - val_mae: 0.0139\n",
            "Epoch 683/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1616e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mae: 0.0211\n",
            "Epoch 684/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8144e-04 - mae: 0.0221 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 685/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3153e-04 - mae: 0.0221 - val_loss: 8.3867e-04 - val_mae: 0.0200\n",
            "Epoch 686/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0017 - val_mae: 0.0311\n",
            "Epoch 687/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 688/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0273\n",
            "Epoch 689/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3561e-04 - mae: 0.0209 - val_loss: 6.2694e-04 - val_mae: 0.0188\n",
            "Epoch 690/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2605e-04 - mae: 0.0235 - val_loss: 9.4742e-04 - val_mae: 0.0233\n",
            "Epoch 691/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4830e-04 - mae: 0.0179 - val_loss: 3.9334e-04 - val_mae: 0.0147\n",
            "Epoch 692/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1768e-04 - mae: 0.0176 - val_loss: 5.5612e-04 - val_mae: 0.0185\n",
            "Epoch 693/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5569e-04 - mae: 0.0179 - val_loss: 4.7935e-04 - val_mae: 0.0165\n",
            "Epoch 694/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9515e-04 - mae: 0.0151 - val_loss: 5.0813e-04 - val_mae: 0.0165\n",
            "Epoch 695/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0069e-04 - mae: 0.0172 - val_loss: 5.4960e-04 - val_mae: 0.0165\n",
            "Epoch 696/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7360e-04 - mae: 0.0180 - val_loss: 5.2209e-04 - val_mae: 0.0175\n",
            "Epoch 697/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9556e-04 - mae: 0.0182 - val_loss: 4.7818e-04 - val_mae: 0.0162\n",
            "Epoch 698/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0056e-04 - mae: 0.0224 - val_loss: 0.0024 - val_mae: 0.0409\n",
            "Epoch 699/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 9.4617e-04 - val_mae: 0.0247\n",
            "Epoch 700/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2048e-04 - mae: 0.0192 - val_loss: 5.5199e-04 - val_mae: 0.0179\n",
            "Epoch 701/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3025e-04 - mae: 0.0175 - val_loss: 6.5273e-04 - val_mae: 0.0202\n",
            "Epoch 702/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0299\n",
            "Epoch 703/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0016 - val_mae: 0.0287\n",
            "Epoch 704/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 705/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.3883e-04 - mae: 0.0229 - val_loss: 3.8671e-04 - val_mae: 0.0146\n",
            "Epoch 706/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1010e-04 - mae: 0.0182 - val_loss: 7.5485e-04 - val_mae: 0.0223\n",
            "Epoch 707/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 4.1665e-04 - val_mae: 0.0149\n",
            "Epoch 708/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9106e-04 - mae: 0.0201 - val_loss: 9.7426e-04 - val_mae: 0.0243\n",
            "Epoch 709/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9696e-04 - mae: 0.0206 - val_loss: 5.2722e-04 - val_mae: 0.0172\n",
            "Epoch 710/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8808e-04 - mae: 0.0202 - val_loss: 8.2182e-04 - val_mae: 0.0220\n",
            "Epoch 711/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4099e-04 - mae: 0.0205 - val_loss: 8.2978e-04 - val_mae: 0.0215\n",
            "Epoch 712/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1160e-04 - mae: 0.0200 - val_loss: 8.1196e-04 - val_mae: 0.0234\n",
            "Epoch 713/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5723e-04 - mae: 0.0181 - val_loss: 4.7380e-04 - val_mae: 0.0171\n",
            "Epoch 714/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4299e-04 - mae: 0.0142 - val_loss: 4.3479e-04 - val_mae: 0.0156\n",
            "Epoch 715/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6070e-04 - mae: 0.0146 - val_loss: 4.0586e-04 - val_mae: 0.0148\n",
            "Epoch 716/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7480e-04 - mae: 0.0147 - val_loss: 8.4761e-04 - val_mae: 0.0194\n",
            "Epoch 717/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5798e-04 - mae: 0.0169 - val_loss: 4.2425e-04 - val_mae: 0.0156\n",
            "Epoch 718/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4940e-04 - mae: 0.0160 - val_loss: 4.8106e-04 - val_mae: 0.0172\n",
            "Epoch 719/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9254e-04 - mae: 0.0152 - val_loss: 4.9007e-04 - val_mae: 0.0173\n",
            "Epoch 720/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9037e-04 - mae: 0.0150 - val_loss: 5.4769e-04 - val_mae: 0.0180\n",
            "Epoch 721/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1345e-04 - mae: 0.0190 - val_loss: 5.5470e-04 - val_mae: 0.0177\n",
            "Epoch 722/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3721e-04 - mae: 0.0185 - val_loss: 9.4262e-04 - val_mae: 0.0230\n",
            "Epoch 723/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1722e-04 - mae: 0.0232 - val_loss: 9.1874e-04 - val_mae: 0.0224\n",
            "Epoch 724/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0000e-04 - mae: 0.0195 - val_loss: 5.5495e-04 - val_mae: 0.0163\n",
            "Epoch 725/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5232e-04 - mae: 0.0228 - val_loss: 4.6680e-04 - val_mae: 0.0164\n",
            "Epoch 726/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9706e-04 - mae: 0.0199 - val_loss: 7.0485e-04 - val_mae: 0.0200\n",
            "Epoch 727/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8490e-04 - mae: 0.0180 - val_loss: 3.5228e-04 - val_mae: 0.0138\n",
            "Epoch 728/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2656e-04 - mae: 0.0152 - val_loss: 4.3875e-04 - val_mae: 0.0158\n",
            "Epoch 729/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.4588e-04 - mae: 0.0213 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 730/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1979e-04 - mae: 0.0211 - val_loss: 4.5674e-04 - val_mae: 0.0159\n",
            "Epoch 731/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5037e-04 - mae: 0.0163 - val_loss: 3.3392e-04 - val_mae: 0.0130\n",
            "Epoch 732/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5735e-04 - mae: 0.0155 - val_loss: 5.5098e-04 - val_mae: 0.0181\n",
            "Epoch 733/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5396e-04 - mae: 0.0161 - val_loss: 8.5949e-04 - val_mae: 0.0229\n",
            "Epoch 734/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9411e-04 - mae: 0.0193 - val_loss: 6.4710e-04 - val_mae: 0.0205\n",
            "Epoch 735/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3547e-04 - mae: 0.0215 - val_loss: 5.5322e-04 - val_mae: 0.0165\n",
            "Epoch 736/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.5682e-04 - mae: 0.0193 - val_loss: 4.2987e-04 - val_mae: 0.0158\n",
            "Epoch 737/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9993e-04 - mae: 0.0171 - val_loss: 5.8266e-04 - val_mae: 0.0176\n",
            "Epoch 738/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2733e-04 - mae: 0.0159 - val_loss: 4.1048e-04 - val_mae: 0.0147\n",
            "Epoch 739/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.2784e-04 - mae: 0.0188 - val_loss: 7.3248e-04 - val_mae: 0.0225\n",
            "Epoch 740/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3953e-04 - mae: 0.0203 - val_loss: 5.8887e-04 - val_mae: 0.0180\n",
            "Epoch 741/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9905e-04 - mae: 0.0163 - val_loss: 4.0518e-04 - val_mae: 0.0145\n",
            "Epoch 742/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.7594e-04 - mae: 0.0206 - val_loss: 9.2299e-04 - val_mae: 0.0221\n",
            "Epoch 743/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.4325e-04 - mae: 0.0223 - val_loss: 7.5923e-04 - val_mae: 0.0209\n",
            "Epoch 744/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.3080e-04 - mae: 0.0232 - val_loss: 5.2859e-04 - val_mae: 0.0164\n",
            "Epoch 745/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9208e-04 - mae: 0.0188 - val_loss: 9.4848e-04 - val_mae: 0.0240\n",
            "Epoch 746/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4523e-04 - mae: 0.0198 - val_loss: 5.2833e-04 - val_mae: 0.0169\n",
            "Epoch 747/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5294e-04 - mae: 0.0223 - val_loss: 0.0014 - val_mae: 0.0316\n",
            "Epoch 748/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0016 - val_mae: 0.0309\n",
            "Epoch 749/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.4565e-04 - mae: 0.0226 - val_loss: 8.0272e-04 - val_mae: 0.0222\n",
            "Epoch 750/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2976e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mae: 0.0245\n",
            "Epoch 751/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 7.8789e-04 - val_mae: 0.0213\n",
            "Epoch 752/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 9.8360e-04 - val_mae: 0.0234\n",
            "Epoch 753/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2821e-04 - mae: 0.0224 - val_loss: 9.5297e-04 - val_mae: 0.0235\n",
            "Epoch 754/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8009e-04 - mae: 0.0200 - val_loss: 5.7895e-04 - val_mae: 0.0172\n",
            "Epoch 755/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4517e-04 - mae: 0.0159 - val_loss: 8.6105e-04 - val_mae: 0.0212\n",
            "Epoch 756/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1097e-04 - mae: 0.0217 - val_loss: 9.5386e-04 - val_mae: 0.0223\n",
            "Epoch 757/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1871e-04 - mae: 0.0183 - val_loss: 6.6934e-04 - val_mae: 0.0193\n",
            "Epoch 758/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3867e-04 - mae: 0.0191 - val_loss: 5.8669e-04 - val_mae: 0.0193\n",
            "Epoch 759/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0854e-04 - mae: 0.0190 - val_loss: 7.4233e-04 - val_mae: 0.0184\n",
            "Epoch 760/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7851e-04 - mae: 0.0185 - val_loss: 5.3822e-04 - val_mae: 0.0175\n",
            "Epoch 761/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1675e-04 - mae: 0.0190 - val_loss: 4.7514e-04 - val_mae: 0.0162\n",
            "Epoch 762/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3042e-04 - mae: 0.0193 - val_loss: 2.9051e-04 - val_mae: 0.0116\n",
            "Epoch 763/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5674e-04 - mae: 0.0177 - val_loss: 9.0342e-04 - val_mae: 0.0240\n",
            "Epoch 764/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1077e-04 - mae: 0.0170 - val_loss: 5.0180e-04 - val_mae: 0.0172\n",
            "Epoch 765/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1713e-04 - mae: 0.0168 - val_loss: 7.0277e-04 - val_mae: 0.0210\n",
            "Epoch 766/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5363e-04 - mae: 0.0184 - val_loss: 9.1213e-04 - val_mae: 0.0230\n",
            "Epoch 767/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0350e-04 - mae: 0.0182 - val_loss: 7.0286e-04 - val_mae: 0.0207\n",
            "Epoch 768/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 769/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6557e-04 - mae: 0.0211 - val_loss: 5.2155e-04 - val_mae: 0.0157\n",
            "Epoch 770/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7974e-04 - mae: 0.0146 - val_loss: 3.7408e-04 - val_mae: 0.0131\n",
            "Epoch 771/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6295e-04 - mae: 0.0143 - val_loss: 4.7894e-04 - val_mae: 0.0161\n",
            "Epoch 772/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6909e-04 - mae: 0.0146 - val_loss: 8.4641e-04 - val_mae: 0.0184\n",
            "Epoch 773/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2460e-04 - mae: 0.0174 - val_loss: 6.9955e-04 - val_mae: 0.0206\n",
            "Epoch 774/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5815e-04 - mae: 0.0207 - val_loss: 0.0015 - val_mae: 0.0290\n",
            "Epoch 775/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0324 - val_loss: 0.0015 - val_mae: 0.0280\n",
            "Epoch 776/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0632 - val_loss: 0.0065 - val_mae: 0.0622\n",
            "Epoch 777/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 6.5929e-04 - val_mae: 0.0205\n",
            "Epoch 778/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8681e-04 - mae: 0.0181 - val_loss: 4.8554e-04 - val_mae: 0.0168\n",
            "Epoch 779/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4863e-04 - mae: 0.0143 - val_loss: 6.2932e-04 - val_mae: 0.0178\n",
            "Epoch 780/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3806e-04 - mae: 0.0177 - val_loss: 9.2099e-04 - val_mae: 0.0227\n",
            "Epoch 781/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7795e-04 - mae: 0.0206 - val_loss: 3.1352e-04 - val_mae: 0.0124\n",
            "Epoch 782/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5522e-04 - mae: 0.0141 - val_loss: 3.7538e-04 - val_mae: 0.0124\n",
            "Epoch 783/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2059e-04 - mae: 0.0132 - val_loss: 4.0167e-04 - val_mae: 0.0147\n",
            "Epoch 784/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8316e-04 - mae: 0.0148 - val_loss: 3.6238e-04 - val_mae: 0.0134\n",
            "Epoch 785/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7947e-04 - mae: 0.0144 - val_loss: 4.2684e-04 - val_mae: 0.0150\n",
            "Epoch 786/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1271e-04 - mae: 0.0156 - val_loss: 3.1512e-04 - val_mae: 0.0122\n",
            "Epoch 787/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0285e-04 - mae: 0.0132 - val_loss: 3.8200e-04 - val_mae: 0.0134\n",
            "Epoch 788/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4702e-04 - mae: 0.0138 - val_loss: 6.3638e-04 - val_mae: 0.0171\n",
            "Epoch 789/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4459e-04 - mae: 0.0164 - val_loss: 5.6527e-04 - val_mae: 0.0189\n",
            "Epoch 790/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1130e-04 - mae: 0.0154 - val_loss: 3.9878e-04 - val_mae: 0.0142\n",
            "Epoch 791/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0405e-04 - mae: 0.0149 - val_loss: 5.3700e-04 - val_mae: 0.0173\n",
            "Epoch 792/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8989e-04 - mae: 0.0166 - val_loss: 3.9903e-04 - val_mae: 0.0149\n",
            "Epoch 793/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5121e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 794/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6361e-04 - mae: 0.0174 - val_loss: 6.2083e-04 - val_mae: 0.0189\n",
            "Epoch 795/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5957e-04 - mae: 0.0180 - val_loss: 3.7139e-04 - val_mae: 0.0152\n",
            "Epoch 796/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4165e-04 - mae: 0.0193 - val_loss: 3.6586e-04 - val_mae: 0.0139\n",
            "Epoch 797/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4145e-04 - mae: 0.0139 - val_loss: 3.8613e-04 - val_mae: 0.0146\n",
            "Epoch 798/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9224e-04 - mae: 0.0151 - val_loss: 4.6384e-04 - val_mae: 0.0150\n",
            "Epoch 799/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0421e-04 - mae: 0.0152 - val_loss: 3.5757e-04 - val_mae: 0.0130\n",
            "Epoch 800/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3171e-04 - mae: 0.0156 - val_loss: 3.1688e-04 - val_mae: 0.0124\n",
            "Epoch 801/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6989e-04 - mae: 0.0121 - val_loss: 3.0024e-04 - val_mae: 0.0120\n",
            "Epoch 802/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7578e-04 - mae: 0.0151 - val_loss: 7.0248e-04 - val_mae: 0.0196\n",
            "Epoch 803/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3135e-04 - mae: 0.0190 - val_loss: 6.0753e-04 - val_mae: 0.0194\n",
            "Epoch 804/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2153e-04 - mae: 0.0135 - val_loss: 4.6503e-04 - val_mae: 0.0147\n",
            "Epoch 805/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4040e-04 - mae: 0.0132 - val_loss: 3.3994e-04 - val_mae: 0.0127\n",
            "Epoch 806/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6130e-04 - mae: 0.0141 - val_loss: 5.2619e-04 - val_mae: 0.0169\n",
            "Epoch 807/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7368e-04 - mae: 0.0206 - val_loss: 8.8780e-04 - val_mae: 0.0230\n",
            "Epoch 808/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5342e-04 - mae: 0.0176 - val_loss: 3.7692e-04 - val_mae: 0.0145\n",
            "Epoch 809/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1880e-04 - mae: 0.0158 - val_loss: 4.0488e-04 - val_mae: 0.0141\n",
            "Epoch 810/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7407e-04 - mae: 0.0168 - val_loss: 5.4706e-04 - val_mae: 0.0166\n",
            "Epoch 811/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1101e-04 - mae: 0.0185 - val_loss: 5.3945e-04 - val_mae: 0.0145\n",
            "Epoch 812/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7238e-04 - mae: 0.0202 - val_loss: 9.0641e-04 - val_mae: 0.0253\n",
            "Epoch 813/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8810e-04 - mae: 0.0227 - val_loss: 5.7935e-04 - val_mae: 0.0169\n",
            "Epoch 814/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0023 - val_mae: 0.0322\n",
            "Epoch 815/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0322 - val_loss: 0.0027 - val_mae: 0.0424\n",
            "Epoch 816/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0020 - val_mae: 0.0334\n",
            "Epoch 817/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.3099e-04 - mae: 0.0217 - val_loss: 6.8817e-04 - val_mae: 0.0201\n",
            "Epoch 818/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4894e-04 - mae: 0.0158 - val_loss: 5.3261e-04 - val_mae: 0.0190\n",
            "Epoch 819/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6967e-04 - mae: 0.0143 - val_loss: 2.9957e-04 - val_mae: 0.0123\n",
            "Epoch 820/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7229e-04 - mae: 0.0123 - val_loss: 4.1332e-04 - val_mae: 0.0151\n",
            "Epoch 821/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1153e-04 - mae: 0.0132 - val_loss: 3.4587e-04 - val_mae: 0.0136\n",
            "Epoch 822/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4713e-04 - mae: 0.0138 - val_loss: 3.6659e-04 - val_mae: 0.0143\n",
            "Epoch 823/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7950e-04 - mae: 0.0168 - val_loss: 4.1593e-04 - val_mae: 0.0157\n",
            "Epoch 824/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4234e-04 - mae: 0.0139 - val_loss: 2.6801e-04 - val_mae: 0.0111\n",
            "Epoch 825/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1168e-04 - mae: 0.0109 - val_loss: 3.4371e-04 - val_mae: 0.0136\n",
            "Epoch 826/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4936e-04 - mae: 0.0121 - val_loss: 3.6990e-04 - val_mae: 0.0142\n",
            "Epoch 827/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4692e-04 - mae: 0.0141 - val_loss: 4.3960e-04 - val_mae: 0.0144\n",
            "Epoch 828/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7188e-04 - mae: 0.0147 - val_loss: 6.9509e-04 - val_mae: 0.0203\n",
            "Epoch 829/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7047e-04 - mae: 0.0162 - val_loss: 2.9535e-04 - val_mae: 0.0120\n",
            "Epoch 830/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6400e-04 - mae: 0.0147 - val_loss: 3.6631e-04 - val_mae: 0.0140\n",
            "Epoch 831/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1672e-04 - mae: 0.0165 - val_loss: 7.4506e-04 - val_mae: 0.0197\n",
            "Epoch 832/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9381e-04 - mae: 0.0185 - val_loss: 5.6942e-04 - val_mae: 0.0168\n",
            "Epoch 833/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1358e-04 - mae: 0.0156 - val_loss: 4.6055e-04 - val_mae: 0.0150\n",
            "Epoch 834/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6044e-04 - mae: 0.0195 - val_loss: 6.2648e-04 - val_mae: 0.0199\n",
            "Epoch 835/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4537e-04 - mae: 0.0195 - val_loss: 5.9940e-04 - val_mae: 0.0183\n",
            "Epoch 836/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3711e-04 - mae: 0.0156 - val_loss: 2.7765e-04 - val_mae: 0.0111\n",
            "Epoch 837/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1549e-04 - mae: 0.0132 - val_loss: 4.8686e-04 - val_mae: 0.0148\n",
            "Epoch 838/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2441e-04 - mae: 0.0153 - val_loss: 4.0012e-04 - val_mae: 0.0138\n",
            "Epoch 839/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9544e-04 - mae: 0.0133 - val_loss: 3.3503e-04 - val_mae: 0.0134\n",
            "Epoch 840/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6374e-04 - mae: 0.0139 - val_loss: 5.2015e-04 - val_mae: 0.0174\n",
            "Epoch 841/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5643e-04 - mae: 0.0164 - val_loss: 6.4394e-04 - val_mae: 0.0189\n",
            "Epoch 842/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4414e-04 - mae: 0.0159 - val_loss: 3.9400e-04 - val_mae: 0.0148\n",
            "Epoch 843/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0421e-04 - mae: 0.0132 - val_loss: 3.0729e-04 - val_mae: 0.0123\n",
            "Epoch 844/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0244e-04 - mae: 0.0135 - val_loss: 5.6457e-04 - val_mae: 0.0176\n",
            "Epoch 845/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0073e-04 - mae: 0.0131 - val_loss: 2.7444e-04 - val_mae: 0.0112\n",
            "Epoch 846/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5265e-04 - mae: 0.0142 - val_loss: 6.1601e-04 - val_mae: 0.0167\n",
            "Epoch 847/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4565e-04 - mae: 0.0162 - val_loss: 6.8911e-04 - val_mae: 0.0182\n",
            "Epoch 848/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3429e-04 - mae: 0.0157 - val_loss: 6.7307e-04 - val_mae: 0.0198\n",
            "Epoch 849/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8176e-04 - mae: 0.0222 - val_loss: 5.3209e-04 - val_mae: 0.0168\n",
            "Epoch 850/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8945e-04 - mae: 0.0163 - val_loss: 4.7720e-04 - val_mae: 0.0156\n",
            "Epoch 851/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1253e-04 - mae: 0.0159 - val_loss: 3.7681e-04 - val_mae: 0.0130\n",
            "Epoch 852/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4690e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 853/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0273\n",
            "Epoch 854/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.6403e-04 - mae: 0.0244 - val_loss: 6.9663e-04 - val_mae: 0.0199\n",
            "Epoch 855/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0015 - val_mae: 0.0264\n",
            "Epoch 856/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0456 - val_loss: 0.0022 - val_mae: 0.0364\n",
            "Epoch 857/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 7.8174e-04 - val_mae: 0.0217\n",
            "Epoch 858/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0023 - val_mae: 0.0367\n",
            "Epoch 859/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0019 - val_mae: 0.0333\n",
            "Epoch 860/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 6.1542e-04 - val_mae: 0.0187\n",
            "Epoch 861/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0236 - val_loss: 9.5946e-04 - val_mae: 0.0263\n",
            "Epoch 862/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 5.8457e-04 - val_mae: 0.0186\n",
            "Epoch 863/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9756e-04 - mae: 0.0169 - val_loss: 5.1612e-04 - val_mae: 0.0177\n",
            "Epoch 864/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0219e-04 - mae: 0.0131 - val_loss: 2.7673e-04 - val_mae: 0.0110\n",
            "Epoch 865/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3724e-04 - mae: 0.0114 - val_loss: 3.2559e-04 - val_mae: 0.0138\n",
            "Epoch 866/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4284e-04 - mae: 0.0117 - val_loss: 2.4679e-04 - val_mae: 0.0105\n",
            "Epoch 867/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5393e-04 - mae: 0.0135 - val_loss: 4.7788e-04 - val_mae: 0.0158\n",
            "Epoch 868/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7839e-04 - mae: 0.0149 - val_loss: 3.2635e-04 - val_mae: 0.0136\n",
            "Epoch 869/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8412e-04 - mae: 0.0162 - val_loss: 0.0011 - val_mae: 0.0219\n",
            "Epoch 870/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9609e-04 - mae: 0.0161 - val_loss: 3.8383e-04 - val_mae: 0.0148\n",
            "Epoch 871/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9525e-04 - mae: 0.0125 - val_loss: 2.8145e-04 - val_mae: 0.0120\n",
            "Epoch 872/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1221e-04 - mae: 0.0137 - val_loss: 3.8909e-04 - val_mae: 0.0146\n",
            "Epoch 873/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0423e-04 - mae: 0.0131 - val_loss: 2.8556e-04 - val_mae: 0.0126\n",
            "Epoch 874/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7597e-04 - mae: 0.0126 - val_loss: 6.5191e-04 - val_mae: 0.0173\n",
            "Epoch 875/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3684e-04 - mae: 0.0134 - val_loss: 4.6128e-04 - val_mae: 0.0139\n",
            "Epoch 876/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8186e-04 - mae: 0.0156 - val_loss: 7.8616e-04 - val_mae: 0.0198\n",
            "Epoch 877/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7292e-04 - mae: 0.0144 - val_loss: 3.8874e-04 - val_mae: 0.0148\n",
            "Epoch 878/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4567e-04 - mae: 0.0137 - val_loss: 3.8218e-04 - val_mae: 0.0152\n",
            "Epoch 879/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0255e-04 - mae: 0.0130 - val_loss: 3.2442e-04 - val_mae: 0.0136\n",
            "Epoch 880/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1657e-04 - mae: 0.0110 - val_loss: 3.3195e-04 - val_mae: 0.0130\n",
            "Epoch 881/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7287e-04 - mae: 0.0121 - val_loss: 6.9466e-04 - val_mae: 0.0185\n",
            "Epoch 882/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0058 - val_mae: 0.0630\n",
            "Epoch 883/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0453 - val_loss: 0.0040 - val_mae: 0.0489\n",
            "Epoch 884/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 6.1536e-04 - val_mae: 0.0171\n",
            "Epoch 885/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0968e-04 - mae: 0.0135 - val_loss: 2.8444e-04 - val_mae: 0.0125\n",
            "Epoch 886/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1190e-04 - mae: 0.0149 - val_loss: 6.9620e-04 - val_mae: 0.0191\n",
            "Epoch 887/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8980e-04 - mae: 0.0162 - val_loss: 3.5659e-04 - val_mae: 0.0139\n",
            "Epoch 888/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4384e-04 - mae: 0.0139 - val_loss: 4.9404e-04 - val_mae: 0.0169\n",
            "Epoch 889/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5810e-04 - mae: 0.0177 - val_loss: 4.8232e-04 - val_mae: 0.0159\n",
            "Epoch 890/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7190e-04 - mae: 0.0125 - val_loss: 2.3563e-04 - val_mae: 0.0105\n",
            "Epoch 891/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6569e-04 - mae: 0.0118 - val_loss: 4.2089e-04 - val_mae: 0.0145\n",
            "Epoch 892/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8974e-04 - mae: 0.0125 - val_loss: 5.7712e-04 - val_mae: 0.0175\n",
            "Epoch 893/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9990e-04 - mae: 0.0146 - val_loss: 5.5786e-04 - val_mae: 0.0162\n",
            "Epoch 894/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4350e-04 - mae: 0.0157 - val_loss: 3.9055e-04 - val_mae: 0.0156\n",
            "Epoch 895/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6068e-04 - mae: 0.0144 - val_loss: 4.2880e-04 - val_mae: 0.0129\n",
            "Epoch 896/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8685e-04 - mae: 0.0150 - val_loss: 3.3345e-04 - val_mae: 0.0134\n",
            "Epoch 897/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8578e-04 - mae: 0.0151 - val_loss: 5.8787e-04 - val_mae: 0.0193\n",
            "Epoch 898/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0529e-04 - mae: 0.0162 - val_loss: 4.8220e-04 - val_mae: 0.0168\n",
            "Epoch 899/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3453e-04 - mae: 0.0212 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 900/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.4454e-04 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 901/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2676e-04 - mae: 0.0225 - val_loss: 2.9466e-04 - val_mae: 0.0125\n",
            "Epoch 902/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5423e-04 - mae: 0.0120 - val_loss: 2.8868e-04 - val_mae: 0.0119\n",
            "Epoch 903/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9444e-04 - mae: 0.0153 - val_loss: 2.7505e-04 - val_mae: 0.0118\n",
            "Epoch 904/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8390e-04 - mae: 0.0131 - val_loss: 2.5995e-04 - val_mae: 0.0115\n",
            "Epoch 905/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8583e-04 - mae: 0.0146 - val_loss: 5.9136e-04 - val_mae: 0.0193\n",
            "Epoch 906/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1528e-04 - mae: 0.0201 - val_loss: 4.4904e-04 - val_mae: 0.0153\n",
            "Epoch 907/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5857e-04 - mae: 0.0160 - val_loss: 7.1193e-04 - val_mae: 0.0190\n",
            "Epoch 908/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3808e-04 - mae: 0.0156 - val_loss: 5.0132e-04 - val_mae: 0.0163\n",
            "Epoch 909/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9227e-04 - mae: 0.0163 - val_loss: 4.9191e-04 - val_mae: 0.0157\n",
            "Epoch 910/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4644e-04 - mae: 0.0159 - val_loss: 5.5383e-04 - val_mae: 0.0180\n",
            "Epoch 911/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.0586e-04 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 912/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0750e-04 - mae: 0.0154 - val_loss: 2.5239e-04 - val_mae: 0.0108\n",
            "Epoch 913/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8584e-04 - mae: 0.0127 - val_loss: 7.8807e-04 - val_mae: 0.0217\n",
            "Epoch 914/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5995e-04 - mae: 0.0210 - val_loss: 7.6871e-04 - val_mae: 0.0209\n",
            "Epoch 915/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6239e-04 - mae: 0.0163 - val_loss: 5.3384e-04 - val_mae: 0.0160\n",
            "Epoch 916/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0278 - val_loss: 0.0015 - val_mae: 0.0303\n",
            "Epoch 917/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 3.7803e-04 - val_mae: 0.0145\n",
            "Epoch 918/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0136e-04 - mae: 0.0200 - val_loss: 5.9919e-04 - val_mae: 0.0178\n",
            "Epoch 919/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8158e-04 - mae: 0.0157 - val_loss: 7.2182e-04 - val_mae: 0.0228\n",
            "Epoch 920/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4309e-04 - mae: 0.0161 - val_loss: 3.4990e-04 - val_mae: 0.0133\n",
            "Epoch 921/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0834e-04 - mae: 0.0158 - val_loss: 5.0231e-04 - val_mae: 0.0185\n",
            "Epoch 922/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5682e-04 - mae: 0.0156 - val_loss: 6.8142e-04 - val_mae: 0.0192\n",
            "Epoch 923/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.2989e-04 - mae: 0.0136 - val_loss: 3.8815e-04 - val_mae: 0.0142\n",
            "Epoch 924/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0789e-04 - mae: 0.0157 - val_loss: 2.4634e-04 - val_mae: 0.0105\n",
            "Epoch 925/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1552e-04 - mae: 0.0133 - val_loss: 5.2516e-04 - val_mae: 0.0147\n",
            "Epoch 926/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9811e-04 - mae: 0.0148 - val_loss: 3.0219e-04 - val_mae: 0.0120\n",
            "Epoch 927/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6282e-04 - mae: 0.0143 - val_loss: 3.7586e-04 - val_mae: 0.0133\n",
            "Epoch 928/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6964e-04 - mae: 0.0159 - val_loss: 8.2652e-04 - val_mae: 0.0194\n",
            "Epoch 929/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3166e-04 - mae: 0.0178 - val_loss: 4.6727e-04 - val_mae: 0.0159\n",
            "Epoch 930/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0033 - val_mae: 0.0380\n",
            "Epoch 931/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0342 - val_loss: 0.0018 - val_mae: 0.0321\n",
            "Epoch 932/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9173e-04 - mae: 0.0216 - val_loss: 5.3221e-04 - val_mae: 0.0157\n",
            "Epoch 933/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8709e-04 - mae: 0.0143 - val_loss: 3.9694e-04 - val_mae: 0.0142\n",
            "Epoch 934/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5886e-04 - mae: 0.0121 - val_loss: 3.0161e-04 - val_mae: 0.0126\n",
            "Epoch 935/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8289e-04 - mae: 0.0127 - val_loss: 3.0387e-04 - val_mae: 0.0128\n",
            "Epoch 936/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6161e-04 - mae: 0.0121 - val_loss: 4.2723e-04 - val_mae: 0.0149\n",
            "Epoch 937/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9659e-04 - mae: 0.0157 - val_loss: 3.3705e-04 - val_mae: 0.0139\n",
            "Epoch 938/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9494e-04 - mae: 0.0131 - val_loss: 4.2616e-04 - val_mae: 0.0150\n",
            "Epoch 939/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5063e-04 - mae: 0.0121 - val_loss: 3.4726e-04 - val_mae: 0.0124\n",
            "Epoch 940/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9923e-04 - mae: 0.0107 - val_loss: 3.1108e-04 - val_mae: 0.0124\n",
            "Epoch 941/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2330e-04 - mae: 0.0133 - val_loss: 3.7490e-04 - val_mae: 0.0151\n",
            "Epoch 942/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2069e-04 - mae: 0.0169 - val_loss: 5.6658e-04 - val_mae: 0.0198\n",
            "Epoch 943/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2591e-04 - mae: 0.0189 - val_loss: 4.2847e-04 - val_mae: 0.0148\n",
            "Epoch 944/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3577e-04 - mae: 0.0115 - val_loss: 2.6566e-04 - val_mae: 0.0117\n",
            "Epoch 945/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5494e-04 - mae: 0.0119 - val_loss: 2.8394e-04 - val_mae: 0.0125\n",
            "Epoch 946/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4730e-04 - mae: 0.0117 - val_loss: 4.3265e-04 - val_mae: 0.0139\n",
            "Epoch 947/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8570e-04 - mae: 0.0148 - val_loss: 4.8581e-04 - val_mae: 0.0160\n",
            "Epoch 948/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0193e-04 - mae: 0.0169 - val_loss: 7.7292e-04 - val_mae: 0.0211\n",
            "Epoch 949/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9025e-04 - mae: 0.0169 - val_loss: 5.4736e-04 - val_mae: 0.0178\n",
            "Epoch 950/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1504e-04 - mae: 0.0153 - val_loss: 3.2601e-04 - val_mae: 0.0135\n",
            "Epoch 951/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.4044e-04 - mae: 0.0143 - val_loss: 2.7083e-04 - val_mae: 0.0115\n",
            "Epoch 952/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2420e-04 - mae: 0.0155 - val_loss: 7.9694e-04 - val_mae: 0.0215\n",
            "Epoch 953/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3462e-04 - mae: 0.0175 - val_loss: 6.8194e-04 - val_mae: 0.0193\n",
            "Epoch 954/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3365e-04 - mae: 0.0174 - val_loss: 5.1457e-04 - val_mae: 0.0167\n",
            "Epoch 955/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9222e-04 - mae: 0.0147 - val_loss: 7.6010e-04 - val_mae: 0.0214\n",
            "Epoch 956/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1217e-04 - mae: 0.0206 - val_loss: 5.9699e-04 - val_mae: 0.0204\n",
            "Epoch 957/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.0307e-04 - mae: 0.0220 - val_loss: 5.0646e-04 - val_mae: 0.0152\n",
            "Epoch 958/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.4251e-04 - mae: 0.0209 - val_loss: 8.0531e-04 - val_mae: 0.0209\n",
            "Epoch 959/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3502e-04 - mae: 0.0211 - val_loss: 7.8841e-04 - val_mae: 0.0197\n",
            "Epoch 960/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 6.3267e-04 - val_mae: 0.0177\n",
            "Epoch 961/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1716e-04 - mae: 0.0207 - val_loss: 6.5472e-04 - val_mae: 0.0216\n",
            "Epoch 962/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0321e-04 - mae: 0.0193 - val_loss: 6.4390e-04 - val_mae: 0.0177\n",
            "Epoch 963/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9826e-04 - mae: 0.0131 - val_loss: 4.0921e-04 - val_mae: 0.0151\n",
            "Epoch 964/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9369e-04 - mae: 0.0148 - val_loss: 4.7597e-04 - val_mae: 0.0165\n",
            "Epoch 965/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4418e-04 - mae: 0.0139 - val_loss: 3.6519e-04 - val_mae: 0.0127\n",
            "Epoch 966/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1633e-04 - mae: 0.0133 - val_loss: 3.6398e-04 - val_mae: 0.0130\n",
            "Epoch 967/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9258e-04 - mae: 0.0151 - val_loss: 4.2871e-04 - val_mae: 0.0176\n",
            "Epoch 968/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9103e-04 - mae: 0.0130 - val_loss: 7.1635e-04 - val_mae: 0.0182\n",
            "Epoch 969/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9323e-04 - mae: 0.0133 - val_loss: 3.1838e-04 - val_mae: 0.0141\n",
            "Epoch 970/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8237e-04 - mae: 0.0128 - val_loss: 3.2619e-04 - val_mae: 0.0132\n",
            "Epoch 971/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4395e-04 - mae: 0.0119 - val_loss: 5.8324e-04 - val_mae: 0.0160\n",
            "Epoch 972/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4586e-04 - mae: 0.0154 - val_loss: 9.5360e-04 - val_mae: 0.0241\n",
            "Epoch 973/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0027 - val_mae: 0.0404\n",
            "Epoch 974/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0373 - val_loss: 0.0013 - val_mae: 0.0306\n",
            "Epoch 975/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5205e-04 - mae: 0.0224 - val_loss: 7.9624e-04 - val_mae: 0.0194\n",
            "Epoch 976/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0074e-04 - mae: 0.0184 - val_loss: 5.0048e-04 - val_mae: 0.0164\n",
            "Epoch 977/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6641e-04 - mae: 0.0196 - val_loss: 7.6469e-04 - val_mae: 0.0229\n",
            "Epoch 978/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3884e-04 - mae: 0.0161 - val_loss: 3.3341e-04 - val_mae: 0.0133\n",
            "Epoch 979/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5249e-04 - mae: 0.0121 - val_loss: 3.2559e-04 - val_mae: 0.0131\n",
            "Epoch 980/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5212e-04 - mae: 0.0139 - val_loss: 3.5956e-04 - val_mae: 0.0139\n",
            "Epoch 981/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3579e-04 - mae: 0.0115 - val_loss: 5.0039e-04 - val_mae: 0.0159\n",
            "Epoch 982/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7021e-04 - mae: 0.0124 - val_loss: 2.5612e-04 - val_mae: 0.0105\n",
            "Epoch 983/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5866e-04 - mae: 0.0122 - val_loss: 3.4618e-04 - val_mae: 0.0141\n",
            "Epoch 984/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8734e-04 - mae: 0.0140 - val_loss: 6.3110e-04 - val_mae: 0.0177\n",
            "Epoch 985/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0015 - val_mae: 0.0304\n",
            "Epoch 986/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 6.7623e-04 - val_mae: 0.0187\n",
            "Epoch 987/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0018 - val_mae: 0.0297\n",
            "Epoch 988/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 989/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.6814e-04 - mae: 0.0244 - val_loss: 9.1986e-04 - val_mae: 0.0235\n",
            "Epoch 990/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3978e-04 - mae: 0.0192 - val_loss: 6.3273e-04 - val_mae: 0.0183\n",
            "Epoch 991/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9037e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mae: 0.0243\n",
            "Epoch 992/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0688e-04 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 993/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1028e-04 - mae: 0.0216 - val_loss: 5.9415e-04 - val_mae: 0.0183\n",
            "Epoch 994/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9471e-04 - mae: 0.0169 - val_loss: 7.2513e-04 - val_mae: 0.0197\n",
            "Epoch 995/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.1498e-04 - mae: 0.0151 - val_loss: 4.7514e-04 - val_mae: 0.0161\n",
            "Epoch 996/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9750e-04 - mae: 0.0149 - val_loss: 6.9077e-04 - val_mae: 0.0202\n",
            "Epoch 997/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8196e-04 - mae: 0.0163 - val_loss: 5.1086e-04 - val_mae: 0.0146\n",
            "Epoch 998/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4687e-04 - mae: 0.0124 - val_loss: 1.9443e-04 - val_mae: 0.0090\n",
            "Epoch 999/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2440e-04 - mae: 0.0109 - val_loss: 2.7673e-04 - val_mae: 0.0116\n",
            "Epoch 1000/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4209e-04 - mae: 0.0118 - val_loss: 5.0368e-04 - val_mae: 0.0172\n",
            "Epoch 1001/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1383e-04 - mae: 0.0127 - val_loss: 3.0354e-04 - val_mae: 0.0130\n",
            "Epoch 1002/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1380e-04 - mae: 0.0111 - val_loss: 3.0439e-04 - val_mae: 0.0124\n",
            "Epoch 1003/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6573e-04 - mae: 0.0122 - val_loss: 4.6464e-04 - val_mae: 0.0162\n",
            "Epoch 1004/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6356e-04 - mae: 0.0141 - val_loss: 4.2090e-04 - val_mae: 0.0152\n",
            "Epoch 1005/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6887e-04 - mae: 0.0140 - val_loss: 3.6848e-04 - val_mae: 0.0148\n",
            "Epoch 1006/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1276e-04 - mae: 0.0108 - val_loss: 5.0918e-04 - val_mae: 0.0169\n",
            "Epoch 1007/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4395e-04 - mae: 0.0140 - val_loss: 3.5125e-04 - val_mae: 0.0126\n",
            "Epoch 1008/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0031e-04 - mae: 0.0133 - val_loss: 4.1936e-04 - val_mae: 0.0140\n",
            "Epoch 1009/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9277e-04 - mae: 0.0126 - val_loss: 2.3504e-04 - val_mae: 0.0101\n",
            "Epoch 1010/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3487e-04 - mae: 0.0169 - val_loss: 6.8856e-04 - val_mae: 0.0211\n",
            "Epoch 1011/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.2808e-04 - mae: 0.0219 - val_loss: 7.3071e-04 - val_mae: 0.0215\n",
            "Epoch 1012/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0991e-04 - mae: 0.0184 - val_loss: 3.6630e-04 - val_mae: 0.0140\n",
            "Epoch 1013/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2413e-04 - mae: 0.0183 - val_loss: 6.6792e-04 - val_mae: 0.0211\n",
            "Epoch 1014/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5539e-04 - mae: 0.0167 - val_loss: 4.1198e-04 - val_mae: 0.0125\n",
            "Epoch 1015/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4791e-04 - mae: 0.0117 - val_loss: 3.0809e-04 - val_mae: 0.0134\n",
            "Epoch 1016/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7738e-04 - mae: 0.0127 - val_loss: 4.8636e-04 - val_mae: 0.0153\n",
            "Epoch 1017/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8174e-04 - mae: 0.0168 - val_loss: 5.8356e-04 - val_mae: 0.0168\n",
            "Epoch 1018/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6759e-04 - mae: 0.0176 - val_loss: 6.8526e-04 - val_mae: 0.0185\n",
            "Epoch 1019/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1997e-04 - mae: 0.0208 - val_loss: 3.5247e-04 - val_mae: 0.0128\n",
            "Epoch 1020/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8164e-04 - mae: 0.0129 - val_loss: 4.1699e-04 - val_mae: 0.0161\n",
            "Epoch 1021/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4158e-04 - mae: 0.0198 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 1022/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5289e-04 - mae: 0.0157 - val_loss: 4.2338e-04 - val_mae: 0.0150\n",
            "Epoch 1023/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2810e-04 - mae: 0.0141 - val_loss: 5.1205e-04 - val_mae: 0.0180\n",
            "Epoch 1024/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6590e-04 - mae: 0.0185 - val_loss: 3.4886e-04 - val_mae: 0.0145\n",
            "Epoch 1025/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9920e-04 - mae: 0.0168 - val_loss: 4.2104e-04 - val_mae: 0.0155\n",
            "Epoch 1026/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0535e-04 - mae: 0.0151 - val_loss: 3.5379e-04 - val_mae: 0.0127\n",
            "Epoch 1027/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4489e-04 - mae: 0.0117 - val_loss: 3.0440e-04 - val_mae: 0.0119\n",
            "Epoch 1028/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9639e-04 - mae: 0.0127 - val_loss: 3.1669e-04 - val_mae: 0.0125\n",
            "Epoch 1029/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4480e-04 - mae: 0.0153 - val_loss: 6.4340e-04 - val_mae: 0.0192\n",
            "Epoch 1030/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0549e-04 - mae: 0.0187 - val_loss: 7.5403e-04 - val_mae: 0.0208\n",
            "Epoch 1031/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3064e-04 - mae: 0.0139 - val_loss: 8.1094e-04 - val_mae: 0.0202\n",
            "Epoch 1032/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7621e-04 - mae: 0.0137 - val_loss: 3.0552e-04 - val_mae: 0.0113\n",
            "Epoch 1033/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3898e-04 - mae: 0.0117 - val_loss: 3.2697e-04 - val_mae: 0.0139\n",
            "Epoch 1034/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1434e-04 - mae: 0.0114 - val_loss: 2.1724e-04 - val_mae: 0.0109\n",
            "Epoch 1035/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9871e-04 - mae: 0.0128 - val_loss: 5.4967e-04 - val_mae: 0.0161\n",
            "Epoch 1036/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8746e-04 - mae: 0.0126 - val_loss: 2.8257e-04 - val_mae: 0.0109\n",
            "Epoch 1037/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8569e-04 - mae: 0.0168 - val_loss: 4.7402e-04 - val_mae: 0.0158\n",
            "Epoch 1038/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2983e-04 - mae: 0.0156 - val_loss: 7.3176e-04 - val_mae: 0.0200\n",
            "Epoch 1039/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 6.6037e-04 - val_mae: 0.0193\n",
            "Epoch 1040/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 1041/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2904e-04 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0273\n",
            "Epoch 1042/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1194e-04 - mae: 0.0221 - val_loss: 6.7374e-04 - val_mae: 0.0174\n",
            "Epoch 1043/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2968e-04 - mae: 0.0190 - val_loss: 0.0012 - val_mae: 0.0303\n",
            "Epoch 1044/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8245e-04 - mae: 0.0162 - val_loss: 2.7748e-04 - val_mae: 0.0133\n",
            "Epoch 1045/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9201e-04 - mae: 0.0109 - val_loss: 2.3907e-04 - val_mae: 0.0108\n",
            "Epoch 1046/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5459e-04 - mae: 0.0120 - val_loss: 3.9476e-04 - val_mae: 0.0137\n",
            "Epoch 1047/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1460e-04 - mae: 0.0111 - val_loss: 2.0630e-04 - val_mae: 0.0102\n",
            "Epoch 1048/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7692e-04 - mae: 0.0099 - val_loss: 2.9517e-04 - val_mae: 0.0120\n",
            "Epoch 1049/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9876e-04 - mae: 0.0108 - val_loss: 2.6494e-04 - val_mae: 0.0118\n",
            "Epoch 1050/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3547e-04 - mae: 0.0138 - val_loss: 3.3212e-04 - val_mae: 0.0150\n",
            "Epoch 1051/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8013e-04 - mae: 0.0188 - val_loss: 5.4313e-04 - val_mae: 0.0187\n",
            "Epoch 1052/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1082e-04 - mae: 0.0150 - val_loss: 7.7240e-04 - val_mae: 0.0203\n",
            "Epoch 1053/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2791e-04 - mae: 0.0161 - val_loss: 5.6242e-04 - val_mae: 0.0177\n",
            "Epoch 1054/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4759e-04 - mae: 0.0136 - val_loss: 4.6475e-04 - val_mae: 0.0166\n",
            "Epoch 1055/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0549e-04 - mae: 0.0133 - val_loss: 2.7862e-04 - val_mae: 0.0124\n",
            "Epoch 1056/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1035e-04 - mae: 0.0111 - val_loss: 3.3688e-04 - val_mae: 0.0136\n",
            "Epoch 1057/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0421e-04 - mae: 0.0108 - val_loss: 2.9334e-04 - val_mae: 0.0123\n",
            "Epoch 1058/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2982e-04 - mae: 0.0134 - val_loss: 5.4888e-04 - val_mae: 0.0158\n",
            "Epoch 1059/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0954e-04 - mae: 0.0136 - val_loss: 3.6489e-04 - val_mae: 0.0134\n",
            "Epoch 1060/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1094e-04 - mae: 0.0108 - val_loss: 3.1211e-04 - val_mae: 0.0116\n",
            "Epoch 1061/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4189e-04 - mae: 0.0119 - val_loss: 2.3538e-04 - val_mae: 0.0111\n",
            "Epoch 1062/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1988e-04 - mae: 0.0132 - val_loss: 4.6139e-04 - val_mae: 0.0161\n",
            "Epoch 1063/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.6929e-04 - mae: 0.0217 - val_loss: 7.4568e-04 - val_mae: 0.0220\n",
            "Epoch 1064/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0022 - val_mae: 0.0409\n",
            "Epoch 1065/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0364 - val_loss: 0.0013 - val_mae: 0.0255\n",
            "Epoch 1066/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9485e-04 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0222\n",
            "Epoch 1067/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0856e-04 - mae: 0.0206 - val_loss: 6.4720e-04 - val_mae: 0.0192\n",
            "Epoch 1068/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.2810e-04 - mae: 0.0200 - val_loss: 8.4028e-04 - val_mae: 0.0204\n",
            "Epoch 1069/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6883e-04 - mae: 0.0178 - val_loss: 2.1337e-04 - val_mae: 0.0101\n",
            "Epoch 1070/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0085e-04 - mae: 0.0104 - val_loss: 4.0317e-04 - val_mae: 0.0132\n",
            "Epoch 1071/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0351e-04 - mae: 0.0110 - val_loss: 2.6132e-04 - val_mae: 0.0103\n",
            "Epoch 1072/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3599e-04 - mae: 0.0131 - val_loss: 5.5522e-04 - val_mae: 0.0171\n",
            "Epoch 1073/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 5.7397e-04 - val_mae: 0.0192\n",
            "Epoch 1074/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4016e-04 - mae: 0.0203 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 1075/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9770e-04 - mae: 0.0233 - val_loss: 5.6786e-04 - val_mae: 0.0169\n",
            "Epoch 1076/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6824e-04 - mae: 0.0144 - val_loss: 4.0747e-04 - val_mae: 0.0169\n",
            "Epoch 1077/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0332e-04 - mae: 0.0108 - val_loss: 3.1136e-04 - val_mae: 0.0132\n",
            "Epoch 1078/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3455e-04 - mae: 0.0118 - val_loss: 3.6528e-04 - val_mae: 0.0147\n",
            "Epoch 1079/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1970e-04 - mae: 0.0113 - val_loss: 4.3558e-04 - val_mae: 0.0151\n",
            "Epoch 1080/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7422e-04 - mae: 0.0138 - val_loss: 3.8721e-04 - val_mae: 0.0149\n",
            "Epoch 1081/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0826e-04 - mae: 0.0134 - val_loss: 6.3293e-04 - val_mae: 0.0190\n",
            "Epoch 1082/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1871e-04 - mae: 0.0136 - val_loss: 2.6837e-04 - val_mae: 0.0110\n",
            "Epoch 1083/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7987e-04 - mae: 0.0100 - val_loss: 2.4191e-04 - val_mae: 0.0106\n",
            "Epoch 1084/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7541e-04 - mae: 0.0103 - val_loss: 2.8281e-04 - val_mae: 0.0108\n",
            "Epoch 1085/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3129e-04 - mae: 0.0116 - val_loss: 3.3431e-04 - val_mae: 0.0130\n",
            "Epoch 1086/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6474e-04 - mae: 0.0147 - val_loss: 0.0012 - val_mae: 0.0287\n",
            "Epoch 1087/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0018 - val_mae: 0.0307\n",
            "Epoch 1088/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6780e-04 - mae: 0.0192 - val_loss: 4.7699e-04 - val_mae: 0.0159\n",
            "Epoch 1089/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2648e-04 - mae: 0.0152 - val_loss: 2.5014e-04 - val_mae: 0.0108\n",
            "Epoch 1090/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2942e-04 - mae: 0.0114 - val_loss: 3.0269e-04 - val_mae: 0.0121\n",
            "Epoch 1091/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5446e-04 - mae: 0.0155 - val_loss: 6.8572e-04 - val_mae: 0.0199\n",
            "Epoch 1092/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.5851e-04 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0236\n",
            "Epoch 1093/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0019 - val_mae: 0.0329\n",
            "Epoch 1094/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0020 - val_mae: 0.0330\n",
            "Epoch 1095/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0249\n",
            "Epoch 1096/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8379e-04 - mae: 0.0173 - val_loss: 5.1639e-04 - val_mae: 0.0155\n",
            "Epoch 1097/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3770e-04 - mae: 0.0119 - val_loss: 2.5009e-04 - val_mae: 0.0109\n",
            "Epoch 1098/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2076e-04 - mae: 0.0112 - val_loss: 1.9826e-04 - val_mae: 0.0092\n",
            "Epoch 1099/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6169e-04 - mae: 0.0097 - val_loss: 2.8797e-04 - val_mae: 0.0119\n",
            "Epoch 1100/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4813e-04 - mae: 0.0114 - val_loss: 4.2391e-04 - val_mae: 0.0147\n",
            "Epoch 1101/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3250e-04 - mae: 0.0113 - val_loss: 1.9801e-04 - val_mae: 0.0091\n",
            "Epoch 1102/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6653e-04 - mae: 0.0097 - val_loss: 2.9880e-04 - val_mae: 0.0123\n",
            "Epoch 1103/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2417e-04 - mae: 0.0113 - val_loss: 2.8838e-04 - val_mae: 0.0124\n",
            "Epoch 1104/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7679e-04 - mae: 0.0101 - val_loss: 2.5778e-04 - val_mae: 0.0117\n",
            "Epoch 1105/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1717e-04 - mae: 0.0182 - val_loss: 8.0030e-04 - val_mae: 0.0224\n",
            "Epoch 1106/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5928e-04 - mae: 0.0184 - val_loss: 5.3272e-04 - val_mae: 0.0175\n",
            "Epoch 1107/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9079e-04 - mae: 0.0167 - val_loss: 5.8394e-04 - val_mae: 0.0169\n",
            "Epoch 1108/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0173e-04 - mae: 0.0124 - val_loss: 2.6885e-04 - val_mae: 0.0110\n",
            "Epoch 1109/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7929e-04 - mae: 0.0123 - val_loss: 3.1657e-04 - val_mae: 0.0137\n",
            "Epoch 1110/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8798e-04 - mae: 0.0127 - val_loss: 4.1954e-04 - val_mae: 0.0150\n",
            "Epoch 1111/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1201e-04 - mae: 0.0180 - val_loss: 9.2996e-04 - val_mae: 0.0247\n",
            "Epoch 1112/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3470e-04 - mae: 0.0215 - val_loss: 4.2898e-04 - val_mae: 0.0144\n",
            "Epoch 1113/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1634e-04 - mae: 0.0158 - val_loss: 5.9815e-04 - val_mae: 0.0156\n",
            "Epoch 1114/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0299e-04 - mae: 0.0175 - val_loss: 6.2976e-04 - val_mae: 0.0188\n",
            "Epoch 1115/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3550e-04 - mae: 0.0199 - val_loss: 4.1848e-04 - val_mae: 0.0150\n",
            "Epoch 1116/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1592e-04 - mae: 0.0173 - val_loss: 5.5101e-04 - val_mae: 0.0183\n",
            "Epoch 1117/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7711e-04 - mae: 0.0161 - val_loss: 8.4886e-04 - val_mae: 0.0221\n",
            "Epoch 1118/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5859e-04 - mae: 0.0146 - val_loss: 3.2884e-04 - val_mae: 0.0129\n",
            "Epoch 1119/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9885e-04 - mae: 0.0151 - val_loss: 3.4186e-04 - val_mae: 0.0141\n",
            "Epoch 1120/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6593e-04 - mae: 0.0148 - val_loss: 3.5543e-04 - val_mae: 0.0143\n",
            "Epoch 1121/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1558e-04 - mae: 0.0112 - val_loss: 2.8379e-04 - val_mae: 0.0132\n",
            "Epoch 1122/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1635e-04 - mae: 0.0111 - val_loss: 4.9653e-04 - val_mae: 0.0142\n",
            "Epoch 1123/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4828e-04 - mae: 0.0181 - val_loss: 3.7181e-04 - val_mae: 0.0134\n",
            "Epoch 1124/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0988e-04 - mae: 0.0137 - val_loss: 2.3541e-04 - val_mae: 0.0117\n",
            "Epoch 1125/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2609e-04 - mae: 0.0157 - val_loss: 3.2011e-04 - val_mae: 0.0134\n",
            "Epoch 1126/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6945e-04 - mae: 0.0144 - val_loss: 3.5972e-04 - val_mae: 0.0136\n",
            "Epoch 1127/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0135e-04 - mae: 0.0107 - val_loss: 2.4030e-04 - val_mae: 0.0108\n",
            "Epoch 1128/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3172e-04 - mae: 0.0113 - val_loss: 5.1813e-04 - val_mae: 0.0146\n",
            "Epoch 1129/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9132e-04 - mae: 0.0146 - val_loss: 5.1572e-04 - val_mae: 0.0162\n",
            "Epoch 1130/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9480e-04 - mae: 0.0147 - val_loss: 4.5653e-04 - val_mae: 0.0163\n",
            "Epoch 1131/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5033e-04 - mae: 0.0121 - val_loss: 2.8802e-04 - val_mae: 0.0123\n",
            "Epoch 1132/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5570e-04 - mae: 0.0121 - val_loss: 5.0854e-04 - val_mae: 0.0174\n",
            "Epoch 1133/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7104e-04 - mae: 0.0126 - val_loss: 4.4937e-04 - val_mae: 0.0153\n",
            "Epoch 1134/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7950e-04 - mae: 0.0125 - val_loss: 3.8172e-04 - val_mae: 0.0148\n",
            "Epoch 1135/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7900e-04 - mae: 0.0125 - val_loss: 3.4276e-04 - val_mae: 0.0146\n",
            "Epoch 1136/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5278e-04 - mae: 0.0121 - val_loss: 2.0788e-04 - val_mae: 0.0104\n",
            "Epoch 1137/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7908e-04 - mae: 0.0101 - val_loss: 2.5086e-04 - val_mae: 0.0106\n",
            "Epoch 1138/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9529e-04 - mae: 0.0131 - val_loss: 4.8453e-04 - val_mae: 0.0162\n",
            "Epoch 1139/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6561e-04 - mae: 0.0194 - val_loss: 5.3844e-04 - val_mae: 0.0180\n",
            "Epoch 1140/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4985e-04 - mae: 0.0164 - val_loss: 3.2746e-04 - val_mae: 0.0143\n",
            "Epoch 1141/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2618e-04 - mae: 0.0187 - val_loss: 3.7869e-04 - val_mae: 0.0143\n",
            "Epoch 1142/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5628e-04 - mae: 0.0213 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 1143/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3498e-04 - mae: 0.0164 - val_loss: 7.1251e-04 - val_mae: 0.0202\n",
            "Epoch 1144/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7138e-04 - mae: 0.0141 - val_loss: 4.6412e-04 - val_mae: 0.0163\n",
            "Epoch 1145/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9336e-04 - mae: 0.0104 - val_loss: 2.3513e-04 - val_mae: 0.0106\n",
            "Epoch 1146/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3718e-04 - mae: 0.0199 - val_loss: 0.0025 - val_mae: 0.0378\n",
            "Epoch 1147/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 1148/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 0.0054 - val_mae: 0.0495\n",
            "Epoch 1149/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0344 - val_loss: 0.0034 - val_mae: 0.0442\n",
            "Epoch 1150/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 4.8076e-04 - val_mae: 0.0160\n",
            "Epoch 1151/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7935e-04 - mae: 0.0206 - val_loss: 3.6674e-04 - val_mae: 0.0153\n",
            "Epoch 1152/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7522e-04 - mae: 0.0126 - val_loss: 2.4623e-04 - val_mae: 0.0116\n",
            "Epoch 1153/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2127e-04 - mae: 0.0112 - val_loss: 2.0427e-04 - val_mae: 0.0087\n",
            "Epoch 1154/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5731e-04 - mae: 0.0118 - val_loss: 2.1813e-04 - val_mae: 0.0104\n",
            "Epoch 1155/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9630e-04 - mae: 0.0128 - val_loss: 2.8803e-04 - val_mae: 0.0119\n",
            "Epoch 1156/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.6932e-04 - mae: 0.0125 - val_loss: 2.8275e-04 - val_mae: 0.0134\n",
            "Epoch 1157/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6933e-04 - mae: 0.0124 - val_loss: 3.9748e-04 - val_mae: 0.0144\n",
            "Epoch 1158/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6986e-04 - mae: 0.0098 - val_loss: 5.7474e-04 - val_mae: 0.0163\n",
            "Epoch 1159/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6034e-04 - mae: 0.0146 - val_loss: 4.3769e-04 - val_mae: 0.0146\n",
            "Epoch 1160/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3448e-04 - mae: 0.0118 - val_loss: 4.2767e-04 - val_mae: 0.0158\n",
            "Epoch 1161/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6804e-04 - mae: 0.0146 - val_loss: 3.5924e-04 - val_mae: 0.0131\n",
            "Epoch 1162/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6005e-04 - mae: 0.0094 - val_loss: 2.3408e-04 - val_mae: 0.0111\n",
            "Epoch 1163/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0766e-04 - mae: 0.0110 - val_loss: 2.1450e-04 - val_mae: 0.0109\n",
            "Epoch 1164/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5698e-04 - mae: 0.0138 - val_loss: 4.1027e-04 - val_mae: 0.0167\n",
            "Epoch 1165/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6330e-04 - mae: 0.0125 - val_loss: 2.1699e-04 - val_mae: 0.0101\n",
            "Epoch 1166/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1707e-04 - mae: 0.0109 - val_loss: 2.9812e-04 - val_mae: 0.0114\n",
            "Epoch 1167/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7808e-04 - mae: 0.0125 - val_loss: 2.2950e-04 - val_mae: 0.0112\n",
            "Epoch 1168/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2249e-04 - mae: 0.0134 - val_loss: 4.6840e-04 - val_mae: 0.0163\n",
            "Epoch 1169/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3138e-04 - mae: 0.0112 - val_loss: 2.1766e-04 - val_mae: 0.0101\n",
            "Epoch 1170/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2324e-04 - mae: 0.0084 - val_loss: 2.0543e-04 - val_mae: 0.0094\n",
            "Epoch 1171/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8992e-04 - mae: 0.0104 - val_loss: 3.1074e-04 - val_mae: 0.0122\n",
            "Epoch 1172/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7046e-04 - mae: 0.0149 - val_loss: 5.3409e-04 - val_mae: 0.0157\n",
            "Epoch 1173/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9569e-04 - mae: 0.0153 - val_loss: 5.7945e-04 - val_mae: 0.0181\n",
            "Epoch 1174/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9453e-04 - mae: 0.0126 - val_loss: 4.5665e-04 - val_mae: 0.0147\n",
            "Epoch 1175/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6143e-04 - mae: 0.0147 - val_loss: 6.6258e-04 - val_mae: 0.0204\n",
            "Epoch 1176/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 0.0026 - val_mae: 0.0405\n",
            "Epoch 1177/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 7.1552e-04 - val_mae: 0.0196\n",
            "Epoch 1178/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7178e-04 - mae: 0.0122 - val_loss: 2.7265e-04 - val_mae: 0.0117\n",
            "Epoch 1179/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.5209e-04 - mae: 0.0142 - val_loss: 2.6569e-04 - val_mae: 0.0117\n",
            "Epoch 1180/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0018 - val_mae: 0.0315\n",
            "Epoch 1181/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0340 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 1182/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1014e-04 - mae: 0.0223 - val_loss: 3.6797e-04 - val_mae: 0.0142\n",
            "Epoch 1183/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4058e-04 - mae: 0.0114 - val_loss: 2.1760e-04 - val_mae: 0.0098\n",
            "Epoch 1184/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2353e-04 - mae: 0.0116 - val_loss: 2.3856e-04 - val_mae: 0.0110\n",
            "Epoch 1185/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8698e-04 - mae: 0.0104 - val_loss: 1.9049e-04 - val_mae: 0.0104\n",
            "Epoch 1186/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6561e-04 - mae: 0.0152 - val_loss: 4.1488e-04 - val_mae: 0.0161\n",
            "Epoch 1187/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4579e-04 - mae: 0.0133 - val_loss: 3.4281e-04 - val_mae: 0.0133\n",
            "Epoch 1188/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9830e-04 - mae: 0.0133 - val_loss: 5.1109e-04 - val_mae: 0.0151\n",
            "Epoch 1189/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2705e-04 - mae: 0.0140 - val_loss: 5.8959e-04 - val_mae: 0.0161\n",
            "Epoch 1190/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4777e-04 - mae: 0.0143 - val_loss: 2.5376e-04 - val_mae: 0.0111\n",
            "Epoch 1191/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1486e-04 - mae: 0.0112 - val_loss: 4.8488e-04 - val_mae: 0.0163\n",
            "Epoch 1192/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0295e-04 - mae: 0.0109 - val_loss: 2.6845e-04 - val_mae: 0.0115\n",
            "Epoch 1193/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0502e-04 - mae: 0.0109 - val_loss: 2.1732e-04 - val_mae: 0.0108\n",
            "Epoch 1194/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5717e-04 - mae: 0.0123 - val_loss: 2.7238e-04 - val_mae: 0.0121\n",
            "Epoch 1195/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1107e-04 - mae: 0.0110 - val_loss: 3.3652e-04 - val_mae: 0.0137\n",
            "Epoch 1196/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0926e-04 - mae: 0.0114 - val_loss: 3.3146e-04 - val_mae: 0.0124\n",
            "Epoch 1197/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7703e-04 - mae: 0.0120 - val_loss: 7.6860e-04 - val_mae: 0.0221\n",
            "Epoch 1198/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6092e-04 - mae: 0.0119 - val_loss: 2.1763e-04 - val_mae: 0.0099\n",
            "Epoch 1199/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5491e-04 - mae: 0.0094 - val_loss: 3.6744e-04 - val_mae: 0.0126\n",
            "Epoch 1200/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5141e-04 - mae: 0.0141 - val_loss: 6.4136e-04 - val_mae: 0.0186\n",
            "Epoch 1201/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.2457e-04 - mae: 0.0114 - val_loss: 2.5830e-04 - val_mae: 0.0120\n",
            "Epoch 1202/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9919e-04 - mae: 0.0106 - val_loss: 2.4377e-04 - val_mae: 0.0100\n",
            "Epoch 1203/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2190e-04 - mae: 0.0110 - val_loss: 3.2321e-04 - val_mae: 0.0128\n",
            "Epoch 1204/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3138e-04 - mae: 0.0142 - val_loss: 8.2701e-04 - val_mae: 0.0225\n",
            "Epoch 1205/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 6.6745e-04 - val_mae: 0.0177\n",
            "Epoch 1206/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 1207/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0029 - val_mae: 0.0400\n",
            "Epoch 1208/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 9.9746e-04 - val_mae: 0.0236\n",
            "Epoch 1209/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0228e-04 - mae: 0.0168 - val_loss: 3.4122e-04 - val_mae: 0.0141\n",
            "Epoch 1210/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4223e-04 - mae: 0.0142 - val_loss: 5.8195e-04 - val_mae: 0.0190\n",
            "Epoch 1211/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8108e-04 - mae: 0.0124 - val_loss: 3.5614e-04 - val_mae: 0.0145\n",
            "Epoch 1212/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5056e-04 - mae: 0.0144 - val_loss: 4.2825e-04 - val_mae: 0.0155\n",
            "Epoch 1213/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2654e-04 - mae: 0.0133 - val_loss: 5.2235e-04 - val_mae: 0.0165\n",
            "Epoch 1214/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3388e-04 - mae: 0.0190 - val_loss: 0.0013 - val_mae: 0.0284\n",
            "Epoch 1215/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8495e-04 - mae: 0.0199 - val_loss: 7.6393e-04 - val_mae: 0.0208\n",
            "Epoch 1216/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 5.6946e-04 - val_mae: 0.0179\n",
            "Epoch 1217/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8328e-04 - mae: 0.0172 - val_loss: 4.7317e-04 - val_mae: 0.0175\n",
            "Epoch 1218/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.1305e-04 - mae: 0.0132 - val_loss: 3.2270e-04 - val_mae: 0.0127\n",
            "Epoch 1219/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6496e-04 - mae: 0.0122 - val_loss: 2.6655e-04 - val_mae: 0.0114\n",
            "Epoch 1220/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8992e-04 - mae: 0.0132 - val_loss: 5.7271e-04 - val_mae: 0.0160\n",
            "Epoch 1221/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 7.7576e-04 - mae: 0.0210 - val_loss: 9.7419e-04 - val_mae: 0.0208\n",
            "Epoch 1222/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8689e-04 - mae: 0.0193 - val_loss: 4.7089e-04 - val_mae: 0.0171\n",
            "Epoch 1223/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2480e-04 - mae: 0.0174 - val_loss: 3.3239e-04 - val_mae: 0.0137\n",
            "Epoch 1224/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0009e-04 - mae: 0.0165 - val_loss: 4.4682e-04 - val_mae: 0.0150\n",
            "Epoch 1225/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5451e-04 - mae: 0.0153 - val_loss: 5.4669e-04 - val_mae: 0.0157\n",
            "Epoch 1226/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7826e-04 - mae: 0.0150 - val_loss: 3.9970e-04 - val_mae: 0.0158\n",
            "Epoch 1227/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2450e-04 - mae: 0.0113 - val_loss: 2.3805e-04 - val_mae: 0.0115\n",
            "Epoch 1228/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7122e-04 - mae: 0.0100 - val_loss: 2.1173e-04 - val_mae: 0.0103\n",
            "Epoch 1229/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0732e-04 - mae: 0.0110 - val_loss: 3.3495e-04 - val_mae: 0.0126\n",
            "Epoch 1230/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5893e-04 - mae: 0.0091 - val_loss: 2.1604e-04 - val_mae: 0.0115\n",
            "Epoch 1231/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0228e-04 - mae: 0.0108 - val_loss: 3.2281e-04 - val_mae: 0.0125\n",
            "Epoch 1232/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0943e-04 - mae: 0.0111 - val_loss: 2.1443e-04 - val_mae: 0.0103\n",
            "Epoch 1233/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4928e-04 - mae: 0.0121 - val_loss: 5.7915e-04 - val_mae: 0.0192\n",
            "Epoch 1234/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5674e-04 - mae: 0.0137 - val_loss: 2.5878e-04 - val_mae: 0.0107\n",
            "Epoch 1235/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6527e-04 - mae: 0.0124 - val_loss: 5.5889e-04 - val_mae: 0.0189\n",
            "Epoch 1236/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4321e-04 - mae: 0.0119 - val_loss: 2.2564e-04 - val_mae: 0.0094\n",
            "Epoch 1237/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4256e-04 - mae: 0.0113 - val_loss: 2.5620e-04 - val_mae: 0.0117\n",
            "Epoch 1238/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9084e-04 - mae: 0.0105 - val_loss: 2.6644e-04 - val_mae: 0.0104\n",
            "Epoch 1239/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1248e-04 - mae: 0.0109 - val_loss: 2.4372e-04 - val_mae: 0.0100\n",
            "Epoch 1240/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1359e-04 - mae: 0.0138 - val_loss: 4.8379e-04 - val_mae: 0.0172\n",
            "Epoch 1241/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1546e-04 - mae: 0.0166 - val_loss: 7.4020e-04 - val_mae: 0.0224\n",
            "Epoch 1242/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8793e-04 - mae: 0.0163 - val_loss: 4.3935e-04 - val_mae: 0.0158\n",
            "Epoch 1243/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7150e-04 - mae: 0.0125 - val_loss: 2.0888e-04 - val_mae: 0.0100\n",
            "Epoch 1244/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6119e-04 - mae: 0.0128 - val_loss: 0.0019 - val_mae: 0.0306\n",
            "Epoch 1245/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9290e-04 - mae: 0.0202 - val_loss: 4.6754e-04 - val_mae: 0.0163\n",
            "Epoch 1246/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7053e-04 - mae: 0.0206 - val_loss: 6.2130e-04 - val_mae: 0.0181\n",
            "Epoch 1247/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6550e-04 - mae: 0.0173 - val_loss: 5.6456e-04 - val_mae: 0.0169\n",
            "Epoch 1248/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 9.2445e-04 - val_mae: 0.0256\n",
            "Epoch 1249/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0040 - val_mae: 0.0433\n",
            "Epoch 1250/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0384 - val_loss: 0.0025 - val_mae: 0.0378\n",
            "Epoch 1251/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0330\n",
            "Epoch 1252/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0017 - val_mae: 0.0319\n",
            "Epoch 1253/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0277 - val_loss: 0.0015 - val_mae: 0.0292\n",
            "Epoch 1254/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0028 - val_mae: 0.0432\n",
            "Epoch 1255/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 7.7552e-04 - val_mae: 0.0228\n",
            "Epoch 1256/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7198e-04 - mae: 0.0141 - val_loss: 4.7641e-04 - val_mae: 0.0145\n",
            "Epoch 1257/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4715e-04 - mae: 0.0119 - val_loss: 3.2362e-04 - val_mae: 0.0123\n",
            "Epoch 1258/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5512e-04 - mae: 0.0097 - val_loss: 1.7245e-04 - val_mae: 0.0087\n",
            "Epoch 1259/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4738e-04 - mae: 0.0090 - val_loss: 2.1023e-04 - val_mae: 0.0102\n",
            "Epoch 1260/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3696e-04 - mae: 0.0086 - val_loss: 2.8190e-04 - val_mae: 0.0116\n",
            "Epoch 1261/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1092e-04 - mae: 0.0107 - val_loss: 2.6525e-04 - val_mae: 0.0118\n",
            "Epoch 1262/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7669e-04 - mae: 0.0099 - val_loss: 2.1020e-04 - val_mae: 0.0105\n",
            "Epoch 1263/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2244e-04 - mae: 0.0081 - val_loss: 1.6032e-04 - val_mae: 0.0087\n",
            "Epoch 1264/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2008e-04 - mae: 0.0081 - val_loss: 2.1067e-04 - val_mae: 0.0097\n",
            "Epoch 1265/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4431e-04 - mae: 0.0089 - val_loss: 1.5940e-04 - val_mae: 0.0082\n",
            "Epoch 1266/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2901e-04 - mae: 0.0082 - val_loss: 1.6944e-04 - val_mae: 0.0089\n",
            "Epoch 1267/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2021e-04 - mae: 0.0080 - val_loss: 1.9918e-04 - val_mae: 0.0093\n",
            "Epoch 1268/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1435e-04 - mae: 0.0077 - val_loss: 2.4733e-04 - val_mae: 0.0107\n",
            "Epoch 1269/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7089e-04 - mae: 0.0113 - val_loss: 4.9162e-04 - val_mae: 0.0159\n",
            "Epoch 1270/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1343e-04 - mae: 0.0132 - val_loss: 1.8592e-04 - val_mae: 0.0096\n",
            "Epoch 1271/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5852e-04 - mae: 0.0095 - val_loss: 1.7729e-04 - val_mae: 0.0090\n",
            "Epoch 1272/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1070e-04 - mae: 0.0076 - val_loss: 2.5664e-04 - val_mae: 0.0118\n",
            "Epoch 1273/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2615e-04 - mae: 0.0110 - val_loss: 4.4465e-04 - val_mae: 0.0125\n",
            "Epoch 1274/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9562e-04 - mae: 0.0151 - val_loss: 6.7353e-04 - val_mae: 0.0174\n",
            "Epoch 1275/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6367e-04 - mae: 0.0207 - val_loss: 7.1746e-04 - val_mae: 0.0198\n",
            "Epoch 1276/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7098e-04 - mae: 0.0209 - val_loss: 6.6402e-04 - val_mae: 0.0182\n",
            "Epoch 1277/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2920e-04 - mae: 0.0133 - val_loss: 2.0523e-04 - val_mae: 0.0101\n",
            "Epoch 1278/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1685e-04 - mae: 0.0111 - val_loss: 3.6049e-04 - val_mae: 0.0147\n",
            "Epoch 1279/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4358e-04 - mae: 0.0116 - val_loss: 2.7161e-04 - val_mae: 0.0118\n",
            "Epoch 1280/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6295e-04 - mae: 0.0096 - val_loss: 2.3279e-04 - val_mae: 0.0105\n",
            "Epoch 1281/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2408e-04 - mae: 0.0112 - val_loss: 2.7672e-04 - val_mae: 0.0119\n",
            "Epoch 1282/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8047e-04 - mae: 0.0099 - val_loss: 2.8974e-04 - val_mae: 0.0122\n",
            "Epoch 1283/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7662e-04 - mae: 0.0103 - val_loss: 2.4178e-04 - val_mae: 0.0103\n",
            "Epoch 1284/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1068e-04 - mae: 0.0133 - val_loss: 3.4812e-04 - val_mae: 0.0140\n",
            "Epoch 1285/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4974e-04 - mae: 0.0136 - val_loss: 3.5493e-04 - val_mae: 0.0129\n",
            "Epoch 1286/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5299e-04 - mae: 0.0161 - val_loss: 3.4454e-04 - val_mae: 0.0127\n",
            "Epoch 1287/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0017 - val_mae: 0.0271\n",
            "Epoch 1288/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 5.1741e-04 - val_mae: 0.0162\n",
            "Epoch 1289/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9595e-04 - mae: 0.0226 - val_loss: 4.3626e-04 - val_mae: 0.0160\n",
            "Epoch 1290/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2883e-04 - mae: 0.0196 - val_loss: 5.5227e-04 - val_mae: 0.0189\n",
            "Epoch 1291/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6471e-04 - mae: 0.0121 - val_loss: 4.9506e-04 - val_mae: 0.0168\n",
            "Epoch 1292/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1681e-04 - mae: 0.0163 - val_loss: 7.6989e-04 - val_mae: 0.0227\n",
            "Epoch 1293/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1985e-04 - mae: 0.0111 - val_loss: 2.3960e-04 - val_mae: 0.0097\n",
            "Epoch 1294/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9288e-04 - mae: 0.0125 - val_loss: 4.2453e-04 - val_mae: 0.0162\n",
            "Epoch 1295/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8860e-04 - mae: 0.0130 - val_loss: 3.1035e-04 - val_mae: 0.0121\n",
            "Epoch 1296/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3216e-04 - mae: 0.0086 - val_loss: 1.9670e-04 - val_mae: 0.0089\n",
            "Epoch 1297/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.0017e-04 - mae: 0.0106 - val_loss: 3.7345e-04 - val_mae: 0.0149\n",
            "Epoch 1298/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2258e-04 - mae: 0.0158 - val_loss: 5.1968e-04 - val_mae: 0.0161\n",
            "Epoch 1299/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7408e-04 - mae: 0.0186 - val_loss: 6.5704e-04 - val_mae: 0.0184\n",
            "Epoch 1300/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4691e-04 - mae: 0.0117 - val_loss: 2.5384e-04 - val_mae: 0.0102\n",
            "Epoch 1301/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7876e-04 - mae: 0.0102 - val_loss: 4.3421e-04 - val_mae: 0.0155\n",
            "Epoch 1302/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8477e-04 - mae: 0.0099 - val_loss: 3.3105e-04 - val_mae: 0.0143\n",
            "Epoch 1303/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1747e-04 - mae: 0.0113 - val_loss: 2.6439e-04 - val_mae: 0.0123\n",
            "Epoch 1304/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2002e-04 - mae: 0.0116 - val_loss: 4.6774e-04 - val_mae: 0.0167\n",
            "Epoch 1305/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.0184e-04 - mae: 0.0135 - val_loss: 5.3827e-04 - val_mae: 0.0174\n",
            "Epoch 1306/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9038e-04 - mae: 0.0147 - val_loss: 4.0783e-04 - val_mae: 0.0147\n",
            "Epoch 1307/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5709e-04 - mae: 0.0144 - val_loss: 2.3680e-04 - val_mae: 0.0115\n",
            "Epoch 1308/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6594e-04 - mae: 0.0143 - val_loss: 5.9613e-04 - val_mae: 0.0174\n",
            "Epoch 1309/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3376e-04 - mae: 0.0152 - val_loss: 3.6993e-04 - val_mae: 0.0148\n",
            "Epoch 1310/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7597e-04 - mae: 0.0148 - val_loss: 5.5150e-04 - val_mae: 0.0174\n",
            "Epoch 1311/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0059e-04 - mae: 0.0144 - val_loss: 4.6503e-04 - val_mae: 0.0139\n",
            "Epoch 1312/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9491e-04 - mae: 0.0105 - val_loss: 3.4131e-04 - val_mae: 0.0140\n",
            "Epoch 1313/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2824e-04 - mae: 0.0140 - val_loss: 8.2387e-04 - val_mae: 0.0203\n",
            "Epoch 1314/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0906e-04 - mae: 0.0131 - val_loss: 5.9918e-04 - val_mae: 0.0166\n",
            "Epoch 1315/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9962e-04 - mae: 0.0184 - val_loss: 4.9225e-04 - val_mae: 0.0174\n",
            "Epoch 1316/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5575e-04 - mae: 0.0145 - val_loss: 3.6950e-04 - val_mae: 0.0139\n",
            "Epoch 1317/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3233e-04 - mae: 0.0118 - val_loss: 2.5122e-04 - val_mae: 0.0116\n",
            "Epoch 1318/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9687e-04 - mae: 0.0108 - val_loss: 3.4106e-04 - val_mae: 0.0126\n",
            "Epoch 1319/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0706e-04 - mae: 0.0191 - val_loss: 0.0036 - val_mae: 0.0453\n",
            "Epoch 1320/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0289 - val_loss: 7.1738e-04 - val_mae: 0.0209\n",
            "Epoch 1321/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 5.4494e-04 - val_mae: 0.0182\n",
            "Epoch 1322/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.9594e-04 - mae: 0.0205 - val_loss: 9.3184e-04 - val_mae: 0.0239\n",
            "Epoch 1323/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8879e-04 - mae: 0.0170 - val_loss: 7.3257e-04 - val_mae: 0.0214\n",
            "Epoch 1324/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8017e-04 - mae: 0.0152 - val_loss: 3.4418e-04 - val_mae: 0.0129\n",
            "Epoch 1325/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5561e-04 - mae: 0.0123 - val_loss: 4.0014e-04 - val_mae: 0.0147\n",
            "Epoch 1326/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1222e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0238\n",
            "Epoch 1327/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0330e-04 - mae: 0.0131 - val_loss: 3.1407e-04 - val_mae: 0.0129\n",
            "Epoch 1328/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9328e-04 - mae: 0.0108 - val_loss: 4.4714e-04 - val_mae: 0.0153\n",
            "Epoch 1329/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7498e-04 - mae: 0.0099 - val_loss: 1.8667e-04 - val_mae: 0.0101\n",
            "Epoch 1330/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2121e-04 - mae: 0.0107 - val_loss: 3.1468e-04 - val_mae: 0.0142\n",
            "Epoch 1331/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1494e-04 - mae: 0.0135 - val_loss: 2.2246e-04 - val_mae: 0.0111\n",
            "Epoch 1332/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4243e-04 - mae: 0.0117 - val_loss: 4.0406e-04 - val_mae: 0.0140\n",
            "Epoch 1333/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.6015e-04 - mae: 0.0122 - val_loss: 3.8134e-04 - val_mae: 0.0144\n",
            "Epoch 1334/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0257e-04 - mae: 0.0106 - val_loss: 4.7189e-04 - val_mae: 0.0149\n",
            "Epoch 1335/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6966e-04 - mae: 0.0140 - val_loss: 9.5666e-04 - val_mae: 0.0228\n",
            "Epoch 1336/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5476e-04 - mae: 0.0144 - val_loss: 5.6656e-04 - val_mae: 0.0169\n",
            "Epoch 1337/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8017e-04 - mae: 0.0156 - val_loss: 5.4928e-04 - val_mae: 0.0154\n",
            "Epoch 1338/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6141e-04 - mae: 0.0181 - val_loss: 8.5970e-04 - val_mae: 0.0194\n",
            "Epoch 1339/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0029 - val_mae: 0.0444\n",
            "Epoch 1340/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0284 - val_loss: 6.3561e-04 - val_mae: 0.0171\n",
            "Epoch 1341/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3837e-04 - mae: 0.0192 - val_loss: 3.1144e-04 - val_mae: 0.0133\n",
            "Epoch 1342/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8542e-04 - mae: 0.0161 - val_loss: 3.6630e-04 - val_mae: 0.0138\n",
            "Epoch 1343/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2940e-04 - mae: 0.0141 - val_loss: 4.8013e-04 - val_mae: 0.0160\n",
            "Epoch 1344/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1624e-04 - mae: 0.0115 - val_loss: 2.1595e-04 - val_mae: 0.0104\n",
            "Epoch 1345/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6310e-04 - mae: 0.0096 - val_loss: 2.6749e-04 - val_mae: 0.0117\n",
            "Epoch 1346/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5609e-04 - mae: 0.0134 - val_loss: 2.4937e-04 - val_mae: 0.0114\n",
            "Epoch 1347/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4569e-04 - mae: 0.0119 - val_loss: 2.8340e-04 - val_mae: 0.0124\n",
            "Epoch 1348/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0488e-04 - mae: 0.0128 - val_loss: 2.3669e-04 - val_mae: 0.0109\n",
            "Epoch 1349/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8893e-04 - mae: 0.0102 - val_loss: 3.0529e-04 - val_mae: 0.0115\n",
            "Epoch 1350/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5558e-04 - mae: 0.0119 - val_loss: 3.3521e-04 - val_mae: 0.0134\n",
            "Epoch 1351/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1957e-04 - mae: 0.0111 - val_loss: 2.8594e-04 - val_mae: 0.0119\n",
            "Epoch 1352/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5782e-04 - mae: 0.0143 - val_loss: 4.3289e-04 - val_mae: 0.0158\n",
            "Epoch 1353/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5440e-04 - mae: 0.0167 - val_loss: 5.6123e-04 - val_mae: 0.0188\n",
            "Epoch 1354/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8680e-04 - mae: 0.0185 - val_loss: 5.1223e-04 - val_mae: 0.0176\n",
            "Epoch 1355/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7139e-04 - mae: 0.0199 - val_loss: 9.3251e-04 - val_mae: 0.0218\n",
            "Epoch 1356/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3246e-04 - mae: 0.0150 - val_loss: 6.4224e-04 - val_mae: 0.0194\n",
            "Epoch 1357/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3973e-04 - mae: 0.0149 - val_loss: 4.0373e-04 - val_mae: 0.0154\n",
            "Epoch 1358/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5281e-04 - mae: 0.0139 - val_loss: 5.5416e-04 - val_mae: 0.0182\n",
            "Epoch 1359/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6676e-04 - mae: 0.0175 - val_loss: 4.7475e-04 - val_mae: 0.0149\n",
            "Epoch 1360/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3200e-04 - mae: 0.0163 - val_loss: 4.4599e-04 - val_mae: 0.0147\n",
            "Epoch 1361/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.2646e-04 - mae: 0.0154 - val_loss: 3.6475e-04 - val_mae: 0.0139\n",
            "Epoch 1362/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6848e-04 - mae: 0.0095 - val_loss: 2.2410e-04 - val_mae: 0.0109\n",
            "Epoch 1363/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.5817e-04 - mae: 0.0095 - val_loss: 1.9792e-04 - val_mae: 0.0098\n",
            "Epoch 1364/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5791e-04 - mae: 0.0092 - val_loss: 2.7817e-04 - val_mae: 0.0108\n",
            "Epoch 1365/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1323e-04 - mae: 0.0078 - val_loss: 1.6579e-04 - val_mae: 0.0091\n",
            "Epoch 1366/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6173e-04 - mae: 0.0095 - val_loss: 2.3046e-04 - val_mae: 0.0121\n",
            "Epoch 1367/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4742e-04 - mae: 0.0093 - val_loss: 2.2053e-04 - val_mae: 0.0099\n",
            "Epoch 1368/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1217e-04 - mae: 0.0108 - val_loss: 2.7416e-04 - val_mae: 0.0132\n",
            "Epoch 1369/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4672e-04 - mae: 0.0118 - val_loss: 2.5546e-04 - val_mae: 0.0109\n",
            "Epoch 1370/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.9423e-04 - mae: 0.0218 - val_loss: 0.0034 - val_mae: 0.0438\n",
            "Epoch 1371/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0031 - val_mae: 0.0378\n",
            "Epoch 1372/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0518 - val_loss: 0.0059 - val_mae: 0.0691\n",
            "Epoch 1373/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 8.5724e-04 - val_mae: 0.0217\n",
            "Epoch 1374/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1950e-04 - mae: 0.0229 - val_loss: 0.0014 - val_mae: 0.0272\n",
            "Epoch 1375/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1366e-04 - mae: 0.0217 - val_loss: 0.0020 - val_mae: 0.0342\n",
            "Epoch 1376/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.6087e-04 - mae: 0.0238 - val_loss: 6.8373e-04 - val_mae: 0.0201\n",
            "Epoch 1377/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4341e-04 - mae: 0.0132 - val_loss: 3.2658e-04 - val_mae: 0.0131\n",
            "Epoch 1378/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0336e-04 - mae: 0.0075 - val_loss: 1.5119e-04 - val_mae: 0.0075\n",
            "Epoch 1379/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5927e-04 - mae: 0.0093 - val_loss: 3.3182e-04 - val_mae: 0.0140\n",
            "Epoch 1380/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2893e-04 - mae: 0.0114 - val_loss: 2.2524e-04 - val_mae: 0.0106\n",
            "Epoch 1381/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0788e-04 - mae: 0.0129 - val_loss: 8.5720e-04 - val_mae: 0.0221\n",
            "Epoch 1382/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1616e-04 - mae: 0.0129 - val_loss: 4.3929e-04 - val_mae: 0.0143\n",
            "Epoch 1383/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5111e-04 - mae: 0.0093 - val_loss: 1.8867e-04 - val_mae: 0.0095\n",
            "Epoch 1384/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9720e-05 - mae: 0.0075 - val_loss: 1.5205e-04 - val_mae: 0.0085\n",
            "Epoch 1385/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4960e-04 - mae: 0.0087 - val_loss: 1.6890e-04 - val_mae: 0.0087\n",
            "Epoch 1386/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1935e-04 - mae: 0.0080 - val_loss: 1.3582e-04 - val_mae: 0.0083\n",
            "Epoch 1387/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1160e-04 - mae: 0.0080 - val_loss: 2.7482e-04 - val_mae: 0.0122\n",
            "Epoch 1388/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4019e-04 - mae: 0.0087 - val_loss: 1.5225e-04 - val_mae: 0.0079\n",
            "Epoch 1389/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1942e-04 - mae: 0.0080 - val_loss: 3.0595e-04 - val_mae: 0.0126\n",
            "Epoch 1390/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4403e-04 - mae: 0.0091 - val_loss: 1.8178e-04 - val_mae: 0.0089\n",
            "Epoch 1391/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7500e-04 - mae: 0.0100 - val_loss: 2.6992e-04 - val_mae: 0.0115\n",
            "Epoch 1392/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.7088e-04 - mae: 0.0098 - val_loss: 2.0537e-04 - val_mae: 0.0113\n",
            "Epoch 1393/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5573e-04 - mae: 0.0092 - val_loss: 2.2648e-04 - val_mae: 0.0110\n",
            "Epoch 1394/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5252e-04 - mae: 0.0093 - val_loss: 2.4305e-04 - val_mae: 0.0099\n",
            "Epoch 1395/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4970e-04 - mae: 0.0093 - val_loss: 4.2684e-04 - val_mae: 0.0147\n",
            "Epoch 1396/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0250e-04 - mae: 0.0105 - val_loss: 2.9779e-04 - val_mae: 0.0107\n",
            "Epoch 1397/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5873e-04 - mae: 0.0119 - val_loss: 3.6471e-04 - val_mae: 0.0131\n",
            "Epoch 1398/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2490e-04 - mae: 0.0166 - val_loss: 4.7488e-04 - val_mae: 0.0163\n",
            "Epoch 1399/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.5767e-04 - mae: 0.0216 - val_loss: 0.0020 - val_mae: 0.0365\n",
            "Epoch 1400/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 9.6999e-04 - val_mae: 0.0237\n",
            "Epoch 1401/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 6.5793e-04 - mae: 0.0183 - val_loss: 2.8486e-04 - val_mae: 0.0112\n",
            "Epoch 1402/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.5044e-04 - mae: 0.0170 - val_loss: 7.1786e-04 - val_mae: 0.0194\n",
            "Epoch 1403/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2417e-04 - mae: 0.0136 - val_loss: 2.5639e-04 - val_mae: 0.0123\n",
            "Epoch 1404/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5027e-04 - mae: 0.0093 - val_loss: 2.0602e-04 - val_mae: 0.0108\n",
            "Epoch 1405/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3583e-04 - mae: 0.0088 - val_loss: 1.6826e-04 - val_mae: 0.0093\n",
            "Epoch 1406/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9075e-04 - mae: 0.0128 - val_loss: 2.7231e-04 - val_mae: 0.0108\n",
            "Epoch 1407/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1887e-04 - mae: 0.0109 - val_loss: 2.7551e-04 - val_mae: 0.0118\n",
            "Epoch 1408/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5842e-04 - mae: 0.0096 - val_loss: 2.4247e-04 - val_mae: 0.0117\n",
            "Epoch 1409/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4567e-04 - mae: 0.0113 - val_loss: 2.0011e-04 - val_mae: 0.0098\n",
            "Epoch 1410/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6963e-04 - mae: 0.0118 - val_loss: 3.7830e-04 - val_mae: 0.0140\n",
            "Epoch 1411/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8124e-04 - mae: 0.0217 - val_loss: 6.8440e-04 - val_mae: 0.0207\n",
            "Epoch 1412/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.9384e-04 - mae: 0.0213 - val_loss: 3.0263e-04 - val_mae: 0.0135\n",
            "Epoch 1413/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6734e-04 - mae: 0.0161 - val_loss: 6.2866e-04 - val_mae: 0.0213\n",
            "Epoch 1414/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0729e-04 - mae: 0.0198 - val_loss: 5.6430e-04 - val_mae: 0.0181\n",
            "Epoch 1415/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.8827e-04 - mae: 0.0153 - val_loss: 3.4471e-04 - val_mae: 0.0147\n",
            "Epoch 1416/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.1678e-04 - mae: 0.0155 - val_loss: 3.0249e-04 - val_mae: 0.0119\n",
            "Epoch 1417/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3435e-04 - mae: 0.0114 - val_loss: 2.6041e-04 - val_mae: 0.0109\n",
            "Epoch 1418/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6151e-04 - mae: 0.0096 - val_loss: 1.4986e-04 - val_mae: 0.0078\n",
            "Epoch 1419/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4176e-04 - mae: 0.0090 - val_loss: 2.3637e-04 - val_mae: 0.0119\n",
            "Epoch 1420/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6192e-04 - mae: 0.0125 - val_loss: 3.4118e-04 - val_mae: 0.0136\n",
            "Epoch 1421/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6611e-04 - mae: 0.0147 - val_loss: 6.0953e-04 - val_mae: 0.0209\n",
            "Epoch 1422/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5383e-04 - mae: 0.0167 - val_loss: 2.2028e-04 - val_mae: 0.0100\n",
            "Epoch 1423/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1289e-04 - mae: 0.0109 - val_loss: 3.2781e-04 - val_mae: 0.0117\n",
            "Epoch 1424/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.9749e-04 - mae: 0.0130 - val_loss: 1.9026e-04 - val_mae: 0.0095\n",
            "Epoch 1425/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7053e-04 - mae: 0.0124 - val_loss: 6.6821e-04 - val_mae: 0.0212\n",
            "Epoch 1426/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.9677e-04 - mae: 0.0145 - val_loss: 1.8482e-04 - val_mae: 0.0092\n",
            "Epoch 1427/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0323e-04 - mae: 0.0124 - val_loss: 3.5342e-04 - val_mae: 0.0139\n",
            "Epoch 1428/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8892e-04 - mae: 0.0103 - val_loss: 2.2573e-04 - val_mae: 0.0106\n",
            "Epoch 1429/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7802e-04 - mae: 0.0123 - val_loss: 2.3155e-04 - val_mae: 0.0112\n",
            "Epoch 1430/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5957e-04 - mae: 0.0095 - val_loss: 1.7139e-04 - val_mae: 0.0086\n",
            "Epoch 1431/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1417e-04 - mae: 0.0076 - val_loss: 1.9926e-04 - val_mae: 0.0096\n",
            "Epoch 1432/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7921e-04 - mae: 0.0101 - val_loss: 3.9138e-04 - val_mae: 0.0136\n",
            "Epoch 1433/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7705e-04 - mae: 0.0100 - val_loss: 2.0120e-04 - val_mae: 0.0103\n",
            "Epoch 1434/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3700e-04 - mae: 0.0111 - val_loss: 2.2925e-04 - val_mae: 0.0104\n",
            "Epoch 1435/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8507e-04 - mae: 0.0218 - val_loss: 0.0020 - val_mae: 0.0371\n",
            "Epoch 1436/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0306 - val_loss: 9.8526e-04 - val_mae: 0.0244\n",
            "Epoch 1437/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.7254e-04 - mae: 0.0201 - val_loss: 0.0014 - val_mae: 0.0276\n",
            "Epoch 1438/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0034 - val_mae: 0.0445\n",
            "Epoch 1439/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.0016 - val_mae: 0.0301\n",
            "Epoch 1440/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 4.3828e-04 - val_mae: 0.0165\n",
            "Epoch 1441/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0828e-04 - mae: 0.0155 - val_loss: 3.9476e-04 - val_mae: 0.0148\n",
            "Epoch 1442/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0887e-04 - mae: 0.0132 - val_loss: 2.6669e-04 - val_mae: 0.0115\n",
            "Epoch 1443/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3472e-04 - mae: 0.0118 - val_loss: 2.9507e-04 - val_mae: 0.0117\n",
            "Epoch 1444/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0360e-04 - mae: 0.0150 - val_loss: 3.3974e-04 - val_mae: 0.0139\n",
            "Epoch 1445/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1591e-04 - mae: 0.0137 - val_loss: 3.1597e-04 - val_mae: 0.0141\n",
            "Epoch 1446/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0881e-04 - mae: 0.0110 - val_loss: 1.8786e-04 - val_mae: 0.0098\n",
            "Epoch 1447/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7126e-04 - mae: 0.0103 - val_loss: 1.6440e-04 - val_mae: 0.0085\n",
            "Epoch 1448/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0528e-04 - mae: 0.0078 - val_loss: 1.7180e-04 - val_mae: 0.0092\n",
            "Epoch 1449/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0347e-04 - mae: 0.0076 - val_loss: 2.2946e-04 - val_mae: 0.0112\n",
            "Epoch 1450/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1537e-04 - mae: 0.0113 - val_loss: 3.8222e-04 - val_mae: 0.0169\n",
            "Epoch 1451/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6221e-04 - mae: 0.0097 - val_loss: 1.2741e-04 - val_mae: 0.0074\n",
            "Epoch 1452/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6482e-04 - mae: 0.0094 - val_loss: 2.0752e-04 - val_mae: 0.0099\n",
            "Epoch 1453/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.8911e-04 - mae: 0.0103 - val_loss: 5.2609e-04 - val_mae: 0.0141\n",
            "Epoch 1454/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0064e-04 - mae: 0.0132 - val_loss: 3.6984e-04 - val_mae: 0.0133\n",
            "Epoch 1455/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1329e-04 - mae: 0.0109 - val_loss: 1.8651e-04 - val_mae: 0.0092\n",
            "Epoch 1456/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6104e-04 - mae: 0.0096 - val_loss: 3.1956e-04 - val_mae: 0.0129\n",
            "Epoch 1457/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1664e-04 - mae: 0.0105 - val_loss: 1.8669e-04 - val_mae: 0.0094\n",
            "Epoch 1458/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2507e-04 - mae: 0.0088 - val_loss: 1.7296e-04 - val_mae: 0.0093\n",
            "Epoch 1459/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3886e-04 - mae: 0.0088 - val_loss: 2.1323e-04 - val_mae: 0.0108\n",
            "Epoch 1460/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4167e-04 - mae: 0.0090 - val_loss: 2.1791e-04 - val_mae: 0.0097\n",
            "Epoch 1461/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3587e-04 - mae: 0.0089 - val_loss: 2.8554e-04 - val_mae: 0.0109\n",
            "Epoch 1462/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3065e-04 - mae: 0.0109 - val_loss: 4.6893e-04 - val_mae: 0.0162\n",
            "Epoch 1463/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 6.5796e-04 - mae: 0.0186 - val_loss: 5.7782e-04 - val_mae: 0.0202\n",
            "Epoch 1464/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3523e-04 - mae: 0.0175 - val_loss: 2.2864e-04 - val_mae: 0.0095\n",
            "Epoch 1465/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.3776e-04 - mae: 0.0182 - val_loss: 3.6001e-04 - val_mae: 0.0131\n",
            "Epoch 1466/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6466e-04 - mae: 0.0184 - val_loss: 3.5304e-04 - val_mae: 0.0131\n",
            "Epoch 1467/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5044e-04 - mae: 0.0141 - val_loss: 3.5129e-04 - val_mae: 0.0139\n",
            "Epoch 1468/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.2102e-04 - mae: 0.0136 - val_loss: 3.3634e-04 - val_mae: 0.0122\n",
            "Epoch 1469/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7273e-04 - mae: 0.0126 - val_loss: 3.2477e-04 - val_mae: 0.0141\n",
            "Epoch 1470/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5245e-04 - mae: 0.0119 - val_loss: 6.2550e-04 - val_mae: 0.0177\n",
            "Epoch 1471/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.8945e-04 - mae: 0.0163 - val_loss: 3.1595e-04 - val_mae: 0.0128\n",
            "Epoch 1472/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9588e-04 - mae: 0.0128 - val_loss: 1.8029e-04 - val_mae: 0.0099\n",
            "Epoch 1473/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.6458e-04 - mae: 0.0136 - val_loss: 6.5346e-04 - val_mae: 0.0201\n",
            "Epoch 1474/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4178e-04 - mae: 0.0173 - val_loss: 5.1989e-04 - val_mae: 0.0167\n",
            "Epoch 1475/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3360e-04 - mae: 0.0176 - val_loss: 5.8097e-04 - val_mae: 0.0159\n",
            "Epoch 1476/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2430e-04 - mae: 0.0175 - val_loss: 5.9161e-04 - val_mae: 0.0190\n",
            "Epoch 1477/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0544e-04 - mae: 0.0189 - val_loss: 4.7317e-04 - val_mae: 0.0163\n",
            "Epoch 1478/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9984e-04 - mae: 0.0153 - val_loss: 3.9115e-04 - val_mae: 0.0155\n",
            "Epoch 1479/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0429e-04 - mae: 0.0128 - val_loss: 3.6792e-04 - val_mae: 0.0153\n",
            "Epoch 1480/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9542e-04 - mae: 0.0141 - val_loss: 2.8543e-04 - val_mae: 0.0125\n",
            "Epoch 1481/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0676e-04 - mae: 0.0130 - val_loss: 4.4992e-04 - val_mae: 0.0160\n",
            "Epoch 1482/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6274e-04 - mae: 0.0145 - val_loss: 2.1804e-04 - val_mae: 0.0110\n",
            "Epoch 1483/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4317e-04 - mae: 0.0135 - val_loss: 4.5883e-04 - val_mae: 0.0151\n",
            "Epoch 1484/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8899e-04 - mae: 0.0107 - val_loss: 1.8364e-04 - val_mae: 0.0089\n",
            "Epoch 1485/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5326e-04 - mae: 0.0092 - val_loss: 4.8088e-04 - val_mae: 0.0183\n",
            "Epoch 1486/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8972e-04 - mae: 0.0132 - val_loss: 4.9249e-04 - val_mae: 0.0175\n",
            "Epoch 1487/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2204e-04 - mae: 0.0173 - val_loss: 2.1133e-04 - val_mae: 0.0102\n",
            "Epoch 1488/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7695e-04 - mae: 0.0146 - val_loss: 2.3294e-04 - val_mae: 0.0115\n",
            "Epoch 1489/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.3330e-04 - mae: 0.0088 - val_loss: 1.7348e-04 - val_mae: 0.0083\n",
            "Epoch 1490/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3598e-04 - mae: 0.0085 - val_loss: 2.4030e-04 - val_mae: 0.0116\n",
            "Epoch 1491/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4626e-04 - mae: 0.0090 - val_loss: 2.1471e-04 - val_mae: 0.0108\n",
            "Epoch 1492/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9570e-04 - mae: 0.0107 - val_loss: 3.2293e-04 - val_mae: 0.0129\n",
            "Epoch 1493/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9461e-04 - mae: 0.0105 - val_loss: 2.5040e-04 - val_mae: 0.0119\n",
            "Epoch 1494/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6337e-04 - mae: 0.0094 - val_loss: 1.7236e-04 - val_mae: 0.0092\n",
            "Epoch 1495/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.3752e-04 - mae: 0.0112 - val_loss: 2.6093e-04 - val_mae: 0.0113\n",
            "Epoch 1496/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0030 - val_mae: 0.0482\n",
            "Epoch 1497/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 6.8578e-04 - val_mae: 0.0198\n",
            "Epoch 1498/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.8891e-04 - mae: 0.0214 - val_loss: 2.8661e-04 - val_mae: 0.0131\n",
            "Epoch 1499/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8393e-04 - mae: 0.0179 - val_loss: 4.7729e-04 - val_mae: 0.0146\n",
            "Epoch 1500/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.1217e-04 - mae: 0.0170 - val_loss: 9.1216e-04 - val_mae: 0.0252\n",
            "Epoch 1501/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.6467e-04 - mae: 0.0124 - val_loss: 1.9989e-04 - val_mae: 0.0104\n",
            "Epoch 1502/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.7049e-04 - mae: 0.0095 - val_loss: 2.0596e-04 - val_mae: 0.0098\n",
            "Epoch 1503/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6930e-04 - mae: 0.0100 - val_loss: 2.8502e-04 - val_mae: 0.0109\n",
            "Epoch 1504/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.3038e-04 - mae: 0.0086 - val_loss: 1.8698e-04 - val_mae: 0.0092\n",
            "Epoch 1505/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8256e-04 - mae: 0.0101 - val_loss: 3.3480e-04 - val_mae: 0.0133\n",
            "Epoch 1506/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4384e-04 - mae: 0.0145 - val_loss: 2.6701e-04 - val_mae: 0.0113\n",
            "Epoch 1507/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3502e-04 - mae: 0.0131 - val_loss: 7.0497e-04 - val_mae: 0.0207\n",
            "Epoch 1508/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 7.2070e-04 - mae: 0.0202 - val_loss: 4.5614e-04 - val_mae: 0.0176\n",
            "Epoch 1509/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 5.2327e-04 - mae: 0.0172 - val_loss: 4.8904e-04 - val_mae: 0.0161\n",
            "Epoch 1510/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0489e-04 - mae: 0.0154 - val_loss: 2.3779e-04 - val_mae: 0.0108\n",
            "Epoch 1511/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.2586e-04 - mae: 0.0138 - val_loss: 2.8412e-04 - val_mae: 0.0122\n",
            "Epoch 1512/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.5679e-04 - mae: 0.0119 - val_loss: 1.9911e-04 - val_mae: 0.0092\n",
            "Epoch 1513/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.4278e-04 - mae: 0.0090 - val_loss: 2.0038e-04 - val_mae: 0.0104\n",
            "Epoch 1514/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.1116e-04 - mae: 0.0078 - val_loss: 1.5079e-04 - val_mae: 0.0086\n",
            "Epoch 1515/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.5143e-04 - mae: 0.0090 - val_loss: 3.1212e-04 - val_mae: 0.0123\n",
            "Epoch 1516/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0084e-04 - mae: 0.0106 - val_loss: 3.8313e-04 - val_mae: 0.0157\n",
            "Epoch 1517/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2581e-04 - mae: 0.0136 - val_loss: 4.6315e-04 - val_mae: 0.0167\n",
            "Epoch 1518/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.4817e-04 - mae: 0.0160 - val_loss: 4.3558e-04 - val_mae: 0.0140\n",
            "Epoch 1519/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1629e-04 - mae: 0.0138 - val_loss: 3.3345e-04 - val_mae: 0.0126\n",
            "Epoch 1520/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3931e-04 - mae: 0.0116 - val_loss: 2.1493e-04 - val_mae: 0.0103\n",
            "Epoch 1521/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6980e-04 - mae: 0.0096 - val_loss: 4.3926e-04 - val_mae: 0.0166\n",
            "Epoch 1522/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4312e-04 - mae: 0.0088 - val_loss: 1.2377e-04 - val_mae: 0.0067\n",
            "Epoch 1523/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5552e-05 - mae: 0.0071 - val_loss: 1.7690e-04 - val_mae: 0.0085\n",
            "Epoch 1524/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6172e-04 - mae: 0.0096 - val_loss: 2.6175e-04 - val_mae: 0.0109\n",
            "Epoch 1525/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.3884e-04 - mae: 0.0089 - val_loss: 4.0213e-04 - val_mae: 0.0150\n",
            "Epoch 1526/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4469e-04 - mae: 0.0143 - val_loss: 2.7393e-04 - val_mae: 0.0122\n",
            "Epoch 1527/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6202e-04 - mae: 0.0096 - val_loss: 3.2867e-04 - val_mae: 0.0117\n",
            "Epoch 1528/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3103e-04 - mae: 0.0111 - val_loss: 6.5856e-04 - val_mae: 0.0208\n",
            "Epoch 1529/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2579e-04 - mae: 0.0113 - val_loss: 1.8263e-04 - val_mae: 0.0096\n",
            "Epoch 1530/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7025e-04 - mae: 0.0137 - val_loss: 7.7586e-04 - val_mae: 0.0196\n",
            "Epoch 1531/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 7.2869e-04 - val_mae: 0.0196\n",
            "Epoch 1532/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6332e-04 - mae: 0.0198 - val_loss: 6.5242e-04 - val_mae: 0.0216\n",
            "Epoch 1533/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3985e-04 - mae: 0.0170 - val_loss: 5.3425e-04 - val_mae: 0.0181\n",
            "Epoch 1534/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4136e-04 - mae: 0.0140 - val_loss: 2.4469e-04 - val_mae: 0.0120\n",
            "Epoch 1535/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3552e-04 - mae: 0.0116 - val_loss: 3.9470e-04 - val_mae: 0.0142\n",
            "Epoch 1536/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8167e-04 - mae: 0.0158 - val_loss: 7.4528e-04 - val_mae: 0.0218\n",
            "Epoch 1537/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1531e-04 - mae: 0.0166 - val_loss: 2.7228e-04 - val_mae: 0.0127\n",
            "Epoch 1538/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8580e-04 - mae: 0.0103 - val_loss: 2.1053e-04 - val_mae: 0.0101\n",
            "Epoch 1539/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4222e-04 - mae: 0.0116 - val_loss: 2.9821e-04 - val_mae: 0.0122\n",
            "Epoch 1540/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0028 - val_mae: 0.0419\n",
            "Epoch 1541/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0355 - val_loss: 5.3550e-04 - val_mae: 0.0175\n",
            "Epoch 1542/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.1782e-04 - mae: 0.0209 - val_loss: 5.1935e-04 - val_mae: 0.0188\n",
            "Epoch 1543/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2402e-04 - mae: 0.0167 - val_loss: 6.9196e-04 - val_mae: 0.0208\n",
            "Epoch 1544/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3635e-04 - mae: 0.0173 - val_loss: 4.1577e-04 - val_mae: 0.0147\n",
            "Epoch 1545/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5067e-04 - mae: 0.0120 - val_loss: 1.9510e-04 - val_mae: 0.0095\n",
            "Epoch 1546/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8980e-04 - mae: 0.0105 - val_loss: 2.9103e-04 - val_mae: 0.0121\n",
            "Epoch 1547/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5170e-04 - mae: 0.0088 - val_loss: 2.1516e-04 - val_mae: 0.0103\n",
            "Epoch 1548/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1683e-04 - mae: 0.0111 - val_loss: 3.6987e-04 - val_mae: 0.0146\n",
            "Epoch 1549/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5829e-04 - mae: 0.0120 - val_loss: 5.5151e-04 - val_mae: 0.0181\n",
            "Epoch 1550/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0885e-04 - mae: 0.0111 - val_loss: 2.4645e-04 - val_mae: 0.0110\n",
            "Epoch 1551/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8703e-04 - mae: 0.0126 - val_loss: 2.5088e-04 - val_mae: 0.0119\n",
            "Epoch 1552/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7142e-04 - mae: 0.0123 - val_loss: 2.2939e-04 - val_mae: 0.0120\n",
            "Epoch 1553/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4202e-04 - mae: 0.0118 - val_loss: 5.7562e-04 - val_mae: 0.0197\n",
            "Epoch 1554/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 1555/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 8.4443e-04 - val_mae: 0.0211\n",
            "Epoch 1556/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.8131e-04 - mae: 0.0195 - val_loss: 4.5577e-04 - val_mae: 0.0155\n",
            "Epoch 1557/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0020 - val_mae: 0.0341\n",
            "Epoch 1558/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 8.2892e-04 - val_mae: 0.0224\n",
            "Epoch 1559/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8404e-04 - mae: 0.0145 - val_loss: 3.9140e-04 - val_mae: 0.0166\n",
            "Epoch 1560/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9043e-04 - mae: 0.0108 - val_loss: 2.1518e-04 - val_mae: 0.0105\n",
            "Epoch 1561/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3313e-04 - mae: 0.0090 - val_loss: 1.6914e-04 - val_mae: 0.0087\n",
            "Epoch 1562/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5466e-04 - mae: 0.0094 - val_loss: 2.3665e-04 - val_mae: 0.0109\n",
            "Epoch 1563/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2942e-04 - mae: 0.0089 - val_loss: 2.1666e-04 - val_mae: 0.0102\n",
            "Epoch 1564/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5225e-04 - mae: 0.0096 - val_loss: 3.2612e-04 - val_mae: 0.0130\n",
            "Epoch 1565/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2101e-04 - mae: 0.0085 - val_loss: 3.4188e-04 - val_mae: 0.0124\n",
            "Epoch 1566/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.6522e-05 - mae: 0.0075 - val_loss: 1.2481e-04 - val_mae: 0.0071\n",
            "Epoch 1567/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2706e-04 - mae: 0.0083 - val_loss: 1.7487e-04 - val_mae: 0.0093\n",
            "Epoch 1568/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4467e-04 - mae: 0.0091 - val_loss: 1.9682e-04 - val_mae: 0.0099\n",
            "Epoch 1569/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2478e-04 - mae: 0.0083 - val_loss: 1.7661e-04 - val_mae: 0.0094\n",
            "Epoch 1570/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2145e-04 - mae: 0.0085 - val_loss: 1.9270e-04 - val_mae: 0.0094\n",
            "Epoch 1571/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1643e-04 - mae: 0.0084 - val_loss: 1.4964e-04 - val_mae: 0.0085\n",
            "Epoch 1572/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4935e-04 - mae: 0.0091 - val_loss: 1.8250e-04 - val_mae: 0.0086\n",
            "Epoch 1573/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4346e-04 - mae: 0.0086 - val_loss: 2.2801e-04 - val_mae: 0.0110\n",
            "Epoch 1574/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6937e-04 - mae: 0.0100 - val_loss: 2.0658e-04 - val_mae: 0.0100\n",
            "Epoch 1575/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9542e-04 - mae: 0.0106 - val_loss: 2.9926e-04 - val_mae: 0.0127\n",
            "Epoch 1576/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6874e-04 - mae: 0.0098 - val_loss: 2.2938e-04 - val_mae: 0.0110\n",
            "Epoch 1577/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3313e-04 - mae: 0.0082 - val_loss: 1.9988e-04 - val_mae: 0.0104\n",
            "Epoch 1578/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3087e-04 - mae: 0.0084 - val_loss: 2.0837e-04 - val_mae: 0.0102\n",
            "Epoch 1579/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6458e-04 - mae: 0.0098 - val_loss: 2.0760e-04 - val_mae: 0.0098\n",
            "Epoch 1580/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2561e-04 - mae: 0.0110 - val_loss: 2.3401e-04 - val_mae: 0.0110\n",
            "Epoch 1581/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5968e-04 - mae: 0.0162 - val_loss: 4.9073e-04 - val_mae: 0.0164\n",
            "Epoch 1582/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2019e-04 - mae: 0.0134 - val_loss: 8.0023e-04 - val_mae: 0.0224\n",
            "Epoch 1583/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6214e-04 - mae: 0.0145 - val_loss: 4.2246e-04 - val_mae: 0.0155\n",
            "Epoch 1584/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1392e-04 - mae: 0.0111 - val_loss: 2.6897e-04 - val_mae: 0.0119\n",
            "Epoch 1585/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5903e-04 - mae: 0.0120 - val_loss: 2.7686e-04 - val_mae: 0.0109\n",
            "Epoch 1586/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7736e-04 - mae: 0.0101 - val_loss: 2.7336e-04 - val_mae: 0.0119\n",
            "Epoch 1587/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6018e-04 - mae: 0.0097 - val_loss: 2.1785e-04 - val_mae: 0.0105\n",
            "Epoch 1588/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3227e-04 - mae: 0.0137 - val_loss: 3.4065e-04 - val_mae: 0.0132\n",
            "Epoch 1589/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7229e-04 - mae: 0.0145 - val_loss: 7.4990e-04 - val_mae: 0.0223\n",
            "Epoch 1590/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5970e-04 - mae: 0.0146 - val_loss: 6.4899e-04 - val_mae: 0.0179\n",
            "Epoch 1591/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3418e-04 - mae: 0.0135 - val_loss: 2.1079e-04 - val_mae: 0.0109\n",
            "Epoch 1592/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7659e-04 - mae: 0.0160 - val_loss: 4.5685e-04 - val_mae: 0.0169\n",
            "Epoch 1593/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1501e-04 - mae: 0.0176 - val_loss: 2.2525e-04 - val_mae: 0.0122\n",
            "Epoch 1594/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2155e-04 - mae: 0.0223 - val_loss: 4.6879e-04 - val_mae: 0.0160\n",
            "Epoch 1595/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2373e-04 - mae: 0.0115 - val_loss: 3.0406e-04 - val_mae: 0.0132\n",
            "Epoch 1596/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4841e-04 - mae: 0.0096 - val_loss: 2.0549e-04 - val_mae: 0.0106\n",
            "Epoch 1597/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3088e-04 - mae: 0.0112 - val_loss: 0.0014 - val_mae: 0.0264\n",
            "Epoch 1598/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1965e-04 - mae: 0.0187 - val_loss: 4.6378e-04 - val_mae: 0.0161\n",
            "Epoch 1599/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7565e-04 - mae: 0.0124 - val_loss: 4.1798e-04 - val_mae: 0.0161\n",
            "Epoch 1600/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5296e-04 - mae: 0.0124 - val_loss: 2.7424e-04 - val_mae: 0.0124\n",
            "Epoch 1601/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6423e-04 - mae: 0.0096 - val_loss: 1.3571e-04 - val_mae: 0.0080\n",
            "Epoch 1602/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5935e-04 - mae: 0.0095 - val_loss: 2.3650e-04 - val_mae: 0.0104\n",
            "Epoch 1603/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4175e-04 - mae: 0.0093 - val_loss: 1.1833e-04 - val_mae: 0.0066\n",
            "Epoch 1604/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5876e-05 - mae: 0.0071 - val_loss: 1.4623e-04 - val_mae: 0.0079\n",
            "Epoch 1605/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8055e-04 - mae: 0.0099 - val_loss: 1.9276e-04 - val_mae: 0.0104\n",
            "Epoch 1606/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3770e-04 - mae: 0.0119 - val_loss: 2.0249e-04 - val_mae: 0.0107\n",
            "Epoch 1607/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5238e-04 - mae: 0.0121 - val_loss: 2.3681e-04 - val_mae: 0.0099\n",
            "Epoch 1608/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3208e-04 - mae: 0.0175 - val_loss: 3.8880e-04 - val_mae: 0.0166\n",
            "Epoch 1609/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7274e-04 - mae: 0.0124 - val_loss: 2.2960e-04 - val_mae: 0.0102\n",
            "Epoch 1610/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4418e-04 - mae: 0.0116 - val_loss: 3.3299e-04 - val_mae: 0.0157\n",
            "Epoch 1611/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.1428e-04 - mae: 0.0177 - val_loss: 0.0018 - val_mae: 0.0340\n",
            "Epoch 1612/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0046 - val_mae: 0.0523\n",
            "Epoch 1613/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 7.0285e-04 - val_mae: 0.0196\n",
            "Epoch 1614/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.3866e-04 - mae: 0.0203 - val_loss: 4.2593e-04 - val_mae: 0.0153\n",
            "Epoch 1615/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2071e-04 - mae: 0.0220 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 1616/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8126e-04 - mae: 0.0178 - val_loss: 9.2180e-04 - val_mae: 0.0215\n",
            "Epoch 1617/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4629e-04 - mae: 0.0120 - val_loss: 1.5922e-04 - val_mae: 0.0077\n",
            "Epoch 1618/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.1168e-04 - mae: 0.0130 - val_loss: 2.2551e-04 - val_mae: 0.0111\n",
            "Epoch 1619/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5704e-04 - mae: 0.0113 - val_loss: 6.4112e-04 - val_mae: 0.0172\n",
            "Epoch 1620/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.6806e-04 - mae: 0.0188 - val_loss: 3.6812e-04 - val_mae: 0.0135\n",
            "Epoch 1621/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5346e-04 - mae: 0.0175 - val_loss: 5.2830e-04 - val_mae: 0.0168\n",
            "Epoch 1622/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9673e-04 - mae: 0.0153 - val_loss: 2.7637e-04 - val_mae: 0.0117\n",
            "Epoch 1623/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4588e-04 - mae: 0.0138 - val_loss: 7.5493e-04 - val_mae: 0.0213\n",
            "Epoch 1624/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 5.4690e-04 - val_mae: 0.0188\n",
            "Epoch 1625/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9888e-04 - mae: 0.0180 - val_loss: 2.5905e-04 - val_mae: 0.0126\n",
            "Epoch 1626/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9908e-04 - mae: 0.0103 - val_loss: 2.1969e-04 - val_mae: 0.0110\n",
            "Epoch 1627/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5785e-04 - mae: 0.0093 - val_loss: 1.8472e-04 - val_mae: 0.0087\n",
            "Epoch 1628/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0609e-04 - mae: 0.0076 - val_loss: 1.3763e-04 - val_mae: 0.0088\n",
            "Epoch 1629/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1296e-04 - mae: 0.0081 - val_loss: 3.6337e-04 - val_mae: 0.0143\n",
            "Epoch 1630/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7057e-04 - mae: 0.0094 - val_loss: 1.9524e-04 - val_mae: 0.0098\n",
            "Epoch 1631/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7085e-04 - mae: 0.0096 - val_loss: 2.4056e-04 - val_mae: 0.0107\n",
            "Epoch 1632/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3866e-04 - mae: 0.0114 - val_loss: 1.6714e-04 - val_mae: 0.0102\n",
            "Epoch 1633/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4600e-04 - mae: 0.0092 - val_loss: 2.9278e-04 - val_mae: 0.0121\n",
            "Epoch 1634/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2201e-04 - mae: 0.0115 - val_loss: 2.4037e-04 - val_mae: 0.0114\n",
            "Epoch 1635/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5156e-04 - mae: 0.0122 - val_loss: 3.1295e-04 - val_mae: 0.0131\n",
            "Epoch 1636/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0042e-04 - mae: 0.0162 - val_loss: 6.5093e-04 - val_mae: 0.0208\n",
            "Epoch 1637/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5223e-04 - mae: 0.0124 - val_loss: 1.3221e-04 - val_mae: 0.0074\n",
            "Epoch 1638/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2789e-04 - mae: 0.0086 - val_loss: 2.0881e-04 - val_mae: 0.0107\n",
            "Epoch 1639/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6380e-04 - mae: 0.0096 - val_loss: 2.7219e-04 - val_mae: 0.0108\n",
            "Epoch 1640/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7229e-04 - mae: 0.0151 - val_loss: 0.0011 - val_mae: 0.0276\n",
            "Epoch 1641/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3474e-04 - mae: 0.0155 - val_loss: 4.3232e-04 - val_mae: 0.0129\n",
            "Epoch 1642/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4809e-04 - mae: 0.0168 - val_loss: 5.8073e-04 - val_mae: 0.0184\n",
            "Epoch 1643/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2628e-04 - mae: 0.0132 - val_loss: 3.5816e-04 - val_mae: 0.0129\n",
            "Epoch 1644/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0271e-04 - mae: 0.0196 - val_loss: 8.2189e-04 - val_mae: 0.0229\n",
            "Epoch 1645/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 8.9308e-04 - mae: 0.0221 - val_loss: 7.2238e-04 - val_mae: 0.0175\n",
            "Epoch 1646/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 9.0867e-04 - mae: 0.0219 - val_loss: 8.5702e-04 - val_mae: 0.0236\n",
            "Epoch 1647/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.9774e-04 - mae: 0.0204 - val_loss: 6.1650e-04 - val_mae: 0.0142\n",
            "Epoch 1648/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.2834e-04 - mae: 0.0198 - val_loss: 9.4608e-04 - val_mae: 0.0251\n",
            "Epoch 1649/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0334e-04 - mae: 0.0184 - val_loss: 0.0013 - val_mae: 0.0275\n",
            "Epoch 1650/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0248e-04 - mae: 0.0232 - val_loss: 3.8498e-04 - val_mae: 0.0144\n",
            "Epoch 1651/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2172e-04 - mae: 0.0169 - val_loss: 3.3965e-04 - val_mae: 0.0134\n",
            "Epoch 1652/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0535e-04 - mae: 0.0103 - val_loss: 3.3283e-04 - val_mae: 0.0129\n",
            "Epoch 1653/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7287e-04 - mae: 0.0123 - val_loss: 2.0467e-04 - val_mae: 0.0112\n",
            "Epoch 1654/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4065e-04 - mae: 0.0111 - val_loss: 1.9517e-04 - val_mae: 0.0106\n",
            "Epoch 1655/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1628e-04 - mae: 0.0083 - val_loss: 2.9614e-04 - val_mae: 0.0121\n",
            "Epoch 1656/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2958e-04 - mae: 0.0086 - val_loss: 2.2751e-04 - val_mae: 0.0101\n",
            "Epoch 1657/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4115e-04 - mae: 0.0091 - val_loss: 2.3278e-04 - val_mae: 0.0112\n",
            "Epoch 1658/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2805e-04 - mae: 0.0085 - val_loss: 2.2444e-04 - val_mae: 0.0118\n",
            "Epoch 1659/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2179e-04 - mae: 0.0083 - val_loss: 3.7424e-04 - val_mae: 0.0149\n",
            "Epoch 1660/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1274e-04 - mae: 0.0111 - val_loss: 2.3166e-04 - val_mae: 0.0105\n",
            "Epoch 1661/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4383e-04 - mae: 0.0118 - val_loss: 6.0972e-04 - val_mae: 0.0168\n",
            "Epoch 1662/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.1784e-04 - mae: 0.0108 - val_loss: 1.6713e-04 - val_mae: 0.0087\n",
            "Epoch 1663/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3400e-04 - mae: 0.0087 - val_loss: 1.5205e-04 - val_mae: 0.0087\n",
            "Epoch 1664/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5504e-04 - mae: 0.0092 - val_loss: 2.4082e-04 - val_mae: 0.0108\n",
            "Epoch 1665/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9256e-04 - mae: 0.0106 - val_loss: 3.2100e-04 - val_mae: 0.0124\n",
            "Epoch 1666/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8813e-04 - mae: 0.0104 - val_loss: 3.4751e-04 - val_mae: 0.0123\n",
            "Epoch 1667/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7085e-04 - mae: 0.0099 - val_loss: 1.6437e-04 - val_mae: 0.0089\n",
            "Epoch 1668/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4067e-04 - mae: 0.0115 - val_loss: 7.8311e-04 - val_mae: 0.0207\n",
            "Epoch 1669/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0627e-04 - mae: 0.0196 - val_loss: 7.5695e-04 - val_mae: 0.0215\n",
            "Epoch 1670/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0021 - val_mae: 0.0344\n",
            "Epoch 1671/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0415 - val_loss: 0.0034 - val_mae: 0.0506\n",
            "Epoch 1672/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 0.0055 - val_mae: 0.0503\n",
            "Epoch 1673/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0010 - val_mae: 0.0229\n",
            "Epoch 1674/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6507e-04 - mae: 0.0168 - val_loss: 2.2867e-04 - val_mae: 0.0111\n",
            "Epoch 1675/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6671e-04 - mae: 0.0124 - val_loss: 2.1069e-04 - val_mae: 0.0113\n",
            "Epoch 1676/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8851e-04 - mae: 0.0102 - val_loss: 1.9263e-04 - val_mae: 0.0091\n",
            "Epoch 1677/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1993e-04 - mae: 0.0081 - val_loss: 1.6995e-04 - val_mae: 0.0086\n",
            "Epoch 1678/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2356e-04 - mae: 0.0084 - val_loss: 1.3220e-04 - val_mae: 0.0082\n",
            "Epoch 1679/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.1635e-05 - mae: 0.0071 - val_loss: 1.5878e-04 - val_mae: 0.0094\n",
            "Epoch 1680/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.5488e-04 - mae: 0.0093 - val_loss: 1.5159e-04 - val_mae: 0.0082\n",
            "Epoch 1681/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5891e-04 - mae: 0.0118 - val_loss: 2.3534e-04 - val_mae: 0.0126\n",
            "Epoch 1682/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1405e-04 - mae: 0.0110 - val_loss: 2.9627e-04 - val_mae: 0.0123\n",
            "Epoch 1683/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6702e-04 - mae: 0.0100 - val_loss: 1.7950e-04 - val_mae: 0.0099\n",
            "Epoch 1684/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.0773e-05 - mae: 0.0072 - val_loss: 2.0596e-04 - val_mae: 0.0101\n",
            "Epoch 1685/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0672e-04 - mae: 0.0077 - val_loss: 1.3805e-04 - val_mae: 0.0081\n",
            "Epoch 1686/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2350e-04 - mae: 0.0086 - val_loss: 1.6679e-04 - val_mae: 0.0092\n",
            "Epoch 1687/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2737e-04 - mae: 0.0083 - val_loss: 1.4328e-04 - val_mae: 0.0083\n",
            "Epoch 1688/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1144e-04 - mae: 0.0080 - val_loss: 2.3035e-04 - val_mae: 0.0107\n",
            "Epoch 1689/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1260e-04 - mae: 0.0080 - val_loss: 1.4654e-04 - val_mae: 0.0087\n",
            "Epoch 1690/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8279e-04 - mae: 0.0098 - val_loss: 1.8856e-04 - val_mae: 0.0091\n",
            "Epoch 1691/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.1298e-04 - mae: 0.0109 - val_loss: 1.9577e-04 - val_mae: 0.0110\n",
            "Epoch 1692/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1499e-04 - mae: 0.0115 - val_loss: 2.9614e-04 - val_mae: 0.0124\n",
            "Epoch 1693/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.7432e-04 - mae: 0.0159 - val_loss: 4.2912e-04 - val_mae: 0.0148\n",
            "Epoch 1694/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.9866e-04 - mae: 0.0181 - val_loss: 2.1748e-04 - val_mae: 0.0118\n",
            "Epoch 1695/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3234e-04 - mae: 0.0111 - val_loss: 1.9589e-04 - val_mae: 0.0091\n",
            "Epoch 1696/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1820e-04 - mae: 0.0083 - val_loss: 2.4428e-04 - val_mae: 0.0113\n",
            "Epoch 1697/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1302e-04 - mae: 0.0079 - val_loss: 1.5448e-04 - val_mae: 0.0082\n",
            "Epoch 1698/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.2625e-05 - mae: 0.0064 - val_loss: 1.6071e-04 - val_mae: 0.0086\n",
            "Epoch 1699/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1322e-04 - mae: 0.0077 - val_loss: 2.2569e-04 - val_mae: 0.0112\n",
            "Epoch 1700/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0369e-04 - mae: 0.0101 - val_loss: 4.2301e-04 - val_mae: 0.0154\n",
            "Epoch 1701/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2253e-04 - mae: 0.0135 - val_loss: 3.7820e-04 - val_mae: 0.0135\n",
            "Epoch 1702/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3496e-04 - mae: 0.0178 - val_loss: 4.5373e-04 - val_mae: 0.0153\n",
            "Epoch 1703/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0880e-04 - mae: 0.0133 - val_loss: 3.0317e-04 - val_mae: 0.0126\n",
            "Epoch 1704/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3658e-04 - mae: 0.0089 - val_loss: 1.4612e-04 - val_mae: 0.0080\n",
            "Epoch 1705/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4706e-04 - mae: 0.0083 - val_loss: 1.6313e-04 - val_mae: 0.0091\n",
            "Epoch 1706/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2271e-04 - mae: 0.0083 - val_loss: 1.6666e-04 - val_mae: 0.0098\n",
            "Epoch 1707/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0702e-04 - mae: 0.0079 - val_loss: 1.3162e-04 - val_mae: 0.0081\n",
            "Epoch 1708/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4474e-04 - mae: 0.0090 - val_loss: 1.8228e-04 - val_mae: 0.0095\n",
            "Epoch 1709/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6598e-04 - mae: 0.0095 - val_loss: 1.6786e-04 - val_mae: 0.0086\n",
            "Epoch 1710/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2242e-04 - mae: 0.0137 - val_loss: 5.6988e-04 - val_mae: 0.0178\n",
            "Epoch 1711/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5483e-04 - mae: 0.0145 - val_loss: 3.4888e-04 - val_mae: 0.0117\n",
            "Epoch 1712/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5261e-04 - mae: 0.0202 - val_loss: 6.2414e-04 - val_mae: 0.0199\n",
            "Epoch 1713/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6871e-04 - mae: 0.0162 - val_loss: 1.9727e-04 - val_mae: 0.0101\n",
            "Epoch 1714/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4249e-04 - mae: 0.0147 - val_loss: 2.0908e-04 - val_mae: 0.0101\n",
            "Epoch 1715/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5673e-04 - mae: 0.0120 - val_loss: 4.6574e-04 - val_mae: 0.0160\n",
            "Epoch 1716/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3532e-04 - mae: 0.0171 - val_loss: 6.5195e-04 - val_mae: 0.0181\n",
            "Epoch 1717/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0041e-04 - mae: 0.0146 - val_loss: 3.1641e-04 - val_mae: 0.0133\n",
            "Epoch 1718/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9290e-04 - mae: 0.0101 - val_loss: 3.1867e-04 - val_mae: 0.0130\n",
            "Epoch 1719/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.8577e-04 - mae: 0.0130 - val_loss: 2.4451e-04 - val_mae: 0.0100\n",
            "Epoch 1720/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.1877e-04 - mae: 0.0080 - val_loss: 3.3359e-04 - val_mae: 0.0135\n",
            "Epoch 1721/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9813e-04 - mae: 0.0103 - val_loss: 3.0692e-04 - val_mae: 0.0135\n",
            "Epoch 1722/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4326e-04 - mae: 0.0119 - val_loss: 3.3549e-04 - val_mae: 0.0133\n",
            "Epoch 1723/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0944e-04 - mae: 0.0153 - val_loss: 4.1231e-04 - val_mae: 0.0149\n",
            "Epoch 1724/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5651e-04 - mae: 0.0143 - val_loss: 4.8385e-04 - val_mae: 0.0171\n",
            "Epoch 1725/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2214e-04 - mae: 0.0115 - val_loss: 1.3961e-04 - val_mae: 0.0085\n",
            "Epoch 1726/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2255e-04 - mae: 0.0082 - val_loss: 1.5258e-04 - val_mae: 0.0072\n",
            "Epoch 1727/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.4743e-05 - mae: 0.0071 - val_loss: 1.2704e-04 - val_mae: 0.0076\n",
            "Epoch 1728/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3726e-04 - mae: 0.0087 - val_loss: 2.5037e-04 - val_mae: 0.0123\n",
            "Epoch 1729/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6161e-04 - mae: 0.0116 - val_loss: 4.5974e-04 - val_mae: 0.0159\n",
            "Epoch 1730/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0665e-04 - mae: 0.0171 - val_loss: 6.0228e-04 - val_mae: 0.0183\n",
            "Epoch 1731/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0032 - val_mae: 0.0444\n",
            "Epoch 1732/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0278\n",
            "Epoch 1733/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.9796e-04 - mae: 0.0147 - val_loss: 2.0616e-04 - val_mae: 0.0103\n",
            "Epoch 1734/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0329e-04 - mae: 0.0105 - val_loss: 2.4001e-04 - val_mae: 0.0114\n",
            "Epoch 1735/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4922e-04 - mae: 0.0121 - val_loss: 3.6642e-04 - val_mae: 0.0137\n",
            "Epoch 1736/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8624e-04 - mae: 0.0128 - val_loss: 2.9395e-04 - val_mae: 0.0113\n",
            "Epoch 1737/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5591e-04 - mae: 0.0137 - val_loss: 4.3233e-04 - val_mae: 0.0150\n",
            "Epoch 1738/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.1245e-04 - mae: 0.0167 - val_loss: 5.2318e-04 - val_mae: 0.0166\n",
            "Epoch 1739/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7334e-04 - mae: 0.0150 - val_loss: 3.9834e-04 - val_mae: 0.0150\n",
            "Epoch 1740/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 3.2519e-04 - mae: 0.0133 - val_loss: 2.3152e-04 - val_mae: 0.0106\n",
            "Epoch 1741/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8143e-04 - mae: 0.0101 - val_loss: 1.6353e-04 - val_mae: 0.0089\n",
            "Epoch 1742/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8478e-04 - mae: 0.0103 - val_loss: 2.7698e-04 - val_mae: 0.0128\n",
            "Epoch 1743/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8466e-04 - mae: 0.0163 - val_loss: 4.5882e-04 - val_mae: 0.0158\n",
            "Epoch 1744/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6289e-04 - mae: 0.0202 - val_loss: 0.0013 - val_mae: 0.0267\n",
            "Epoch 1745/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1891e-04 - mae: 0.0210 - val_loss: 9.5151e-04 - val_mae: 0.0226\n",
            "Epoch 1746/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 9.5458e-04 - val_mae: 0.0234\n",
            "Epoch 1747/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0785e-04 - mae: 0.0155 - val_loss: 6.2589e-04 - val_mae: 0.0176\n",
            "Epoch 1748/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0016 - val_mae: 0.0308\n",
            "Epoch 1749/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 8.1915e-04 - val_mae: 0.0205\n",
            "Epoch 1750/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0326\n",
            "Epoch 1751/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8733e-04 - mae: 0.0180 - val_loss: 5.6180e-04 - val_mae: 0.0176\n",
            "Epoch 1752/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3453e-04 - mae: 0.0116 - val_loss: 2.0650e-04 - val_mae: 0.0099\n",
            "Epoch 1753/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1328e-04 - mae: 0.0080 - val_loss: 1.3812e-04 - val_mae: 0.0076\n",
            "Epoch 1754/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4759e-05 - mae: 0.0065 - val_loss: 1.3270e-04 - val_mae: 0.0074\n",
            "Epoch 1755/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4316e-04 - mae: 0.0085 - val_loss: 2.5955e-04 - val_mae: 0.0114\n",
            "Epoch 1756/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5710e-04 - mae: 0.0096 - val_loss: 3.7670e-04 - val_mae: 0.0149\n",
            "Epoch 1757/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6375e-04 - mae: 0.0097 - val_loss: 2.6441e-04 - val_mae: 0.0126\n",
            "Epoch 1758/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6982e-04 - mae: 0.0099 - val_loss: 2.4426e-04 - val_mae: 0.0113\n",
            "Epoch 1759/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1120e-04 - mae: 0.0112 - val_loss: 3.1460e-04 - val_mae: 0.0120\n",
            "Epoch 1760/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5187e-04 - mae: 0.0119 - val_loss: 1.8527e-04 - val_mae: 0.0101\n",
            "Epoch 1761/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6245e-04 - mae: 0.0098 - val_loss: 1.5077e-04 - val_mae: 0.0084\n",
            "Epoch 1762/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.5506e-05 - mae: 0.0074 - val_loss: 1.7205e-04 - val_mae: 0.0097\n",
            "Epoch 1763/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.3496e-05 - mae: 0.0069 - val_loss: 1.2315e-04 - val_mae: 0.0075\n",
            "Epoch 1764/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5283e-04 - mae: 0.0117 - val_loss: 2.4316e-04 - val_mae: 0.0117\n",
            "Epoch 1765/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.7836e-04 - mae: 0.0100 - val_loss: 2.1051e-04 - val_mae: 0.0099\n",
            "Epoch 1766/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2229e-04 - mae: 0.0083 - val_loss: 2.1430e-04 - val_mae: 0.0102\n",
            "Epoch 1767/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.7321e-05 - mae: 0.0076 - val_loss: 1.4511e-04 - val_mae: 0.0091\n",
            "Epoch 1768/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1905e-04 - mae: 0.0076 - val_loss: 1.3053e-04 - val_mae: 0.0077\n",
            "Epoch 1769/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7403e-04 - mae: 0.0101 - val_loss: 2.1314e-04 - val_mae: 0.0104\n",
            "Epoch 1770/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4467e-04 - mae: 0.0117 - val_loss: 2.1307e-04 - val_mae: 0.0107\n",
            "Epoch 1771/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5401e-04 - mae: 0.0094 - val_loss: 1.8166e-04 - val_mae: 0.0100\n",
            "Epoch 1772/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.8939e-05 - mae: 0.0071 - val_loss: 1.3736e-04 - val_mae: 0.0079\n",
            "Epoch 1773/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4164e-04 - mae: 0.0087 - val_loss: 2.4086e-04 - val_mae: 0.0121\n",
            "Epoch 1774/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8929e-04 - mae: 0.0166 - val_loss: 2.6484e-04 - val_mae: 0.0117\n",
            "Epoch 1775/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5579e-04 - mae: 0.0176 - val_loss: 8.2121e-04 - val_mae: 0.0215\n",
            "Epoch 1776/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9649e-04 - mae: 0.0170 - val_loss: 2.5691e-04 - val_mae: 0.0109\n",
            "Epoch 1777/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2336e-04 - mae: 0.0135 - val_loss: 7.5799e-04 - val_mae: 0.0194\n",
            "Epoch 1778/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.8246e-04 - mae: 0.0208 - val_loss: 5.0774e-04 - val_mae: 0.0179\n",
            "Epoch 1779/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0311 - val_loss: 0.0020 - val_mae: 0.0355\n",
            "Epoch 1780/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 9.4369e-04 - val_mae: 0.0241\n",
            "Epoch 1781/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.2185e-04 - mae: 0.0188 - val_loss: 4.0597e-04 - val_mae: 0.0156\n",
            "Epoch 1782/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7237e-04 - mae: 0.0097 - val_loss: 1.6117e-04 - val_mae: 0.0093\n",
            "Epoch 1783/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4202e-04 - mae: 0.0088 - val_loss: 3.9094e-04 - val_mae: 0.0151\n",
            "Epoch 1784/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2707e-04 - mae: 0.0135 - val_loss: 2.1450e-04 - val_mae: 0.0106\n",
            "Epoch 1785/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.4020e-05 - mae: 0.0073 - val_loss: 1.1320e-04 - val_mae: 0.0073\n",
            "Epoch 1786/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.8494e-05 - mae: 0.0073 - val_loss: 1.6514e-04 - val_mae: 0.0086\n",
            "Epoch 1787/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2867e-04 - mae: 0.0085 - val_loss: 1.6885e-04 - val_mae: 0.0097\n",
            "Epoch 1788/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2706e-04 - mae: 0.0115 - val_loss: 1.6525e-04 - val_mae: 0.0090\n",
            "Epoch 1789/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6082e-04 - mae: 0.0092 - val_loss: 1.5799e-04 - val_mae: 0.0090\n",
            "Epoch 1790/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3774e-04 - mae: 0.0086 - val_loss: 1.3889e-04 - val_mae: 0.0084\n",
            "Epoch 1791/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1825e-04 - mae: 0.0081 - val_loss: 1.7199e-04 - val_mae: 0.0088\n",
            "Epoch 1792/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4746e-04 - mae: 0.0091 - val_loss: 2.0160e-04 - val_mae: 0.0101\n",
            "Epoch 1793/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0554e-04 - mae: 0.0106 - val_loss: 2.5443e-04 - val_mae: 0.0115\n",
            "Epoch 1794/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3274e-04 - mae: 0.0129 - val_loss: 3.6133e-04 - val_mae: 0.0138\n",
            "Epoch 1795/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3492e-04 - mae: 0.0171 - val_loss: 3.8401e-04 - val_mae: 0.0136\n",
            "Epoch 1796/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8457e-04 - mae: 0.0103 - val_loss: 2.5668e-04 - val_mae: 0.0107\n",
            "Epoch 1797/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4923e-04 - mae: 0.0118 - val_loss: 3.2227e-04 - val_mae: 0.0135\n",
            "Epoch 1798/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6580e-04 - mae: 0.0123 - val_loss: 2.0556e-04 - val_mae: 0.0107\n",
            "Epoch 1799/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2396e-04 - mae: 0.0114 - val_loss: 0.0010 - val_mae: 0.0257\n",
            "Epoch 1800/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5457e-04 - mae: 0.0116 - val_loss: 3.5270e-04 - val_mae: 0.0137\n",
            "Epoch 1801/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 6.9878e-04 - val_mae: 0.0209\n",
            "Epoch 1802/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3870e-04 - mae: 0.0181 - val_loss: 3.1154e-04 - val_mae: 0.0124\n",
            "Epoch 1803/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6569e-04 - mae: 0.0123 - val_loss: 4.5720e-04 - val_mae: 0.0148\n",
            "Epoch 1804/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6868e-04 - mae: 0.0096 - val_loss: 3.1490e-04 - val_mae: 0.0126\n",
            "Epoch 1805/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4417e-04 - mae: 0.0093 - val_loss: 2.9143e-04 - val_mae: 0.0120\n",
            "Epoch 1806/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.5963e-04 - mae: 0.0097 - val_loss: 2.3414e-04 - val_mae: 0.0103\n",
            "Epoch 1807/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.7010e-05 - mae: 0.0073 - val_loss: 1.3894e-04 - val_mae: 0.0084\n",
            "Epoch 1808/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3604e-04 - mae: 0.0087 - val_loss: 1.2394e-04 - val_mae: 0.0080\n",
            "Epoch 1809/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6719e-04 - mae: 0.0096 - val_loss: 2.4983e-04 - val_mae: 0.0126\n",
            "Epoch 1810/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9112e-04 - mae: 0.0133 - val_loss: 3.2832e-04 - val_mae: 0.0136\n",
            "Epoch 1811/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8272e-04 - mae: 0.0102 - val_loss: 1.6982e-04 - val_mae: 0.0098\n",
            "Epoch 1812/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0293e-04 - mae: 0.0108 - val_loss: 5.3591e-04 - val_mae: 0.0196\n",
            "Epoch 1813/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.0723e-04 - mae: 0.0208 - val_loss: 4.9753e-04 - val_mae: 0.0178\n",
            "Epoch 1814/2000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 4.1115e-04 - mae: 0.0155 - val_loss: 9.3162e-04 - val_mae: 0.0274\n",
            "Epoch 1815/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2256e-04 - mae: 0.0137 - val_loss: 2.9642e-04 - val_mae: 0.0129\n",
            "Epoch 1816/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5096e-04 - mae: 0.0095 - val_loss: 1.7383e-04 - val_mae: 0.0100\n",
            "Epoch 1817/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2343e-04 - mae: 0.0111 - val_loss: 2.0019e-04 - val_mae: 0.0095\n",
            "Epoch 1818/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1643e-04 - mae: 0.0111 - val_loss: 4.1059e-04 - val_mae: 0.0144\n",
            "Epoch 1819/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9463e-04 - mae: 0.0135 - val_loss: 5.0830e-04 - val_mae: 0.0163\n",
            "Epoch 1820/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0044e-04 - mae: 0.0124 - val_loss: 1.7826e-04 - val_mae: 0.0092\n",
            "Epoch 1821/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9474e-04 - mae: 0.0102 - val_loss: 2.3238e-04 - val_mae: 0.0108\n",
            "Epoch 1822/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8612e-04 - mae: 0.0119 - val_loss: 4.6881e-04 - val_mae: 0.0148\n",
            "Epoch 1823/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3026e-04 - mae: 0.0173 - val_loss: 4.1687e-04 - val_mae: 0.0153\n",
            "Epoch 1824/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6798e-04 - mae: 0.0143 - val_loss: 2.6586e-04 - val_mae: 0.0119\n",
            "Epoch 1825/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0811e-04 - mae: 0.0132 - val_loss: 3.1843e-04 - val_mae: 0.0125\n",
            "Epoch 1826/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.9828e-04 - mae: 0.0163 - val_loss: 5.0363e-04 - val_mae: 0.0164\n",
            "Epoch 1827/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6164e-04 - mae: 0.0204 - val_loss: 7.0781e-04 - val_mae: 0.0214\n",
            "Epoch 1828/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7147e-04 - mae: 0.0188 - val_loss: 1.9888e-04 - val_mae: 0.0095\n",
            "Epoch 1829/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4080e-04 - mae: 0.0166 - val_loss: 8.1189e-04 - val_mae: 0.0204\n",
            "Epoch 1830/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0199e-04 - mae: 0.0143 - val_loss: 1.7262e-04 - val_mae: 0.0094\n",
            "Epoch 1831/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3281e-04 - mae: 0.0085 - val_loss: 1.7332e-04 - val_mae: 0.0097\n",
            "Epoch 1832/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8017e-04 - mae: 0.0101 - val_loss: 5.1776e-04 - val_mae: 0.0174\n",
            "Epoch 1833/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5698e-04 - mae: 0.0136 - val_loss: 9.9478e-04 - val_mae: 0.0195\n",
            "Epoch 1834/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.6333e-04 - mae: 0.0185 - val_loss: 4.4678e-04 - val_mae: 0.0163\n",
            "Epoch 1835/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8802e-04 - mae: 0.0187 - val_loss: 8.1768e-04 - val_mae: 0.0194\n",
            "Epoch 1836/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 4.7892e-04 - val_mae: 0.0161\n",
            "Epoch 1837/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.3644e-04 - mae: 0.0177 - val_loss: 6.9064e-04 - val_mae: 0.0211\n",
            "Epoch 1838/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6569e-04 - mae: 0.0169 - val_loss: 3.1458e-04 - val_mae: 0.0115\n",
            "Epoch 1839/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9196e-04 - mae: 0.0104 - val_loss: 2.1668e-04 - val_mae: 0.0096\n",
            "Epoch 1840/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4150e-04 - mae: 0.0090 - val_loss: 1.3407e-04 - val_mae: 0.0081\n",
            "Epoch 1841/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8560e-04 - mae: 0.0103 - val_loss: 1.9053e-04 - val_mae: 0.0091\n",
            "Epoch 1842/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1277e-04 - mae: 0.0105 - val_loss: 5.2640e-04 - val_mae: 0.0146\n",
            "Epoch 1843/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7182e-04 - mae: 0.0139 - val_loss: 7.2353e-04 - val_mae: 0.0193\n",
            "Epoch 1844/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.8114e-04 - mae: 0.0185 - val_loss: 5.0138e-04 - val_mae: 0.0163\n",
            "Epoch 1845/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7722e-04 - mae: 0.0181 - val_loss: 4.7584e-04 - val_mae: 0.0161\n",
            "Epoch 1846/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.7641e-04 - mae: 0.0201 - val_loss: 0.0022 - val_mae: 0.0369\n",
            "Epoch 1847/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0021 - val_mae: 0.0360\n",
            "Epoch 1848/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0012 - val_mae: 0.0267\n",
            "Epoch 1849/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0010 - val_mae: 0.0262\n",
            "Epoch 1850/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8073e-04 - mae: 0.0200 - val_loss: 3.8892e-04 - val_mae: 0.0148\n",
            "Epoch 1851/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4877e-04 - mae: 0.0090 - val_loss: 1.4891e-04 - val_mae: 0.0086\n",
            "Epoch 1852/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4798e-04 - mae: 0.0087 - val_loss: 3.1891e-04 - val_mae: 0.0131\n",
            "Epoch 1853/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6599e-04 - mae: 0.0098 - val_loss: 2.9863e-04 - val_mae: 0.0126\n",
            "Epoch 1854/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2219e-04 - mae: 0.0084 - val_loss: 1.4407e-04 - val_mae: 0.0075\n",
            "Epoch 1855/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8420e-04 - mae: 0.0122 - val_loss: 7.6729e-04 - val_mae: 0.0194\n",
            "Epoch 1856/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.3654e-04 - mae: 0.0160 - val_loss: 4.6277e-04 - val_mae: 0.0169\n",
            "Epoch 1857/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4364e-04 - mae: 0.0092 - val_loss: 1.3240e-04 - val_mae: 0.0082\n",
            "Epoch 1858/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.9703e-05 - mae: 0.0077 - val_loss: 1.3763e-04 - val_mae: 0.0079\n",
            "Epoch 1859/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.4551e-05 - mae: 0.0067 - val_loss: 1.5507e-04 - val_mae: 0.0086\n",
            "Epoch 1860/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5878e-04 - mae: 0.0093 - val_loss: 2.3603e-04 - val_mae: 0.0111\n",
            "Epoch 1861/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6961e-04 - mae: 0.0097 - val_loss: 1.4130e-04 - val_mae: 0.0075\n",
            "Epoch 1862/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1107e-04 - mae: 0.0080 - val_loss: 1.6245e-04 - val_mae: 0.0083\n",
            "Epoch 1863/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4152e-04 - mae: 0.0116 - val_loss: 3.2417e-04 - val_mae: 0.0127\n",
            "Epoch 1864/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6439e-04 - mae: 0.0095 - val_loss: 1.6046e-04 - val_mae: 0.0092\n",
            "Epoch 1865/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1521e-04 - mae: 0.0081 - val_loss: 1.4813e-04 - val_mae: 0.0082\n",
            "Epoch 1866/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6207e-04 - mae: 0.0096 - val_loss: 3.1344e-04 - val_mae: 0.0147\n",
            "Epoch 1867/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7440e-04 - mae: 0.0101 - val_loss: 1.4052e-04 - val_mae: 0.0080\n",
            "Epoch 1868/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5372e-04 - mae: 0.0093 - val_loss: 1.4227e-04 - val_mae: 0.0086\n",
            "Epoch 1869/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7870e-04 - mae: 0.0095 - val_loss: 9.9488e-05 - val_mae: 0.0059\n",
            "Epoch 1870/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.6032e-05 - mae: 0.0070 - val_loss: 2.3182e-04 - val_mae: 0.0108\n",
            "Epoch 1871/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8717e-04 - mae: 0.0100 - val_loss: 1.8851e-04 - val_mae: 0.0103\n",
            "Epoch 1872/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.4129e-05 - mae: 0.0074 - val_loss: 1.4020e-04 - val_mae: 0.0078\n",
            "Epoch 1873/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.6998e-05 - mae: 0.0064 - val_loss: 1.3252e-04 - val_mae: 0.0078\n",
            "Epoch 1874/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2331e-04 - mae: 0.0080 - val_loss: 1.4316e-04 - val_mae: 0.0076\n",
            "Epoch 1875/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5411e-04 - mae: 0.0151 - val_loss: 7.1403e-04 - val_mae: 0.0219\n",
            "Epoch 1876/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2639e-04 - mae: 0.0172 - val_loss: 6.7653e-04 - val_mae: 0.0198\n",
            "Epoch 1877/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5478e-04 - mae: 0.0124 - val_loss: 3.0249e-04 - val_mae: 0.0129\n",
            "Epoch 1878/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9425e-04 - mae: 0.0106 - val_loss: 1.4513e-04 - val_mae: 0.0085\n",
            "Epoch 1879/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5578e-04 - mae: 0.0143 - val_loss: 9.0752e-04 - val_mae: 0.0220\n",
            "Epoch 1880/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5225e-04 - mae: 0.0142 - val_loss: 3.3933e-04 - val_mae: 0.0148\n",
            "Epoch 1881/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.0164e-04 - mae: 0.0141 - val_loss: 2.9687e-04 - val_mae: 0.0129\n",
            "Epoch 1882/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2116e-04 - mae: 0.0115 - val_loss: 2.9578e-04 - val_mae: 0.0121\n",
            "Epoch 1883/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3486e-04 - mae: 0.0118 - val_loss: 2.1837e-04 - val_mae: 0.0103\n",
            "Epoch 1884/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9903e-04 - mae: 0.0100 - val_loss: 1.7992e-04 - val_mae: 0.0084\n",
            "Epoch 1885/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0809e-04 - mae: 0.0076 - val_loss: 1.9531e-04 - val_mae: 0.0104\n",
            "Epoch 1886/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0568e-04 - mae: 0.0106 - val_loss: 2.5583e-04 - val_mae: 0.0118\n",
            "Epoch 1887/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.7151e-04 - mae: 0.0121 - val_loss: 9.9507e-04 - val_mae: 0.0224\n",
            "Epoch 1888/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.5124e-04 - mae: 0.0202 - val_loss: 0.0027 - val_mae: 0.0312\n",
            "Epoch 1889/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.4771e-04 - mae: 0.0177 - val_loss: 7.1328e-04 - val_mae: 0.0191\n",
            "Epoch 1890/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.9518e-04 - mae: 0.0211 - val_loss: 8.9598e-04 - val_mae: 0.0218\n",
            "Epoch 1891/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.6395e-04 - mae: 0.0221 - val_loss: 1.9867e-04 - val_mae: 0.0103\n",
            "Epoch 1892/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.6446e-04 - mae: 0.0121 - val_loss: 2.3018e-04 - val_mae: 0.0106\n",
            "Epoch 1893/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5590e-04 - mae: 0.0121 - val_loss: 2.9531e-04 - val_mae: 0.0118\n",
            "Epoch 1894/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8195e-04 - mae: 0.0100 - val_loss: 1.6734e-04 - val_mae: 0.0097\n",
            "Epoch 1895/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1325e-04 - mae: 0.0079 - val_loss: 2.0523e-04 - val_mae: 0.0101\n",
            "Epoch 1896/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3330e-04 - mae: 0.0089 - val_loss: 1.6120e-04 - val_mae: 0.0095\n",
            "Epoch 1897/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.8210e-04 - mae: 0.0105 - val_loss: 3.1498e-04 - val_mae: 0.0127\n",
            "Epoch 1898/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3565e-04 - mae: 0.0117 - val_loss: 4.2443e-04 - val_mae: 0.0159\n",
            "Epoch 1899/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6041e-04 - mae: 0.0140 - val_loss: 3.3911e-04 - val_mae: 0.0142\n",
            "Epoch 1900/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0260e-04 - mae: 0.0106 - val_loss: 2.0382e-04 - val_mae: 0.0112\n",
            "Epoch 1901/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3556e-04 - mae: 0.0134 - val_loss: 2.8662e-04 - val_mae: 0.0129\n",
            "Epoch 1902/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1229e-04 - mae: 0.0109 - val_loss: 1.2766e-04 - val_mae: 0.0077\n",
            "Epoch 1903/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.6846e-05 - mae: 0.0073 - val_loss: 1.3212e-04 - val_mae: 0.0081\n",
            "Epoch 1904/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1263e-04 - mae: 0.0080 - val_loss: 1.6423e-04 - val_mae: 0.0085\n",
            "Epoch 1905/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6965e-04 - mae: 0.0096 - val_loss: 2.4649e-04 - val_mae: 0.0108\n",
            "Epoch 1906/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7128e-04 - mae: 0.0100 - val_loss: 2.3453e-04 - val_mae: 0.0101\n",
            "Epoch 1907/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7590e-04 - mae: 0.0149 - val_loss: 6.8525e-04 - val_mae: 0.0213\n",
            "Epoch 1908/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4062e-04 - mae: 0.0151 - val_loss: 3.1742e-04 - val_mae: 0.0143\n",
            "Epoch 1909/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.0641e-04 - mae: 0.0184 - val_loss: 0.0013 - val_mae: 0.0306\n",
            "Epoch 1910/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 9.5506e-04 - val_mae: 0.0264\n",
            "Epoch 1911/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.5036e-04 - mae: 0.0160 - val_loss: 3.6016e-04 - val_mae: 0.0127\n",
            "Epoch 1912/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.3932e-04 - mae: 0.0134 - val_loss: 2.0691e-04 - val_mae: 0.0114\n",
            "Epoch 1913/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9761e-04 - mae: 0.0107 - val_loss: 1.3989e-04 - val_mae: 0.0080\n",
            "Epoch 1914/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4533e-04 - mae: 0.0092 - val_loss: 3.5236e-04 - val_mae: 0.0159\n",
            "Epoch 1915/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3866e-04 - mae: 0.0092 - val_loss: 1.4822e-04 - val_mae: 0.0085\n",
            "Epoch 1916/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6645e-04 - mae: 0.0093 - val_loss: 5.4081e-04 - val_mae: 0.0155\n",
            "Epoch 1917/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6720e-04 - mae: 0.0093 - val_loss: 1.6232e-04 - val_mae: 0.0092\n",
            "Epoch 1918/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0529e-04 - mae: 0.0079 - val_loss: 1.3734e-04 - val_mae: 0.0079\n",
            "Epoch 1919/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7051e-04 - mae: 0.0091 - val_loss: 2.0167e-04 - val_mae: 0.0105\n",
            "Epoch 1920/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3590e-04 - mae: 0.0088 - val_loss: 1.7718e-04 - val_mae: 0.0099\n",
            "Epoch 1921/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3423e-04 - mae: 0.0086 - val_loss: 1.3438e-04 - val_mae: 0.0083\n",
            "Epoch 1922/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.8711e-05 - mae: 0.0075 - val_loss: 1.5548e-04 - val_mae: 0.0088\n",
            "Epoch 1923/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.2491e-05 - mae: 0.0071 - val_loss: 1.0440e-04 - val_mae: 0.0068\n",
            "Epoch 1924/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0304e-04 - mae: 0.0076 - val_loss: 1.4203e-04 - val_mae: 0.0085\n",
            "Epoch 1925/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4443e-04 - mae: 0.0090 - val_loss: 3.7696e-04 - val_mae: 0.0136\n",
            "Epoch 1926/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3686e-04 - mae: 0.0121 - val_loss: 4.6173e-04 - val_mae: 0.0160\n",
            "Epoch 1927/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.5166e-04 - mae: 0.0159 - val_loss: 4.9863e-04 - val_mae: 0.0142\n",
            "Epoch 1928/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.2565e-04 - mae: 0.0209 - val_loss: 4.8169e-04 - val_mae: 0.0133\n",
            "Epoch 1929/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2592e-04 - mae: 0.0175 - val_loss: 2.3056e-04 - val_mae: 0.0099\n",
            "Epoch 1930/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.2011e-04 - mae: 0.0169 - val_loss: 8.4890e-04 - val_mae: 0.0226\n",
            "Epoch 1931/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 4.9672e-04 - val_mae: 0.0179\n",
            "Epoch 1932/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0019 - val_mae: 0.0302\n",
            "Epoch 1933/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 5.2341e-04 - val_mae: 0.0184\n",
            "Epoch 1934/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.7874e-04 - mae: 0.0195 - val_loss: 8.9560e-04 - val_mae: 0.0233\n",
            "Epoch 1935/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2858e-04 - mae: 0.0138 - val_loss: 2.2571e-04 - val_mae: 0.0107\n",
            "Epoch 1936/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3371e-04 - mae: 0.0116 - val_loss: 2.1956e-04 - val_mae: 0.0115\n",
            "Epoch 1937/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.4273e-04 - mae: 0.0130 - val_loss: 6.5009e-04 - val_mae: 0.0207\n",
            "Epoch 1938/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.1054e-04 - mae: 0.0145 - val_loss: 4.0823e-04 - val_mae: 0.0150\n",
            "Epoch 1939/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8407e-04 - mae: 0.0145 - val_loss: 3.8406e-04 - val_mae: 0.0134\n",
            "Epoch 1940/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.4707e-04 - mae: 0.0187 - val_loss: 9.1015e-04 - val_mae: 0.0236\n",
            "Epoch 1941/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 5.5012e-04 - val_mae: 0.0166\n",
            "Epoch 1942/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 6.8767e-04 - mae: 0.0202 - val_loss: 6.2575e-04 - val_mae: 0.0202\n",
            "Epoch 1943/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0828e-04 - mae: 0.0129 - val_loss: 1.3188e-04 - val_mae: 0.0082\n",
            "Epoch 1944/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2932e-04 - mae: 0.0086 - val_loss: 1.3605e-04 - val_mae: 0.0085\n",
            "Epoch 1945/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1219e-04 - mae: 0.0080 - val_loss: 1.7450e-04 - val_mae: 0.0101\n",
            "Epoch 1946/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1003e-04 - mae: 0.0079 - val_loss: 1.9928e-04 - val_mae: 0.0101\n",
            "Epoch 1947/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6817e-04 - mae: 0.0098 - val_loss: 1.7543e-04 - val_mae: 0.0096\n",
            "Epoch 1948/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0232e-04 - mae: 0.0076 - val_loss: 1.4643e-04 - val_mae: 0.0090\n",
            "Epoch 1949/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.2162e-05 - mae: 0.0069 - val_loss: 2.6198e-04 - val_mae: 0.0112\n",
            "Epoch 1950/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.2920e-04 - mae: 0.0139 - val_loss: 4.0116e-04 - val_mae: 0.0138\n",
            "Epoch 1951/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0064e-04 - mae: 0.0125 - val_loss: 1.4092e-04 - val_mae: 0.0082\n",
            "Epoch 1952/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5301e-04 - mae: 0.0118 - val_loss: 3.3791e-04 - val_mae: 0.0141\n",
            "Epoch 1953/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.7163e-04 - mae: 0.0097 - val_loss: 3.3815e-04 - val_mae: 0.0148\n",
            "Epoch 1954/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4989e-04 - mae: 0.0117 - val_loss: 4.5404e-04 - val_mae: 0.0139\n",
            "Epoch 1955/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.9541e-04 - mae: 0.0134 - val_loss: 3.0060e-04 - val_mae: 0.0125\n",
            "Epoch 1956/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9116e-04 - mae: 0.0106 - val_loss: 1.5130e-04 - val_mae: 0.0090\n",
            "Epoch 1957/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7663e-04 - mae: 0.0101 - val_loss: 3.4015e-04 - val_mae: 0.0148\n",
            "Epoch 1958/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0276e-04 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0257\n",
            "Epoch 1959/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.8576e-04 - mae: 0.0149 - val_loss: 4.1584e-04 - val_mae: 0.0161\n",
            "Epoch 1960/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.7052e-04 - mae: 0.0141 - val_loss: 5.3477e-04 - val_mae: 0.0174\n",
            "Epoch 1961/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8687e-04 - mae: 0.0123 - val_loss: 1.7274e-04 - val_mae: 0.0090\n",
            "Epoch 1962/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0339e-04 - mae: 0.0106 - val_loss: 7.4509e-04 - val_mae: 0.0200\n",
            "Epoch 1963/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.0948e-04 - mae: 0.0165 - val_loss: 5.0196e-04 - val_mae: 0.0170\n",
            "Epoch 1964/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 4.0205e-04 - mae: 0.0145 - val_loss: 3.2329e-04 - val_mae: 0.0142\n",
            "Epoch 1965/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.5662e-04 - mae: 0.0145 - val_loss: 8.8157e-04 - val_mae: 0.0236\n",
            "Epoch 1966/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.4399e-04 - mae: 0.0197 - val_loss: 5.2760e-04 - val_mae: 0.0155\n",
            "Epoch 1967/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0565e-04 - mae: 0.0132 - val_loss: 2.9500e-04 - val_mae: 0.0127\n",
            "Epoch 1968/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0227e-04 - mae: 0.0130 - val_loss: 1.4415e-04 - val_mae: 0.0077\n",
            "Epoch 1969/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9067e-04 - mae: 0.0105 - val_loss: 3.1935e-04 - val_mae: 0.0135\n",
            "Epoch 1970/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7047e-04 - mae: 0.0099 - val_loss: 3.2059e-04 - val_mae: 0.0141\n",
            "Epoch 1971/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0072e-04 - mae: 0.0106 - val_loss: 1.3087e-04 - val_mae: 0.0090\n",
            "Epoch 1972/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0302e-04 - mae: 0.0076 - val_loss: 1.7262e-04 - val_mae: 0.0095\n",
            "Epoch 1973/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0552e-04 - mae: 0.0110 - val_loss: 2.8069e-04 - val_mae: 0.0125\n",
            "Epoch 1974/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.2576e-04 - mae: 0.0111 - val_loss: 2.0102e-04 - val_mae: 0.0083\n",
            "Epoch 1975/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.0191e-04 - mae: 0.0109 - val_loss: 1.5245e-04 - val_mae: 0.0092\n",
            "Epoch 1976/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7021e-04 - mae: 0.0103 - val_loss: 1.5710e-04 - val_mae: 0.0087\n",
            "Epoch 1977/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.7925e-04 - mae: 0.0103 - val_loss: 1.7763e-04 - val_mae: 0.0089\n",
            "Epoch 1978/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4304e-04 - mae: 0.0089 - val_loss: 1.4360e-04 - val_mae: 0.0086\n",
            "Epoch 1979/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6176e-04 - mae: 0.0098 - val_loss: 3.2138e-04 - val_mae: 0.0123\n",
            "Epoch 1980/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2030e-04 - mae: 0.0111 - val_loss: 8.2463e-04 - val_mae: 0.0239\n",
            "Epoch 1981/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 7.2999e-04 - mae: 0.0205 - val_loss: 7.9178e-04 - val_mae: 0.0218\n",
            "Epoch 1982/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2359e-04 - mae: 0.0226 - val_loss: 4.2220e-04 - val_mae: 0.0149\n",
            "Epoch 1983/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.8463e-04 - mae: 0.0163 - val_loss: 4.3791e-04 - val_mae: 0.0152\n",
            "Epoch 1984/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 9.2622e-04 - mae: 0.0220 - val_loss: 0.0017 - val_mae: 0.0318\n",
            "Epoch 1985/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 1986/2000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 7.2890e-04 - val_mae: 0.0182\n",
            "Epoch 1987/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.6966e-04 - mae: 0.0161 - val_loss: 2.2245e-04 - val_mae: 0.0116\n",
            "Epoch 1988/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1322e-04 - mae: 0.0108 - val_loss: 2.7098e-04 - val_mae: 0.0130\n",
            "Epoch 1989/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1657e-04 - mae: 0.0083 - val_loss: 1.3883e-04 - val_mae: 0.0087\n",
            "Epoch 1990/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 4.4196e-04 - mae: 0.0146 - val_loss: 3.9264e-04 - val_mae: 0.0149\n",
            "Epoch 1991/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 8.1183e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 1992/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 5.7024e-04 - mae: 0.0185 - val_loss: 5.4005e-04 - val_mae: 0.0156\n",
            "Epoch 1993/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.9161e-04 - mae: 0.0123 - val_loss: 3.8347e-04 - val_mae: 0.0144\n",
            "Epoch 1994/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.8749e-04 - mae: 0.0130 - val_loss: 3.2292e-04 - val_mae: 0.0121\n",
            "Epoch 1995/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.5309e-04 - mae: 0.0120 - val_loss: 3.3904e-04 - val_mae: 0.0124\n",
            "Epoch 1996/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.0154e-04 - mae: 0.0128 - val_loss: 4.1433e-04 - val_mae: 0.0136\n",
            "Epoch 1997/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1814e-04 - mae: 0.0108 - val_loss: 1.3325e-04 - val_mae: 0.0077\n",
            "Epoch 1998/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.3324e-04 - mae: 0.0112 - val_loss: 1.6962e-04 - val_mae: 0.0095\n",
            "Epoch 1999/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2477e-04 - mae: 0.0114 - val_loss: 3.0550e-04 - val_mae: 0.0131\n",
            "Epoch 2000/2000\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 3.6311e-04 - mae: 0.0141 - val_loss: 2.6033e-04 - val_mae: 0.0116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teQHdXF6WPSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp.save('/659rnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEIs5aT79lVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40d3393c-bac6-4c7a-ee6c-37187bc49218"
      },
      "source": [
        "prediction=mlp.predict(x_test_rnn)\n",
        "result=[]\n",
        "for i in range(len(prediction)):\n",
        "  a=np.abs(prediction[i]-y_test[i])\n",
        "  b=sum(a)\n",
        "  result.append(b/2)\n",
        "mae_test=sum(result)/len(result)\n",
        "mae_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.011926393276740664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDLWsBmfuqdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ture_out=creat_label(y_test)\n",
        "prediction_out=creat_label(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDWvHhtOFlEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a110ce60-d456-4b3e-eec9-772ac11e89d6"
      },
      "source": [
        "accuracy=0\n",
        "for i in range(len(ture_out)):\n",
        "  if (ture_out[i]==prediction_out[i]):\n",
        "    accuracy=accuracy+1\n",
        "accuracy/len(ture_out)*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTgP1JvI8czQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f1118a7-9607-46a7-ba76-995dbf422258"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_score = mlp.evaluate(x_test_rnn, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 2.1721e-04 - mae: 0.0119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwrVpXa9zrb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "eb96095a-43c5-4c80-cfbd-fec4a0de05e9"
      },
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "plt.plot([2,12.97],[2,2],c='green')\n",
        "plt.plot([2,12.97],[13.89,13.89],c='green')\n",
        "plt.plot([3.37,3.37],[2,13.89],c='green')\n",
        "plt.plot([11.6,11.6],[2,13.89],c='green')\n",
        "plt.plot([2,2],[2,13.89],c='green')\n",
        "plt.plot([12.97,12.97],[2,13.89],c='green')\n",
        "plt.plot([3.37,11.6],[7.49,7.49],c='green')\n",
        "plt.plot([7.485,7.485],[7.49,13.89],c='green')\n",
        "plt.scatter(y_test[:,0],y_test[:,1],marker='o',c='red',s=100,label=\"drop point\")\n",
        "plt.scatter(prediction[:,0],prediction[:,1],marker='x',c='blue',s=100,label=\"predict point\")\n",
        "plt.scatter(s_cor[:,0],s_cor[:,1],marker='*',c='black',s=100,label=\"sensor\")\n",
        "plt.gca().set_aspect('equal',adjustable='box')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd9c4ee3390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7IbHRrWZ65E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c18c4edc-78d0-4d32-b43d-b75859300e04"
      },
      "source": [
        "plt.plot(history_mlp.history['mae'],label=\"train set\")\n",
        "plt.plot(history_mlp.history['val_mae'],label=\"val set\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"mae\")\n",
        "plt.title(\"The Mae of Training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The Mae of Training')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkprQSoaPQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "b16872a0-35bd-4281-9459-b4fe20f8a63d"
      },
      "source": [
        "plt.plot(history_mlp.history['loss'],label=\"train set\")\n",
        "plt.plot(history_mlp.history['val_loss'],label=\"val set\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"The Loss of Training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The Loss of Training')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM0r41eWlOCU",
        "colab_type": "text"
      },
      "source": [
        "# MLP model predict out or not according input class 0 class 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqSu8HF-bA2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=500\n",
        "t_cor_cnn=[]\n",
        "np.random.seed(5)\n",
        "x=np.random.uniform(low=0,high=(x_boundary+2),size=N)\n",
        "y=np.random.uniform(low=0,high=(y_boundary+2),size=N)\n",
        "t_cor=[]\n",
        "temp=[]\n",
        "for i in range(N):\n",
        "  temp.append(x[i])\n",
        "  temp.append(y[i])\n",
        "  t_cor_cnn.append(temp)\n",
        "  temp=[]\n",
        "dis=[]\n",
        "#compute the distance\n",
        "for i in range(N):\n",
        "  dis.append(list(np.linalg.norm((t_cor_cnn[i]-s_cor),axis=1)))\n",
        "dis_array=np.array(dis)\n",
        "fsl=Pathloss(dis_array)\n",
        "RSS=10+24-fsl"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGmPqnXl2aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=RSS\n",
        "label=np.array(creat_label(t_cor_cnn))\n",
        "x_train,x_test,y_train,y_test=train_test_split(data,label,random_state=42,test_size=0.2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rH00hQoul0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale=StandardScaler()\n",
        "scale.fit(x_train)\n",
        "x_train_m=scale.transform(x_train).astype('float64')\n",
        "x_test_m=scale.transform(x_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdMmGO2Nl24V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeygbSdTnIwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afcda9ce-cc2f-4e70-f940-7b03893f486f"
      },
      "source": [
        "model=model()\n",
        "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau('loss',patience=3,factor=0.3,min_lr=0.00001)\n",
        "model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, ),\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "history_model=model.fit(\n",
        "    x_train_m,y_train,\n",
        "    epochs=800,\n",
        "    batch_size=10,\n",
        "    validation_split=0.2,\n",
        "    validation_freq=1,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.7264 - accuracy: 0.5188 - val_loss: 0.6794 - val_accuracy: 0.4500\n",
            "Epoch 2/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.4875 - val_loss: 0.6557 - val_accuracy: 0.4625\n",
            "Epoch 3/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.5437 - val_loss: 0.6406 - val_accuracy: 0.5250\n",
            "Epoch 4/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6219 - val_loss: 0.6280 - val_accuracy: 0.5625\n",
            "Epoch 5/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6500 - val_loss: 0.6128 - val_accuracy: 0.6500\n",
            "Epoch 6/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6906 - val_loss: 0.5965 - val_accuracy: 0.6875\n",
            "Epoch 7/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6906 - val_loss: 0.5807 - val_accuracy: 0.7125\n",
            "Epoch 8/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7063 - val_loss: 0.5596 - val_accuracy: 0.7875\n",
            "Epoch 9/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7437 - val_loss: 0.5370 - val_accuracy: 0.8125\n",
            "Epoch 10/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7563 - val_loss: 0.5153 - val_accuracy: 0.8500\n",
            "Epoch 11/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7625 - val_loss: 0.4935 - val_accuracy: 0.8375\n",
            "Epoch 12/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8031 - val_loss: 0.4741 - val_accuracy: 0.8375\n",
            "Epoch 13/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8188 - val_loss: 0.4522 - val_accuracy: 0.8375\n",
            "Epoch 14/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7906 - val_loss: 0.4287 - val_accuracy: 0.8750\n",
            "Epoch 15/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8062 - val_loss: 0.4126 - val_accuracy: 0.8875\n",
            "Epoch 16/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8062 - val_loss: 0.3953 - val_accuracy: 0.8750\n",
            "Epoch 17/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8344 - val_loss: 0.3810 - val_accuracy: 0.8750\n",
            "Epoch 18/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8250 - val_loss: 0.3742 - val_accuracy: 0.8875\n",
            "Epoch 19/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.3575 - val_accuracy: 0.8875\n",
            "Epoch 20/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8375 - val_loss: 0.3503 - val_accuracy: 0.8750\n",
            "Epoch 21/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8000 - val_loss: 0.3402 - val_accuracy: 0.8875\n",
            "Epoch 22/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8313 - val_loss: 0.3351 - val_accuracy: 0.8750\n",
            "Epoch 23/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8219 - val_loss: 0.3311 - val_accuracy: 0.9000\n",
            "Epoch 24/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8406 - val_loss: 0.3244 - val_accuracy: 0.8875\n",
            "Epoch 25/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8406 - val_loss: 0.3172 - val_accuracy: 0.8750\n",
            "Epoch 26/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8500 - val_loss: 0.3024 - val_accuracy: 0.8875\n",
            "Epoch 27/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8469 - val_loss: 0.3053 - val_accuracy: 0.9000\n",
            "Epoch 28/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8500 - val_loss: 0.3005 - val_accuracy: 0.9000\n",
            "Epoch 29/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8656 - val_loss: 0.2948 - val_accuracy: 0.9125\n",
            "Epoch 30/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8375 - val_loss: 0.2926 - val_accuracy: 0.9000\n",
            "Epoch 31/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8500 - val_loss: 0.2833 - val_accuracy: 0.9000\n",
            "Epoch 32/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8750 - val_loss: 0.2834 - val_accuracy: 0.9000\n",
            "Epoch 33/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8844 - val_loss: 0.2690 - val_accuracy: 0.9000\n",
            "Epoch 34/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8719 - val_loss: 0.2690 - val_accuracy: 0.9125\n",
            "Epoch 35/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8906 - val_loss: 0.2687 - val_accuracy: 0.9000\n",
            "Epoch 36/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8750 - val_loss: 0.2577 - val_accuracy: 0.9125\n",
            "Epoch 37/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8656 - val_loss: 0.2706 - val_accuracy: 0.9250\n",
            "Epoch 38/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8719 - val_loss: 0.2613 - val_accuracy: 0.9125\n",
            "Epoch 39/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8656 - val_loss: 0.2586 - val_accuracy: 0.9000\n",
            "Epoch 40/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8438 - val_loss: 0.2572 - val_accuracy: 0.9125\n",
            "Epoch 41/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8750 - val_loss: 0.2404 - val_accuracy: 0.9125\n",
            "Epoch 42/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8875 - val_loss: 0.2474 - val_accuracy: 0.9125\n",
            "Epoch 43/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8844 - val_loss: 0.2364 - val_accuracy: 0.9250\n",
            "Epoch 44/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8875 - val_loss: 0.2394 - val_accuracy: 0.9250\n",
            "Epoch 45/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9062 - val_loss: 0.2274 - val_accuracy: 0.9250\n",
            "Epoch 46/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8906 - val_loss: 0.2361 - val_accuracy: 0.9125\n",
            "Epoch 47/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9031 - val_loss: 0.2213 - val_accuracy: 0.9250\n",
            "Epoch 48/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8906 - val_loss: 0.2212 - val_accuracy: 0.9250\n",
            "Epoch 49/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8781 - val_loss: 0.2172 - val_accuracy: 0.9250\n",
            "Epoch 50/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8875 - val_loss: 0.2178 - val_accuracy: 0.9250\n",
            "Epoch 51/800\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9062 - val_loss: 0.2154 - val_accuracy: 0.9250\n",
            "Epoch 52/800\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2635 - accuracy: 0.8844 - val_loss: 0.2174 - val_accuracy: 0.9250\n",
            "Epoch 53/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9125 - val_loss: 0.2140 - val_accuracy: 0.9250\n",
            "Epoch 54/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9094 - val_loss: 0.2066 - val_accuracy: 0.9250\n",
            "Epoch 55/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9062 - val_loss: 0.2026 - val_accuracy: 0.9250\n",
            "Epoch 56/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8906 - val_loss: 0.2115 - val_accuracy: 0.9375\n",
            "Epoch 57/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9031 - val_loss: 0.1997 - val_accuracy: 0.9250\n",
            "Epoch 58/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.8969 - val_loss: 0.1996 - val_accuracy: 0.9250\n",
            "Epoch 59/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9094 - val_loss: 0.1921 - val_accuracy: 0.9250\n",
            "Epoch 60/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9219 - val_loss: 0.1918 - val_accuracy: 0.9375\n",
            "Epoch 61/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9094 - val_loss: 0.1774 - val_accuracy: 0.9250\n",
            "Epoch 62/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9156 - val_loss: 0.1921 - val_accuracy: 0.9250\n",
            "Epoch 63/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9250 - val_loss: 0.1767 - val_accuracy: 0.9250\n",
            "Epoch 64/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9125 - val_loss: 0.1809 - val_accuracy: 0.9250\n",
            "Epoch 65/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9125 - val_loss: 0.1700 - val_accuracy: 0.9375\n",
            "Epoch 66/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9031 - val_loss: 0.1756 - val_accuracy: 0.9375\n",
            "Epoch 67/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.8938 - val_loss: 0.1799 - val_accuracy: 0.9250\n",
            "Epoch 68/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9219 - val_loss: 0.1823 - val_accuracy: 0.9375\n",
            "Epoch 69/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9219 - val_loss: 0.1734 - val_accuracy: 0.9375\n",
            "Epoch 70/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9406 - val_loss: 0.1637 - val_accuracy: 0.9250\n",
            "Epoch 71/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9281 - val_loss: 0.1762 - val_accuracy: 0.9375\n",
            "Epoch 72/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9031 - val_loss: 0.1761 - val_accuracy: 0.9375\n",
            "Epoch 73/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9375 - val_loss: 0.1762 - val_accuracy: 0.9375\n",
            "Epoch 74/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9500 - val_loss: 0.1699 - val_accuracy: 0.9250\n",
            "Epoch 75/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9312 - val_loss: 0.1740 - val_accuracy: 0.9500\n",
            "Epoch 76/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9344 - val_loss: 0.1831 - val_accuracy: 0.9250\n",
            "Epoch 77/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9438 - val_loss: 0.1688 - val_accuracy: 0.9375\n",
            "Epoch 78/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9187 - val_loss: 0.1556 - val_accuracy: 0.9250\n",
            "Epoch 79/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9344 - val_loss: 0.1651 - val_accuracy: 0.9250\n",
            "Epoch 80/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9438 - val_loss: 0.1502 - val_accuracy: 0.9375\n",
            "Epoch 81/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9312 - val_loss: 0.1523 - val_accuracy: 0.9250\n",
            "Epoch 82/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.8969 - val_loss: 0.1663 - val_accuracy: 0.9375\n",
            "Epoch 83/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9281 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
            "Epoch 84/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9125 - val_loss: 0.1550 - val_accuracy: 0.9375\n",
            "Epoch 85/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9312 - val_loss: 0.1556 - val_accuracy: 0.9250\n",
            "Epoch 86/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9344 - val_loss: 0.1531 - val_accuracy: 0.9250\n",
            "Epoch 87/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9406 - val_loss: 0.1480 - val_accuracy: 0.9375\n",
            "Epoch 88/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9375 - val_loss: 0.1543 - val_accuracy: 0.9250\n",
            "Epoch 89/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9531 - val_loss: 0.1382 - val_accuracy: 0.9500\n",
            "Epoch 90/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9187 - val_loss: 0.1402 - val_accuracy: 0.9250\n",
            "Epoch 91/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9375 - val_loss: 0.1458 - val_accuracy: 0.9250\n",
            "Epoch 92/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9344 - val_loss: 0.1392 - val_accuracy: 0.9375\n",
            "Epoch 93/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9312 - val_loss: 0.1339 - val_accuracy: 0.9375\n",
            "Epoch 94/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9281 - val_loss: 0.1386 - val_accuracy: 0.9375\n",
            "Epoch 95/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9625 - val_loss: 0.1293 - val_accuracy: 0.9500\n",
            "Epoch 96/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9250 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 97/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9344 - val_loss: 0.1321 - val_accuracy: 0.9500\n",
            "Epoch 98/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9344 - val_loss: 0.1224 - val_accuracy: 0.9625\n",
            "Epoch 99/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9531 - val_loss: 0.1254 - val_accuracy: 0.9625\n",
            "Epoch 100/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9375 - val_loss: 0.1289 - val_accuracy: 0.9625\n",
            "Epoch 101/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9500 - val_loss: 0.1382 - val_accuracy: 0.9500\n",
            "Epoch 102/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9563 - val_loss: 0.1186 - val_accuracy: 0.9625\n",
            "Epoch 103/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9375 - val_loss: 0.1301 - val_accuracy: 0.9625\n",
            "Epoch 104/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9563 - val_loss: 0.1229 - val_accuracy: 0.9750\n",
            "Epoch 105/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9438 - val_loss: 0.1244 - val_accuracy: 0.9625\n",
            "Epoch 106/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9187 - val_loss: 0.1167 - val_accuracy: 0.9625\n",
            "Epoch 107/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9500 - val_loss: 0.1161 - val_accuracy: 0.9625\n",
            "Epoch 108/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9469 - val_loss: 0.1277 - val_accuracy: 0.9625\n",
            "Epoch 109/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9563 - val_loss: 0.1291 - val_accuracy: 0.9625\n",
            "Epoch 110/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9406 - val_loss: 0.1207 - val_accuracy: 0.9500\n",
            "Epoch 111/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9656 - val_loss: 0.1179 - val_accuracy: 0.9750\n",
            "Epoch 112/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9469 - val_loss: 0.1179 - val_accuracy: 0.9500\n",
            "Epoch 113/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9469 - val_loss: 0.1065 - val_accuracy: 0.9750\n",
            "Epoch 114/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9531 - val_loss: 0.1143 - val_accuracy: 0.9750\n",
            "Epoch 115/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9531 - val_loss: 0.1277 - val_accuracy: 0.9625\n",
            "Epoch 116/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9563 - val_loss: 0.1184 - val_accuracy: 0.9625\n",
            "Epoch 117/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9531 - val_loss: 0.1154 - val_accuracy: 0.9750\n",
            "Epoch 118/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9500 - val_loss: 0.1180 - val_accuracy: 0.9625\n",
            "Epoch 119/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9625 - val_loss: 0.1111 - val_accuracy: 0.9750\n",
            "Epoch 120/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9563 - val_loss: 0.0981 - val_accuracy: 0.9750\n",
            "Epoch 121/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9406 - val_loss: 0.1412 - val_accuracy: 0.9375\n",
            "Epoch 122/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9438 - val_loss: 0.1064 - val_accuracy: 0.9750\n",
            "Epoch 123/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9688 - val_loss: 0.1059 - val_accuracy: 0.9750\n",
            "Epoch 124/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9625 - val_loss: 0.1148 - val_accuracy: 0.9750\n",
            "Epoch 125/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9563 - val_loss: 0.1161 - val_accuracy: 0.9750\n",
            "Epoch 126/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9688 - val_loss: 0.1038 - val_accuracy: 0.9750\n",
            "Epoch 127/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9625 - val_loss: 0.1137 - val_accuracy: 0.9750\n",
            "Epoch 128/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9594 - val_loss: 0.1112 - val_accuracy: 0.9750\n",
            "Epoch 129/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9531 - val_loss: 0.1073 - val_accuracy: 0.9750\n",
            "Epoch 130/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9438 - val_loss: 0.1055 - val_accuracy: 0.9750\n",
            "Epoch 131/800\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1198 - accuracy: 0.9500 - val_loss: 0.1154 - val_accuracy: 0.9750\n",
            "Epoch 132/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9531 - val_loss: 0.0905 - val_accuracy: 0.9750\n",
            "Epoch 133/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9656 - val_loss: 0.1172 - val_accuracy: 0.9750\n",
            "Epoch 134/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9625 - val_loss: 0.0879 - val_accuracy: 0.9750\n",
            "Epoch 135/800\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9719 - val_loss: 0.0946 - val_accuracy: 0.9750\n",
            "Epoch 136/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9656 - val_loss: 0.0953 - val_accuracy: 0.9750\n",
            "Epoch 137/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9500 - val_loss: 0.0960 - val_accuracy: 0.9750\n",
            "Epoch 138/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9625 - val_loss: 0.1066 - val_accuracy: 0.9750\n",
            "Epoch 139/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9625 - val_loss: 0.0947 - val_accuracy: 0.9750\n",
            "Epoch 140/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9812 - val_loss: 0.1000 - val_accuracy: 0.9750\n",
            "Epoch 141/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9469 - val_loss: 0.0921 - val_accuracy: 0.9750\n",
            "Epoch 142/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9719 - val_loss: 0.0993 - val_accuracy: 0.9750\n",
            "Epoch 143/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9656 - val_loss: 0.0764 - val_accuracy: 0.9750\n",
            "Epoch 144/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9531 - val_loss: 0.0884 - val_accuracy: 0.9750\n",
            "Epoch 145/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9625\n",
            "Epoch 146/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9563 - val_loss: 0.0926 - val_accuracy: 0.9750\n",
            "Epoch 147/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9406 - val_loss: 0.0932 - val_accuracy: 0.9750\n",
            "Epoch 148/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9656 - val_loss: 0.0936 - val_accuracy: 0.9750\n",
            "Epoch 149/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9563 - val_loss: 0.0913 - val_accuracy: 0.9750\n",
            "Epoch 150/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9531 - val_loss: 0.1066 - val_accuracy: 0.9625\n",
            "Epoch 151/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9656 - val_loss: 0.1216 - val_accuracy: 0.9500\n",
            "Epoch 152/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9563 - val_loss: 0.1035 - val_accuracy: 0.9625\n",
            "Epoch 153/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9625 - val_loss: 0.0924 - val_accuracy: 0.9625\n",
            "Epoch 154/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9688 - val_loss: 0.0865 - val_accuracy: 0.9750\n",
            "Epoch 155/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.0853 - val_accuracy: 0.9750\n",
            "Epoch 156/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9656 - val_loss: 0.0894 - val_accuracy: 0.9750\n",
            "Epoch 157/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9656 - val_loss: 0.0905 - val_accuracy: 0.9625\n",
            "Epoch 158/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9688 - val_loss: 0.0859 - val_accuracy: 0.9625\n",
            "Epoch 159/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.0797 - val_accuracy: 0.9750\n",
            "Epoch 160/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9563 - val_loss: 0.0891 - val_accuracy: 0.9625\n",
            "Epoch 161/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.0749 - val_accuracy: 0.9750\n",
            "Epoch 162/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9719 - val_loss: 0.0975 - val_accuracy: 0.9500\n",
            "Epoch 163/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9625 - val_loss: 0.0835 - val_accuracy: 0.9750\n",
            "Epoch 164/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 0.0691 - val_accuracy: 0.9750\n",
            "Epoch 165/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9750 - val_loss: 0.0828 - val_accuracy: 0.9750\n",
            "Epoch 166/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9781 - val_loss: 0.0770 - val_accuracy: 0.9750\n",
            "Epoch 167/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9906 - val_loss: 0.0906 - val_accuracy: 0.9750\n",
            "Epoch 168/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 0.0839 - val_accuracy: 0.9750\n",
            "Epoch 169/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9750 - val_loss: 0.0804 - val_accuracy: 0.9750\n",
            "Epoch 170/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9594 - val_loss: 0.0906 - val_accuracy: 0.9750\n",
            "Epoch 171/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9625 - val_loss: 0.0879 - val_accuracy: 0.9750\n",
            "Epoch 172/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9719 - val_loss: 0.0683 - val_accuracy: 0.9750\n",
            "Epoch 173/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9625 - val_loss: 0.0855 - val_accuracy: 0.9750\n",
            "Epoch 174/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9656 - val_loss: 0.0830 - val_accuracy: 0.9750\n",
            "Epoch 175/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9719 - val_loss: 0.0879 - val_accuracy: 0.9750\n",
            "Epoch 176/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9656 - val_loss: 0.0786 - val_accuracy: 0.9750\n",
            "Epoch 177/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9688 - val_loss: 0.0977 - val_accuracy: 0.9750\n",
            "Epoch 178/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9656 - val_loss: 0.0755 - val_accuracy: 0.9750\n",
            "Epoch 179/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.0703 - val_accuracy: 0.9625\n",
            "Epoch 180/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9656 - val_loss: 0.1001 - val_accuracy: 0.9625\n",
            "Epoch 181/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.0799 - val_accuracy: 0.9750\n",
            "Epoch 182/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9844 - val_loss: 0.0795 - val_accuracy: 0.9750\n",
            "Epoch 183/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9719 - val_loss: 0.0976 - val_accuracy: 0.9625\n",
            "Epoch 184/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9688 - val_loss: 0.0753 - val_accuracy: 0.9750\n",
            "Epoch 185/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9719 - val_loss: 0.0815 - val_accuracy: 0.9750\n",
            "Epoch 186/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9625 - val_loss: 0.0891 - val_accuracy: 0.9625\n",
            "Epoch 187/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9781 - val_loss: 0.0867 - val_accuracy: 0.9750\n",
            "Epoch 188/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9688 - val_loss: 0.0976 - val_accuracy: 0.9750\n",
            "Epoch 189/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9844 - val_loss: 0.0756 - val_accuracy: 0.9750\n",
            "Epoch 190/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9719 - val_loss: 0.0806 - val_accuracy: 0.9750\n",
            "Epoch 191/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9844 - val_loss: 0.0848 - val_accuracy: 0.9750\n",
            "Epoch 192/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9844 - val_loss: 0.0854 - val_accuracy: 0.9750\n",
            "Epoch 193/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9719 - val_loss: 0.0953 - val_accuracy: 0.9750\n",
            "Epoch 194/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9594 - val_loss: 0.0699 - val_accuracy: 0.9750\n",
            "Epoch 195/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9812 - val_loss: 0.0748 - val_accuracy: 0.9750\n",
            "Epoch 196/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9719 - val_loss: 0.0889 - val_accuracy: 0.9750\n",
            "Epoch 197/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9781 - val_loss: 0.0960 - val_accuracy: 0.9625\n",
            "Epoch 198/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9781 - val_loss: 0.0871 - val_accuracy: 0.9750\n",
            "Epoch 199/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.0645 - val_accuracy: 0.9750\n",
            "Epoch 200/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 0.0753 - val_accuracy: 0.9625\n",
            "Epoch 201/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9781 - val_loss: 0.1183 - val_accuracy: 0.9500\n",
            "Epoch 202/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9844 - val_loss: 0.0793 - val_accuracy: 0.9750\n",
            "Epoch 203/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9656 - val_loss: 0.0821 - val_accuracy: 0.9750\n",
            "Epoch 204/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9781 - val_loss: 0.0875 - val_accuracy: 0.9625\n",
            "Epoch 205/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9688 - val_loss: 0.0843 - val_accuracy: 0.9750\n",
            "Epoch 206/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.0769 - val_accuracy: 0.9750\n",
            "Epoch 207/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9656 - val_loss: 0.0754 - val_accuracy: 0.9750\n",
            "Epoch 208/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9781 - val_loss: 0.0787 - val_accuracy: 0.9750\n",
            "Epoch 209/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9781 - val_loss: 0.0700 - val_accuracy: 0.9750\n",
            "Epoch 210/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9875 - val_loss: 0.0764 - val_accuracy: 0.9750\n",
            "Epoch 211/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9750 - val_loss: 0.0806 - val_accuracy: 0.9625\n",
            "Epoch 212/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9688 - val_loss: 0.0527 - val_accuracy: 0.9750\n",
            "Epoch 213/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9688 - val_loss: 0.0651 - val_accuracy: 0.9750\n",
            "Epoch 214/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9875 - val_loss: 0.0663 - val_accuracy: 0.9750\n",
            "Epoch 215/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 0.0644 - val_accuracy: 0.9750\n",
            "Epoch 216/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9781 - val_loss: 0.0488 - val_accuracy: 0.9875\n",
            "Epoch 217/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9875 - val_loss: 0.0623 - val_accuracy: 0.9750\n",
            "Epoch 218/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9625 - val_loss: 0.0769 - val_accuracy: 0.9750\n",
            "Epoch 219/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9656 - val_loss: 0.0662 - val_accuracy: 0.9750\n",
            "Epoch 220/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9719 - val_loss: 0.0607 - val_accuracy: 0.9875\n",
            "Epoch 221/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9750 - val_loss: 0.0695 - val_accuracy: 0.9750\n",
            "Epoch 222/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9719 - val_loss: 0.0701 - val_accuracy: 0.9750\n",
            "Epoch 223/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.0774 - val_accuracy: 0.9750\n",
            "Epoch 224/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9750 - val_loss: 0.0893 - val_accuracy: 0.9750\n",
            "Epoch 225/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9875 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
            "Epoch 226/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9812 - val_loss: 0.0852 - val_accuracy: 0.9750\n",
            "Epoch 227/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9781 - val_loss: 0.0790 - val_accuracy: 0.9750\n",
            "Epoch 228/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9750 - val_loss: 0.0817 - val_accuracy: 0.9750\n",
            "Epoch 229/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9781 - val_loss: 0.0550 - val_accuracy: 0.9875\n",
            "Epoch 230/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9875 - val_loss: 0.0797 - val_accuracy: 0.9750\n",
            "Epoch 231/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
            "Epoch 232/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9750 - val_loss: 0.0705 - val_accuracy: 0.9750\n",
            "Epoch 233/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9906 - val_loss: 0.0607 - val_accuracy: 0.9750\n",
            "Epoch 234/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9906 - val_loss: 0.0602 - val_accuracy: 0.9750\n",
            "Epoch 235/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9750 - val_loss: 0.0619 - val_accuracy: 0.9750\n",
            "Epoch 236/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9656 - val_loss: 0.0679 - val_accuracy: 0.9750\n",
            "Epoch 237/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9781 - val_loss: 0.0503 - val_accuracy: 0.9875\n",
            "Epoch 238/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.0600 - val_accuracy: 0.9750\n",
            "Epoch 239/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9781 - val_loss: 0.0589 - val_accuracy: 0.9750\n",
            "Epoch 240/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0642 - val_accuracy: 0.9750\n",
            "Epoch 241/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 0.0510 - val_accuracy: 0.9750\n",
            "Epoch 242/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9812 - val_loss: 0.0567 - val_accuracy: 0.9750\n",
            "Epoch 243/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9781 - val_loss: 0.0580 - val_accuracy: 0.9750\n",
            "Epoch 244/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9781 - val_loss: 0.0528 - val_accuracy: 0.9875\n",
            "Epoch 245/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9781 - val_loss: 0.0570 - val_accuracy: 0.9750\n",
            "Epoch 246/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9906 - val_loss: 0.1018 - val_accuracy: 0.9625\n",
            "Epoch 247/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
            "Epoch 248/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9750 - val_loss: 0.0489 - val_accuracy: 0.9750\n",
            "Epoch 249/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9719 - val_loss: 0.0446 - val_accuracy: 0.9875\n",
            "Epoch 250/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0450 - val_accuracy: 0.9750\n",
            "Epoch 251/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.0684 - val_accuracy: 0.9750\n",
            "Epoch 252/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.0780 - val_accuracy: 0.9625\n",
            "Epoch 253/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.0638 - val_accuracy: 0.9875\n",
            "Epoch 254/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9781 - val_loss: 0.0444 - val_accuracy: 0.9875\n",
            "Epoch 255/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 0.0791 - val_accuracy: 0.9750\n",
            "Epoch 256/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9812 - val_loss: 0.0690 - val_accuracy: 0.9750\n",
            "Epoch 257/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.0470 - val_accuracy: 0.9750\n",
            "Epoch 258/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9906 - val_loss: 0.0757 - val_accuracy: 0.9625\n",
            "Epoch 259/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9781 - val_loss: 0.0650 - val_accuracy: 0.9750\n",
            "Epoch 260/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.0646 - val_accuracy: 0.9750\n",
            "Epoch 261/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9812 - val_loss: 0.0840 - val_accuracy: 0.9625\n",
            "Epoch 262/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9781 - val_loss: 0.1063 - val_accuracy: 0.9625\n",
            "Epoch 263/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9844 - val_loss: 0.0828 - val_accuracy: 0.9750\n",
            "Epoch 264/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9812 - val_loss: 0.0738 - val_accuracy: 0.9750\n",
            "Epoch 265/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9875 - val_loss: 0.0506 - val_accuracy: 0.9750\n",
            "Epoch 266/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9906 - val_loss: 0.0826 - val_accuracy: 0.9625\n",
            "Epoch 267/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9750 - val_loss: 0.0615 - val_accuracy: 0.9750\n",
            "Epoch 268/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9844 - val_loss: 0.0628 - val_accuracy: 0.9750\n",
            "Epoch 269/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9812 - val_loss: 0.0838 - val_accuracy: 0.9750\n",
            "Epoch 270/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9844 - val_loss: 0.0750 - val_accuracy: 0.9750\n",
            "Epoch 271/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9906 - val_loss: 0.0520 - val_accuracy: 0.9750\n",
            "Epoch 272/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9875 - val_loss: 0.0789 - val_accuracy: 0.9750\n",
            "Epoch 273/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9875 - val_loss: 0.0454 - val_accuracy: 0.9625\n",
            "Epoch 274/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9688 - val_loss: 0.0566 - val_accuracy: 0.9875\n",
            "Epoch 275/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9719 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
            "Epoch 276/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9781 - val_loss: 0.0998 - val_accuracy: 0.9625\n",
            "Epoch 277/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9750 - val_loss: 0.0439 - val_accuracy: 0.9750\n",
            "Epoch 278/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.0491 - val_accuracy: 0.9750\n",
            "Epoch 279/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 0.0530 - val_accuracy: 0.9750\n",
            "Epoch 280/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9781 - val_loss: 0.0672 - val_accuracy: 0.9750\n",
            "Epoch 281/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9781 - val_loss: 0.0664 - val_accuracy: 0.9750\n",
            "Epoch 282/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9781 - val_loss: 0.0646 - val_accuracy: 0.9750\n",
            "Epoch 283/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9812 - val_loss: 0.0402 - val_accuracy: 0.9875\n",
            "Epoch 284/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9906 - val_loss: 0.0636 - val_accuracy: 0.9750\n",
            "Epoch 285/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9969 - val_loss: 0.0676 - val_accuracy: 0.9750\n",
            "Epoch 286/800\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9750 - val_loss: 0.0485 - val_accuracy: 0.9875\n",
            "Epoch 287/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9844 - val_loss: 0.0341 - val_accuracy: 0.9875\n",
            "Epoch 288/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.0388 - val_accuracy: 0.9875\n",
            "Epoch 289/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9844 - val_loss: 0.0428 - val_accuracy: 0.9875\n",
            "Epoch 290/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9875 - val_loss: 0.0720 - val_accuracy: 0.9750\n",
            "Epoch 291/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9969 - val_loss: 0.0757 - val_accuracy: 0.9750\n",
            "Epoch 292/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.0458 - val_accuracy: 0.9750\n",
            "Epoch 293/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.0475 - val_accuracy: 0.9875\n",
            "Epoch 294/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.0565 - val_accuracy: 0.9875\n",
            "Epoch 295/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0362 - val_accuracy: 0.9875\n",
            "Epoch 296/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9969 - val_loss: 0.0459 - val_accuracy: 0.9875\n",
            "Epoch 297/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9875 - val_loss: 0.0909 - val_accuracy: 0.9625\n",
            "Epoch 298/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9750 - val_loss: 0.0591 - val_accuracy: 0.9875\n",
            "Epoch 299/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9781 - val_loss: 0.0371 - val_accuracy: 0.9875\n",
            "Epoch 300/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9937 - val_loss: 0.0425 - val_accuracy: 0.9750\n",
            "Epoch 301/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9688 - val_loss: 0.0494 - val_accuracy: 0.9750\n",
            "Epoch 302/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9969 - val_loss: 0.0717 - val_accuracy: 0.9625\n",
            "Epoch 303/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9781 - val_loss: 0.0440 - val_accuracy: 0.9750\n",
            "Epoch 304/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0910 - val_accuracy: 0.9625\n",
            "Epoch 305/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9844 - val_loss: 0.0363 - val_accuracy: 0.9875\n",
            "Epoch 306/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9875 - val_loss: 0.0510 - val_accuracy: 0.9875\n",
            "Epoch 307/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9937 - val_loss: 0.0385 - val_accuracy: 0.9875\n",
            "Epoch 308/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9844 - val_loss: 0.0439 - val_accuracy: 0.9750\n",
            "Epoch 309/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.0668 - val_accuracy: 0.9750\n",
            "Epoch 310/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9812 - val_loss: 0.0724 - val_accuracy: 0.9750\n",
            "Epoch 311/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9969 - val_loss: 0.0675 - val_accuracy: 0.9625\n",
            "Epoch 312/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9812 - val_loss: 0.0508 - val_accuracy: 0.9750\n",
            "Epoch 313/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9844 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 314/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9844 - val_loss: 0.1001 - val_accuracy: 0.9625\n",
            "Epoch 315/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9688 - val_loss: 0.0325 - val_accuracy: 0.9875\n",
            "Epoch 316/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9875 - val_loss: 0.0596 - val_accuracy: 0.9750\n",
            "Epoch 317/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9844 - val_loss: 0.0762 - val_accuracy: 0.9625\n",
            "Epoch 318/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9969 - val_loss: 0.0526 - val_accuracy: 0.9875\n",
            "Epoch 319/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0835 - val_accuracy: 0.9750\n",
            "Epoch 320/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.0572 - val_accuracy: 0.9750\n",
            "Epoch 321/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9812 - val_loss: 0.0371 - val_accuracy: 0.9750\n",
            "Epoch 322/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.0523 - val_accuracy: 0.9750\n",
            "Epoch 323/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9812 - val_loss: 0.0490 - val_accuracy: 0.9875\n",
            "Epoch 324/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.0323 - val_accuracy: 0.9875\n",
            "Epoch 325/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9906 - val_loss: 0.0493 - val_accuracy: 0.9875\n",
            "Epoch 326/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 0.0548 - val_accuracy: 0.9875\n",
            "Epoch 327/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.0362 - val_accuracy: 0.9875\n",
            "Epoch 328/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9937 - val_loss: 0.0468 - val_accuracy: 0.9750\n",
            "Epoch 329/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0588 - val_accuracy: 0.9750\n",
            "Epoch 330/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.0329 - val_accuracy: 0.9875\n",
            "Epoch 331/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9937 - val_loss: 0.0723 - val_accuracy: 0.9750\n",
            "Epoch 332/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9875\n",
            "Epoch 333/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9937 - val_loss: 0.0647 - val_accuracy: 0.9750\n",
            "Epoch 334/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0499 - val_accuracy: 0.9625\n",
            "Epoch 335/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9969 - val_loss: 0.1277 - val_accuracy: 0.9500\n",
            "Epoch 336/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.0637 - val_accuracy: 0.9875\n",
            "Epoch 337/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 0.0460 - val_accuracy: 0.9750\n",
            "Epoch 338/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.0388 - val_accuracy: 0.9875\n",
            "Epoch 339/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9781 - val_loss: 0.0641 - val_accuracy: 0.9750\n",
            "Epoch 340/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9906 - val_loss: 0.0566 - val_accuracy: 0.9750\n",
            "Epoch 341/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.0673 - val_accuracy: 0.9750\n",
            "Epoch 342/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9844 - val_loss: 0.0297 - val_accuracy: 0.9875\n",
            "Epoch 343/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9906 - val_loss: 0.0898 - val_accuracy: 0.9625\n",
            "Epoch 344/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.0570 - val_accuracy: 0.9875\n",
            "Epoch 345/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9875 - val_loss: 0.0276 - val_accuracy: 0.9875\n",
            "Epoch 346/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 0.0608 - val_accuracy: 0.9750\n",
            "Epoch 347/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9969 - val_loss: 0.0380 - val_accuracy: 0.9875\n",
            "Epoch 348/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9906 - val_loss: 0.0476 - val_accuracy: 0.9875\n",
            "Epoch 349/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.0385 - val_accuracy: 0.9875\n",
            "Epoch 350/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.0329 - val_accuracy: 0.9875\n",
            "Epoch 351/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 352/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.0472 - val_accuracy: 0.9750\n",
            "Epoch 353/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9812 - val_loss: 0.0320 - val_accuracy: 0.9875\n",
            "Epoch 354/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.0562 - val_accuracy: 0.9750\n",
            "Epoch 355/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9937 - val_loss: 0.0309 - val_accuracy: 0.9875\n",
            "Epoch 356/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0341 - val_accuracy: 0.9750\n",
            "Epoch 357/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0486 - val_accuracy: 0.9750\n",
            "Epoch 358/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9906 - val_loss: 0.0429 - val_accuracy: 0.9750\n",
            "Epoch 359/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9937 - val_loss: 0.0464 - val_accuracy: 0.9875\n",
            "Epoch 360/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0973 - val_accuracy: 0.9625\n",
            "Epoch 361/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9906 - val_loss: 0.0308 - val_accuracy: 0.9875\n",
            "Epoch 362/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9844 - val_loss: 0.0438 - val_accuracy: 0.9750\n",
            "Epoch 363/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9937 - val_loss: 0.0755 - val_accuracy: 0.9750\n",
            "Epoch 364/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9750 - val_loss: 0.0439 - val_accuracy: 0.9750\n",
            "Epoch 365/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0623 - val_accuracy: 0.9750\n",
            "Epoch 366/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9875\n",
            "Epoch 367/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.0499 - val_accuracy: 0.9750\n",
            "Epoch 368/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9844 - val_loss: 0.0437 - val_accuracy: 0.9750\n",
            "Epoch 369/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.0450 - val_accuracy: 0.9750\n",
            "Epoch 370/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9750\n",
            "Epoch 371/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0398 - val_accuracy: 0.9750\n",
            "Epoch 372/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9812 - val_loss: 0.0748 - val_accuracy: 0.9625\n",
            "Epoch 373/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9906 - val_loss: 0.0494 - val_accuracy: 0.9750\n",
            "Epoch 374/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0658 - val_accuracy: 0.9750\n",
            "Epoch 375/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.0497 - val_accuracy: 0.9875\n",
            "Epoch 376/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 0.0411 - val_accuracy: 0.9750\n",
            "Epoch 377/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9844 - val_loss: 0.0445 - val_accuracy: 0.9875\n",
            "Epoch 378/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9906 - val_loss: 0.0682 - val_accuracy: 0.9750\n",
            "Epoch 379/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0450 - val_accuracy: 0.9875\n",
            "Epoch 380/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0783 - val_accuracy: 0.9750\n",
            "Epoch 381/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9812 - val_loss: 0.0558 - val_accuracy: 0.9750\n",
            "Epoch 382/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.0606 - val_accuracy: 0.9875\n",
            "Epoch 383/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0730 - val_accuracy: 0.9625\n",
            "Epoch 384/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0571 - val_accuracy: 0.9750\n",
            "Epoch 385/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.0444 - val_accuracy: 0.9875\n",
            "Epoch 386/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9875 - val_loss: 0.0537 - val_accuracy: 0.9750\n",
            "Epoch 387/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.0690 - val_accuracy: 0.9750\n",
            "Epoch 388/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0372 - val_accuracy: 0.9875\n",
            "Epoch 389/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0446 - val_accuracy: 0.9750\n",
            "Epoch 390/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9875 - val_loss: 0.0634 - val_accuracy: 0.9750\n",
            "Epoch 391/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9906 - val_loss: 0.0663 - val_accuracy: 0.9750\n",
            "Epoch 392/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9875 - val_loss: 0.1052 - val_accuracy: 0.9625\n",
            "Epoch 393/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.0534 - val_accuracy: 0.9750\n",
            "Epoch 394/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0499 - val_accuracy: 0.9750\n",
            "Epoch 395/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.1191 - val_accuracy: 0.9750\n",
            "Epoch 396/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9969 - val_loss: 0.0437 - val_accuracy: 0.9750\n",
            "Epoch 397/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.0420 - val_accuracy: 0.9750\n",
            "Epoch 398/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.0549 - val_accuracy: 0.9750\n",
            "Epoch 399/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
            "Epoch 400/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9844 - val_loss: 0.0692 - val_accuracy: 0.9750\n",
            "Epoch 401/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9844 - val_loss: 0.0605 - val_accuracy: 0.9750\n",
            "Epoch 402/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9875 - val_loss: 0.0789 - val_accuracy: 0.9750\n",
            "Epoch 403/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9875 - val_loss: 0.0364 - val_accuracy: 0.9750\n",
            "Epoch 404/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.0753 - val_accuracy: 0.9750\n",
            "Epoch 405/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9844 - val_loss: 0.0487 - val_accuracy: 0.9750\n",
            "Epoch 406/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9844 - val_loss: 0.0699 - val_accuracy: 0.9750\n",
            "Epoch 407/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9875 - val_loss: 0.0302 - val_accuracy: 0.9750\n",
            "Epoch 408/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9906 - val_loss: 0.0457 - val_accuracy: 0.9875\n",
            "Epoch 409/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9844 - val_loss: 0.0597 - val_accuracy: 0.9875\n",
            "Epoch 410/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9937 - val_loss: 0.0456 - val_accuracy: 0.9875\n",
            "Epoch 411/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0560 - val_accuracy: 0.9750\n",
            "Epoch 412/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9844 - val_loss: 0.0425 - val_accuracy: 0.9875\n",
            "Epoch 413/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9844 - val_loss: 0.1268 - val_accuracy: 0.9625\n",
            "Epoch 414/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0561 - val_accuracy: 0.9750\n",
            "Epoch 415/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9906 - val_loss: 0.0274 - val_accuracy: 0.9875\n",
            "Epoch 416/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: 0.0747 - val_accuracy: 0.9750\n",
            "Epoch 417/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 0.0521 - val_accuracy: 0.9750\n",
            "Epoch 418/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9937 - val_loss: 0.0344 - val_accuracy: 0.9750\n",
            "Epoch 419/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.0345 - val_accuracy: 0.9875\n",
            "Epoch 420/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9875 - val_loss: 0.0295 - val_accuracy: 0.9875\n",
            "Epoch 421/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9750\n",
            "Epoch 422/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9844 - val_loss: 0.0578 - val_accuracy: 0.9875\n",
            "Epoch 423/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0686 - val_accuracy: 0.9750\n",
            "Epoch 424/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0363 - val_accuracy: 0.9875\n",
            "Epoch 425/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9750\n",
            "Epoch 426/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0339 - val_accuracy: 0.9875\n",
            "Epoch 427/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9969 - val_loss: 0.0394 - val_accuracy: 0.9875\n",
            "Epoch 428/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9875\n",
            "Epoch 429/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9750\n",
            "Epoch 430/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9875\n",
            "Epoch 431/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9875\n",
            "Epoch 432/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.0486 - val_accuracy: 0.9750\n",
            "Epoch 433/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0505 - val_accuracy: 0.9750\n",
            "Epoch 434/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0648 - val_accuracy: 0.9625\n",
            "Epoch 435/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9750\n",
            "Epoch 436/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0502 - val_accuracy: 0.9750\n",
            "Epoch 437/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9906 - val_loss: 0.0330 - val_accuracy: 0.9875\n",
            "Epoch 438/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9812 - val_loss: 0.0353 - val_accuracy: 0.9750\n",
            "Epoch 439/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9781 - val_loss: 0.0492 - val_accuracy: 0.9875\n",
            "Epoch 440/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9750 - val_loss: 0.0791 - val_accuracy: 0.9625\n",
            "Epoch 441/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9844 - val_loss: 0.0578 - val_accuracy: 0.9750\n",
            "Epoch 442/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 0.0342 - val_accuracy: 0.9750\n",
            "Epoch 443/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0368 - val_accuracy: 0.9875\n",
            "Epoch 444/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0658 - val_accuracy: 0.9750\n",
            "Epoch 445/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0329 - val_accuracy: 0.9750\n",
            "Epoch 446/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0456 - val_accuracy: 0.9750\n",
            "Epoch 447/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.0747 - val_accuracy: 0.9750\n",
            "Epoch 448/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.1273 - val_accuracy: 0.9625\n",
            "Epoch 449/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0676 - val_accuracy: 0.9875\n",
            "Epoch 450/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9781 - val_loss: 0.0647 - val_accuracy: 0.9750\n",
            "Epoch 451/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9844 - val_loss: 0.1121 - val_accuracy: 0.9500\n",
            "Epoch 452/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9844 - val_loss: 0.0841 - val_accuracy: 0.9875\n",
            "Epoch 453/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9719 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 454/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9937 - val_loss: 0.0649 - val_accuracy: 0.9750\n",
            "Epoch 455/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9875\n",
            "Epoch 456/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 457/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0349 - val_accuracy: 0.9875\n",
            "Epoch 458/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 0.0513 - val_accuracy: 0.9750\n",
            "Epoch 459/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9969 - val_loss: 0.0365 - val_accuracy: 0.9875\n",
            "Epoch 460/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.0783 - val_accuracy: 0.9750\n",
            "Epoch 461/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0487 - val_accuracy: 0.9750\n",
            "Epoch 462/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.0357 - val_accuracy: 0.9875\n",
            "Epoch 463/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0486 - val_accuracy: 0.9875\n",
            "Epoch 464/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0470 - val_accuracy: 0.9750\n",
            "Epoch 465/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0407 - val_accuracy: 0.9750\n",
            "Epoch 466/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9875\n",
            "Epoch 467/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0426 - val_accuracy: 0.9750\n",
            "Epoch 468/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0330 - val_accuracy: 0.9750\n",
            "Epoch 469/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9906 - val_loss: 0.0387 - val_accuracy: 0.9875\n",
            "Epoch 470/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9875\n",
            "Epoch 471/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9875\n",
            "Epoch 472/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0525 - val_accuracy: 0.9875\n",
            "Epoch 473/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9906 - val_loss: 0.0619 - val_accuracy: 0.9875\n",
            "Epoch 474/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
            "Epoch 475/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0515 - val_accuracy: 0.9750\n",
            "Epoch 476/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9937 - val_loss: 0.0730 - val_accuracy: 0.9750\n",
            "Epoch 477/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9812 - val_loss: 0.0454 - val_accuracy: 0.9875\n",
            "Epoch 478/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0536 - val_accuracy: 0.9875\n",
            "Epoch 479/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9875 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 480/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9875 - val_loss: 0.0653 - val_accuracy: 0.9875\n",
            "Epoch 481/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9906 - val_loss: 0.0817 - val_accuracy: 0.9750\n",
            "Epoch 482/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.1110 - val_accuracy: 0.9625\n",
            "Epoch 483/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9937 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
            "Epoch 484/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9750\n",
            "Epoch 485/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0348 - val_accuracy: 0.9750\n",
            "Epoch 486/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9937 - val_loss: 0.0500 - val_accuracy: 0.9750\n",
            "Epoch 487/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9875\n",
            "Epoch 488/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9750\n",
            "Epoch 489/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.0328 - val_accuracy: 0.9750\n",
            "Epoch 490/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0541 - val_accuracy: 0.9875\n",
            "Epoch 491/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9937 - val_loss: 0.0706 - val_accuracy: 0.9750\n",
            "Epoch 492/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9812 - val_loss: 0.0429 - val_accuracy: 0.9750\n",
            "Epoch 493/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9875 - val_loss: 0.0262 - val_accuracy: 0.9750\n",
            "Epoch 494/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.0406 - val_accuracy: 0.9875\n",
            "Epoch 495/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9875 - val_loss: 0.0489 - val_accuracy: 0.9875\n",
            "Epoch 496/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0553 - val_accuracy: 0.9875\n",
            "Epoch 497/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
            "Epoch 498/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9875\n",
            "Epoch 499/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9875\n",
            "Epoch 500/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9875\n",
            "Epoch 501/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 502/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.0848 - val_accuracy: 0.9750\n",
            "Epoch 503/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9844 - val_loss: 0.0515 - val_accuracy: 0.9875\n",
            "Epoch 504/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0241 - val_accuracy: 0.9875\n",
            "Epoch 505/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9781 - val_loss: 0.0439 - val_accuracy: 0.9750\n",
            "Epoch 506/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.0493 - val_accuracy: 0.9750\n",
            "Epoch 507/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.0412 - val_accuracy: 0.9875\n",
            "Epoch 508/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0437 - val_accuracy: 0.9875\n",
            "Epoch 509/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9875\n",
            "Epoch 510/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9875\n",
            "Epoch 511/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9875\n",
            "Epoch 512/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9875\n",
            "Epoch 513/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0378 - val_accuracy: 0.9750\n",
            "Epoch 514/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9750\n",
            "Epoch 515/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0380 - val_accuracy: 0.9750\n",
            "Epoch 516/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0371 - val_accuracy: 0.9875\n",
            "Epoch 517/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.0751 - val_accuracy: 0.9750\n",
            "Epoch 518/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0375 - val_accuracy: 0.9875\n",
            "Epoch 519/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.1172 - val_accuracy: 0.9500\n",
            "Epoch 520/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 521/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0719 - val_accuracy: 0.9750\n",
            "Epoch 522/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 0.0620 - val_accuracy: 0.9750\n",
            "Epoch 523/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0290 - val_accuracy: 0.9875\n",
            "Epoch 524/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0861 - val_accuracy: 0.9625\n",
            "Epoch 525/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9937 - val_loss: 0.0192 - val_accuracy: 0.9875\n",
            "Epoch 526/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0293 - val_accuracy: 0.9875\n",
            "Epoch 527/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0816 - val_accuracy: 0.9625\n",
            "Epoch 528/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0951 - val_accuracy: 0.9750\n",
            "Epoch 529/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0714 - val_accuracy: 0.9875\n",
            "Epoch 530/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 0.0336 - val_accuracy: 0.9875\n",
            "Epoch 531/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9906 - val_loss: 0.0524 - val_accuracy: 0.9875\n",
            "Epoch 532/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9875 - val_loss: 0.0434 - val_accuracy: 0.9750\n",
            "Epoch 533/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9781 - val_loss: 0.0681 - val_accuracy: 0.9750\n",
            "Epoch 534/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0673 - val_accuracy: 0.9625\n",
            "Epoch 535/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0520 - val_accuracy: 0.9750\n",
            "Epoch 536/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9750\n",
            "Epoch 537/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0673 - val_accuracy: 0.9750\n",
            "Epoch 538/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9844 - val_loss: 0.0800 - val_accuracy: 0.9750\n",
            "Epoch 539/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.0484 - val_accuracy: 0.9750\n",
            "Epoch 540/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9937 - val_loss: 0.0543 - val_accuracy: 0.9625\n",
            "Epoch 541/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9750\n",
            "Epoch 542/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0519 - val_accuracy: 0.9750\n",
            "Epoch 543/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0340 - val_accuracy: 0.9875\n",
            "Epoch 544/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0603 - val_accuracy: 0.9750\n",
            "Epoch 545/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0442 - val_accuracy: 0.9875\n",
            "Epoch 546/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0532 - val_accuracy: 0.9750\n",
            "Epoch 547/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9906 - val_loss: 0.0986 - val_accuracy: 0.9625\n",
            "Epoch 548/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9906 - val_loss: 0.0636 - val_accuracy: 0.9750\n",
            "Epoch 549/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9750\n",
            "Epoch 550/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.0533 - val_accuracy: 0.9750\n",
            "Epoch 551/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1193 - val_accuracy: 0.9625\n",
            "Epoch 552/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9937 - val_loss: 0.0631 - val_accuracy: 0.9750\n",
            "Epoch 553/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9750\n",
            "Epoch 554/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9750\n",
            "Epoch 555/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9750\n",
            "Epoch 556/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9937 - val_loss: 0.0315 - val_accuracy: 0.9875\n",
            "Epoch 557/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0423 - val_accuracy: 0.9875\n",
            "Epoch 558/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9875 - val_loss: 0.0352 - val_accuracy: 0.9875\n",
            "Epoch 559/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.0300 - val_accuracy: 0.9875\n",
            "Epoch 560/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.0300 - val_accuracy: 0.9875\n",
            "Epoch 561/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9875\n",
            "Epoch 562/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9625\n",
            "Epoch 563/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9906 - val_loss: 0.0506 - val_accuracy: 0.9750\n",
            "Epoch 564/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0411 - val_accuracy: 0.9750\n",
            "Epoch 565/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9875\n",
            "Epoch 566/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9750\n",
            "Epoch 567/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0275 - val_accuracy: 0.9750\n",
            "Epoch 568/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0273 - val_accuracy: 0.9875\n",
            "Epoch 569/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9875\n",
            "Epoch 570/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9906 - val_loss: 0.0460 - val_accuracy: 0.9875\n",
            "Epoch 571/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0887 - val_accuracy: 0.9750\n",
            "Epoch 572/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9969 - val_loss: 0.0976 - val_accuracy: 0.9625\n",
            "Epoch 573/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9750\n",
            "Epoch 574/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9875\n",
            "Epoch 575/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9875\n",
            "Epoch 576/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9750\n",
            "Epoch 577/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
            "Epoch 578/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 579/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9750\n",
            "Epoch 580/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9750\n",
            "Epoch 581/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9875\n",
            "Epoch 582/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9969 - val_loss: 0.0553 - val_accuracy: 0.9875\n",
            "Epoch 583/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0360 - val_accuracy: 0.9875\n",
            "Epoch 584/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0709 - val_accuracy: 0.9750\n",
            "Epoch 585/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9750\n",
            "Epoch 586/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9906 - val_loss: 0.0452 - val_accuracy: 0.9875\n",
            "Epoch 587/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9750\n",
            "Epoch 588/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0539 - val_accuracy: 0.9750\n",
            "Epoch 589/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9750\n",
            "Epoch 590/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9750\n",
            "Epoch 591/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9875\n",
            "Epoch 592/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9875\n",
            "Epoch 593/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.0595 - val_accuracy: 0.9875\n",
            "Epoch 594/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9906 - val_loss: 0.0592 - val_accuracy: 0.9750\n",
            "Epoch 595/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9875\n",
            "Epoch 596/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.0564 - val_accuracy: 0.9875\n",
            "Epoch 597/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.0584 - val_accuracy: 0.9750\n",
            "Epoch 598/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 0.0824 - val_accuracy: 0.9625\n",
            "Epoch 599/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0471 - val_accuracy: 0.9750\n",
            "Epoch 600/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.0604 - val_accuracy: 0.9750\n",
            "Epoch 601/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.0507 - val_accuracy: 0.9750\n",
            "Epoch 602/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0556 - val_accuracy: 0.9750\n",
            "Epoch 603/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9906 - val_loss: 0.0279 - val_accuracy: 0.9875\n",
            "Epoch 604/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9906 - val_loss: 0.0538 - val_accuracy: 0.9750\n",
            "Epoch 605/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9937 - val_loss: 0.0559 - val_accuracy: 0.9875\n",
            "Epoch 606/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9875\n",
            "Epoch 607/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9937 - val_loss: 0.0617 - val_accuracy: 0.9750\n",
            "Epoch 608/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.0314 - val_accuracy: 0.9875\n",
            "Epoch 609/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0621 - val_accuracy: 0.9750\n",
            "Epoch 610/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.0867 - val_accuracy: 0.9750\n",
            "Epoch 611/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.0301 - val_accuracy: 0.9875\n",
            "Epoch 612/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9906 - val_loss: 0.0506 - val_accuracy: 0.9750\n",
            "Epoch 613/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0242 - val_accuracy: 0.9875\n",
            "Epoch 614/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9937 - val_loss: 0.1026 - val_accuracy: 0.9625\n",
            "Epoch 615/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.0421 - val_accuracy: 0.9875\n",
            "Epoch 616/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0507 - val_accuracy: 0.9875\n",
            "Epoch 617/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0880 - val_accuracy: 0.9750\n",
            "Epoch 618/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.0398 - val_accuracy: 0.9875\n",
            "Epoch 619/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 0.0591 - val_accuracy: 0.9875\n",
            "Epoch 620/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9875 - val_loss: 0.0923 - val_accuracy: 0.9750\n",
            "Epoch 621/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9969 - val_loss: 0.0190 - val_accuracy: 0.9875\n",
            "Epoch 622/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0312 - val_accuracy: 0.9875\n",
            "Epoch 623/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9875\n",
            "Epoch 624/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0390 - val_accuracy: 0.9750\n",
            "Epoch 625/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.1183 - val_accuracy: 0.9750\n",
            "Epoch 626/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.0458 - val_accuracy: 0.9750\n",
            "Epoch 627/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9906 - val_loss: 0.0395 - val_accuracy: 0.9750\n",
            "Epoch 628/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.1373 - val_accuracy: 0.9625\n",
            "Epoch 629/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9844 - val_loss: 0.0509 - val_accuracy: 0.9750\n",
            "Epoch 630/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9781 - val_loss: 0.0542 - val_accuracy: 0.9750\n",
            "Epoch 631/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9812 - val_loss: 0.0537 - val_accuracy: 0.9750\n",
            "Epoch 632/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0147 - val_accuracy: 0.9875\n",
            "Epoch 633/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0227 - val_accuracy: 0.9875\n",
            "Epoch 634/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9937 - val_loss: 0.0500 - val_accuracy: 0.9750\n",
            "Epoch 635/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0366 - val_accuracy: 0.9750\n",
            "Epoch 636/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.0249 - val_accuracy: 0.9875\n",
            "Epoch 637/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.0237 - val_accuracy: 0.9875\n",
            "Epoch 638/800\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9750\n",
            "Epoch 639/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9969 - val_loss: 0.0434 - val_accuracy: 0.9750\n",
            "Epoch 640/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0718 - val_accuracy: 0.9875\n",
            "Epoch 641/800\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9875\n",
            "Epoch 642/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9875\n",
            "Epoch 643/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 0.0551 - val_accuracy: 0.9750\n",
            "Epoch 644/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9750\n",
            "Epoch 645/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 0.0569 - val_accuracy: 0.9750\n",
            "Epoch 646/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9969 - val_loss: 0.0217 - val_accuracy: 0.9875\n",
            "Epoch 647/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9875\n",
            "Epoch 648/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.0688 - val_accuracy: 0.9750\n",
            "Epoch 649/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9750\n",
            "Epoch 650/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 651/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9844 - val_loss: 0.0943 - val_accuracy: 0.9750\n",
            "Epoch 652/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0614 - val_accuracy: 0.9750\n",
            "Epoch 653/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0221 - val_accuracy: 0.9750\n",
            "Epoch 654/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 655/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9906 - val_loss: 0.0453 - val_accuracy: 0.9875\n",
            "Epoch 656/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9875 - val_loss: 0.1495 - val_accuracy: 0.9625\n",
            "Epoch 657/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9906 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
            "Epoch 658/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9750\n",
            "Epoch 659/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9750\n",
            "Epoch 660/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0140 - val_accuracy: 0.9875\n",
            "Epoch 661/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9906 - val_loss: 0.0561 - val_accuracy: 0.9875\n",
            "Epoch 662/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9875\n",
            "Epoch 663/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9875\n",
            "Epoch 664/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9875\n",
            "Epoch 665/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9875\n",
            "Epoch 666/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.0544 - val_accuracy: 0.9750\n",
            "Epoch 667/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9875\n",
            "Epoch 668/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9875\n",
            "Epoch 669/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9875\n",
            "Epoch 670/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9875\n",
            "Epoch 671/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9875\n",
            "Epoch 672/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9750\n",
            "Epoch 673/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9937 - val_loss: 0.0447 - val_accuracy: 0.9875\n",
            "Epoch 674/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0373 - val_accuracy: 0.9875\n",
            "Epoch 675/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9750\n",
            "Epoch 676/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9875\n",
            "Epoch 677/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9875\n",
            "Epoch 678/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0574 - val_accuracy: 0.9750\n",
            "Epoch 679/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9750\n",
            "Epoch 680/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0554 - val_accuracy: 0.9875\n",
            "Epoch 681/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9875\n",
            "Epoch 682/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 0.0277 - val_accuracy: 0.9875\n",
            "Epoch 683/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 0.0432 - val_accuracy: 0.9875\n",
            "Epoch 684/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.0453 - val_accuracy: 0.9875\n",
            "Epoch 685/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9937 - val_loss: 0.0321 - val_accuracy: 0.9875\n",
            "Epoch 686/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.1017 - val_accuracy: 0.9625\n",
            "Epoch 687/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9937 - val_loss: 0.0220 - val_accuracy: 0.9750\n",
            "Epoch 688/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9750\n",
            "Epoch 689/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0528 - val_accuracy: 0.9750\n",
            "Epoch 690/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0287 - val_accuracy: 0.9875\n",
            "Epoch 691/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.0183 - val_accuracy: 0.9875\n",
            "Epoch 692/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0683 - val_accuracy: 0.9875\n",
            "Epoch 693/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9875\n",
            "Epoch 694/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0230 - val_accuracy: 0.9875\n",
            "Epoch 695/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0576 - val_accuracy: 0.9875\n",
            "Epoch 696/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0276 - val_accuracy: 0.9875\n",
            "Epoch 697/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9937 - val_loss: 0.1098 - val_accuracy: 0.9625\n",
            "Epoch 698/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9875\n",
            "Epoch 699/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9906 - val_loss: 0.0349 - val_accuracy: 0.9875\n",
            "Epoch 700/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9937 - val_loss: 0.0832 - val_accuracy: 0.9750\n",
            "Epoch 701/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9906 - val_loss: 0.0451 - val_accuracy: 0.9875\n",
            "Epoch 702/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9875 - val_loss: 0.1094 - val_accuracy: 0.9625\n",
            "Epoch 703/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9937 - val_loss: 0.0650 - val_accuracy: 0.9750\n",
            "Epoch 704/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9750\n",
            "Epoch 705/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9750\n",
            "Epoch 706/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.0362 - val_accuracy: 0.9875\n",
            "Epoch 707/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9875\n",
            "Epoch 708/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9875\n",
            "Epoch 709/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0287 - val_accuracy: 0.9875\n",
            "Epoch 710/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0370 - val_accuracy: 0.9875\n",
            "Epoch 711/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9875\n",
            "Epoch 712/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9906 - val_loss: 0.0583 - val_accuracy: 0.9750\n",
            "Epoch 713/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0881 - val_accuracy: 0.9750\n",
            "Epoch 714/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 0.0387 - val_accuracy: 0.9875\n",
            "Epoch 715/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9937 - val_loss: 0.0603 - val_accuracy: 0.9750\n",
            "Epoch 716/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9875\n",
            "Epoch 717/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9875\n",
            "Epoch 718/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9875\n",
            "Epoch 719/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9875\n",
            "Epoch 720/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1421 - val_accuracy: 0.9625\n",
            "Epoch 721/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9812 - val_loss: 0.0404 - val_accuracy: 0.9875\n",
            "Epoch 722/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.0996 - val_accuracy: 0.9625\n",
            "Epoch 723/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9937 - val_loss: 0.0463 - val_accuracy: 0.9750\n",
            "Epoch 724/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9906 - val_loss: 0.1020 - val_accuracy: 0.9750\n",
            "Epoch 725/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9750\n",
            "Epoch 726/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0741 - val_accuracy: 0.9750\n",
            "Epoch 727/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0230 - val_accuracy: 0.9875\n",
            "Epoch 728/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9969 - val_loss: 0.1305 - val_accuracy: 0.9625\n",
            "Epoch 729/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9906 - val_loss: 0.0402 - val_accuracy: 0.9875\n",
            "Epoch 730/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0662 - val_accuracy: 0.9875\n",
            "Epoch 731/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 732/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9937 - val_loss: 0.0779 - val_accuracy: 0.9875\n",
            "Epoch 733/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9875\n",
            "Epoch 734/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 0.0337 - val_accuracy: 0.9750\n",
            "Epoch 735/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9906 - val_loss: 0.0930 - val_accuracy: 0.9875\n",
            "Epoch 736/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9937 - val_loss: 0.0279 - val_accuracy: 0.9875\n",
            "Epoch 737/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.1058 - val_accuracy: 0.9750\n",
            "Epoch 738/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9906 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
            "Epoch 739/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.1059 - val_accuracy: 0.9625\n",
            "Epoch 740/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9812 - val_loss: 0.0350 - val_accuracy: 0.9875\n",
            "Epoch 741/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 0.9875\n",
            "Epoch 742/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.0352 - val_accuracy: 0.9875\n",
            "Epoch 743/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0233 - val_accuracy: 0.9875\n",
            "Epoch 744/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9969 - val_loss: 0.0281 - val_accuracy: 0.9875\n",
            "Epoch 745/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9844 - val_loss: 0.0227 - val_accuracy: 0.9875\n",
            "Epoch 746/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9969 - val_loss: 0.0449 - val_accuracy: 0.9750\n",
            "Epoch 747/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9750\n",
            "Epoch 748/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9750\n",
            "Epoch 749/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9875\n",
            "Epoch 750/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9750\n",
            "Epoch 751/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 0.0828 - val_accuracy: 0.9750\n",
            "Epoch 752/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9875\n",
            "Epoch 753/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9969 - val_loss: 0.0865 - val_accuracy: 0.9750\n",
            "Epoch 754/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0237 - val_accuracy: 0.9875\n",
            "Epoch 755/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0259 - val_accuracy: 0.9875\n",
            "Epoch 756/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0395 - val_accuracy: 0.9750\n",
            "Epoch 757/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9969 - val_loss: 0.0597 - val_accuracy: 0.9750\n",
            "Epoch 758/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.0610 - val_accuracy: 0.9750\n",
            "Epoch 759/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9750\n",
            "Epoch 760/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0802 - val_accuracy: 0.9750\n",
            "Epoch 761/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9969 - val_loss: 0.0197 - val_accuracy: 0.9875\n",
            "Epoch 762/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9750\n",
            "Epoch 763/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0720 - val_accuracy: 0.9750\n",
            "Epoch 764/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 0.0174 - val_accuracy: 0.9875\n",
            "Epoch 765/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9937 - val_loss: 0.0404 - val_accuracy: 0.9750\n",
            "Epoch 766/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9875\n",
            "Epoch 767/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9750\n",
            "Epoch 768/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9750\n",
            "Epoch 769/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9937 - val_loss: 0.0442 - val_accuracy: 0.9750\n",
            "Epoch 770/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9937 - val_loss: 0.0311 - val_accuracy: 0.9750\n",
            "Epoch 771/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9750\n",
            "Epoch 772/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9750\n",
            "Epoch 773/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9750\n",
            "Epoch 774/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9750\n",
            "Epoch 775/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
            "Epoch 776/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9750\n",
            "Epoch 777/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9875\n",
            "Epoch 778/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9750\n",
            "Epoch 779/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9875 - val_loss: 0.0208 - val_accuracy: 0.9875\n",
            "Epoch 780/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0212 - val_accuracy: 0.9875\n",
            "Epoch 781/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.0791 - val_accuracy: 0.9875\n",
            "Epoch 782/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0762 - val_accuracy: 0.9875\n",
            "Epoch 783/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9875 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 784/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9937 - val_loss: 0.0163 - val_accuracy: 0.9875\n",
            "Epoch 785/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9750\n",
            "Epoch 786/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9750\n",
            "Epoch 787/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9750\n",
            "Epoch 788/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.0555 - val_accuracy: 0.9875\n",
            "Epoch 789/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.1335 - val_accuracy: 0.9625\n",
            "Epoch 790/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9906 - val_loss: 0.0940 - val_accuracy: 0.9625\n",
            "Epoch 791/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1036 - val_accuracy: 0.9750\n",
            "Epoch 792/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.0776 - val_accuracy: 0.9875\n",
            "Epoch 793/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9875\n",
            "Epoch 794/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0414 - val_accuracy: 0.9875\n",
            "Epoch 795/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9937 - val_loss: 0.0982 - val_accuracy: 0.9625\n",
            "Epoch 796/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9906 - val_loss: 0.0872 - val_accuracy: 0.9750\n",
            "Epoch 797/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9875\n",
            "Epoch 798/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0580 - val_accuracy: 0.9875\n",
            "Epoch 799/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9875\n",
            "Epoch 800/800\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg4nwUY9cYas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8d829c61-8b88-48ca-b40d-1520091402e3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (10, 32)                  160       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (10, 32)                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (10, 32)                  1056      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (10, 32)                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (10, 1)                   33        \n",
            "=================================================================\n",
            "Total params: 1,249\n",
            "Trainable params: 1,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4CBA0aJn41X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "80d1206b-829c-470d-bda7-9d6745c1f81c"
      },
      "source": [
        "model.evaluate(x_test_m,y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2102479338645935, 0.9700000286102295]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auwdQ9DHu0ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "2d3a1148-3976-4175-8869-10ba3d0a74a6"
      },
      "source": [
        "plt.plot(history_model.history['val_loss'],label=\"val set\")\n",
        "plt.plot(history_model.history['loss'],label=\"train set\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"The Loss of Training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The Loss of Training')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXObenKWal1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "4259cdd8-66c1-4d75-d908-01b574da8995"
      },
      "source": [
        "plt.plot(history_model.history['val_accuracy'],label=\"val set\")\n",
        "plt.plot(history_model.history['accuracy'],label=\"train set\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"The Accuracy of Training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'The Accuracy of Training')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZSIZL61YTMQ",
        "colab_type": "text"
      },
      "source": [
        "## Confusion maxtrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjbhOnvqpCbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "5f77e9f7-7200-41ad-9f2b-d88b8a9f9d6f"
      },
      "source": [
        "prediction_model=model.predict_classes(x_test_m)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "matirx=confusion_matrix(y_test, prediction_model,normalize='true')\n",
        "ConfusionMatrixDisplay(matirx,display_labels=['neg','pos']).plot()\n",
        "plt.title(\"Matrix confusion of MLP\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-1c614c05f9c6>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Matrix confusion of MLP')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDbNMaA7Zbib",
        "colab_type": "text"
      },
      "source": [
        "## ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVNi-bLQZdAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1bc3907a-035b-4490-8db6-1e6de59b016b"
      },
      "source": [
        "train_proba = model.predict_proba(x_train_m)\n",
        "test_proba = model.predict_proba(x_test_m)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr_test, tpr_test, th_test = metrics.roc_curve(y_test, test_proba)\n",
        "fpr_train, tpr_train, th_train = metrics.roc_curve(y_train, train_proba)\n",
        "plt.figure(figsize=[10, 5])\n",
        "plt.plot(fpr_test, tpr_test)\n",
        "plt.plot(fpr_train, tpr_train,\"r--\")\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpFSEJ89Z-o9",
        "colab_type": "text"
      },
      "source": [
        "## F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOWz92eZ9vi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8c0e3c04-7252-4fe5-e990-7a682334d2bb"
      },
      "source": [
        "print(metrics.classification_report(y_test, prediction_model))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.96        32\n",
            "           1       1.00      0.96      0.98        68\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.96      0.98      0.97       100\n",
            "weighted avg       0.97      0.97      0.97       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvHUIFzWYZxi",
        "colab_type": "text"
      },
      "source": [
        "# SVM based method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO7TZ-IZYPDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1f7ad52c-5982-4603-dac3-816199a463ed"
      },
      "source": [
        "from sklearn import svm\n",
        "parameters=[1,5,10,15,20,25,30]\n",
        "result=[]\n",
        "for i in parameters:\n",
        "    clf = svm.SVC(C=i)\n",
        "    clf.fit(x_train_m,y_train)\n",
        "    result.append(clf.score(x_test_m,y_test))\n",
        "parameters_str = [str(j) for j in parameters]\n",
        "plt.plot(parameters_str,result,color='b',marker='o',linestyle='dashed')\n",
        "plt.xlabel('C value')\n",
        "plt.ylabel('mean of accuaracy')\n",
        "max_index=result.index(max(result))\n",
        "parameter=parameters[max_index]\n",
        "print(max(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.96\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYGK1H-1il1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6199d911-ad32-4e4a-a8c9-be4c4fe055ac"
      },
      "source": [
        "parameters=[15,16,17,18,19,20,21]\n",
        "result=[]\n",
        "for i in parameters:\n",
        "    clf = svm.SVC(C=i)\n",
        "    clf.fit(x_train_m,y_train)\n",
        "    result.append(clf.score(x_test_m,y_test))\n",
        "parameters_str = [str(j) for j in parameters]\n",
        "plt.plot(parameters_str,result,color='b',marker='o',linestyle='dashed')\n",
        "plt.xlabel('C value')\n",
        "plt.ylabel('mean of accuaracy')\n",
        "max_index=result.index(max(result))\n",
        "parameter=parameters[max_index]\n",
        "print(max(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.96\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q75uaFVaYfjw",
        "colab_type": "text"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl4OsfM2bEmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "93621fb0-6155-491f-d837-876fae0f6c22"
      },
      "source": [
        "prediction_svm=clf.predict(x_test_m)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "matirx=confusion_matrix(y_test, prediction_svm,normalize='true')\n",
        "ConfusionMatrixDisplay(matirx,display_labels=['neg','pos']).plot()\n",
        "plt.title(\"Matrix confusion of SVM\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Matrix confusion of SVM')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdujFhs6ZUSX",
        "colab_type": "text"
      },
      "source": [
        "## ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnDjTI_q18Se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "294848d2-28e4-4753-9c4d-3ecf1b7c71a1"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score as AUC\n",
        "from sklearn.metrics import roc_curve\n",
        "clf_proba = clf.fit(x_train_m, y_train)\n",
        "\n",
        "FPR, recall, thresholds = roc_curve(y_test,clf_proba.decision_function(x_test_m), pos_label=1)\n",
        "FPR_train, recall_train, thresholds_train = roc_curve(y_train,clf_proba.decision_function(x_train_m), pos_label=1)\n",
        "\n",
        "print(FPR.shape)        # (45,))\n",
        "print(recall.shape)     # (45,))\n",
        "print(thresholds.shape) # (45,))\n",
        "\n",
        "area = AUC(y_train,clf_proba.decision_function(x_train_m))\n",
        "print(area)     # 0.9696400000000001\n",
        "\n",
        "plt.figure()\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(FPR, recall\n",
        "         ,label='ROC curve (area = %0.2f)' % area)\n",
        "plt.plot(FPR_train, recall_train, \"r--\"\n",
        "         ,label='ROC curve (area = %0.2f)' % area)\n",
        "#plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
        "\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Roc Curve')\n",
        "#plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "maxindex = (recall - FPR).tolist().index(max(recall - FPR))\n",
        "print(thresholds[maxindex])     # -1.0860191749391461"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8,)\n",
            "(8,)\n",
            "(8,)\n",
            "0.998448603743369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "-0.0070993516312540805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J810qwRKZW6L",
        "colab_type": "text"
      },
      "source": [
        "## F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVc2rCjQ5ZEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7a68416a-3f25-4575-8682-51bf856a0d22"
      },
      "source": [
        "#print(metrics.classification_report(y_test, prediction_svm))\n",
        "from sklearn.metrics import confusion_matrix as CM, precision_score as P, recall_score as R, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, prediction_svm))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        32\n",
            "           1       1.00      0.94      0.97        68\n",
            "\n",
            "    accuracy                           0.96       100\n",
            "   macro avg       0.94      0.97      0.96       100\n",
            "weighted avg       0.96      0.96      0.96       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
